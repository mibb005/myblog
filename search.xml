<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2021%2F07%2F07%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[NAT与内网穿透]]></title>
    <url>%2F2021%2F07%2F07%2Fnet-md%2F</url>
    <content type="text"><![CDATA[NAT是什么 网络地址转换,就是替换IP报文头部的地址信息.由于IPv4地址有限,不可能为每一个上网设备分配一个ip,而NAT就是来解决这个问题的.我们在上网时很有可能处在一个NAT设备之后, NAT设备会在ip包通过时会修改其 源/目标IP地址,有时还会修改TCP/UDP协议的端口号,从而实现多台设备使用同一外网IP进行互联网通讯 NAT特点 1,网络被分为私网,公网两部分,NAT网关设置私网到公网的路由出口.2,网络只能由私网侧发起,公网无法主动访问私网主机(是这样设计的,但是可以通过打洞)3,NAT网关在两个访问方向上完成两次地址的转换,出口替换源地址,入口替换目的地址4,NAT网关的存在对通信双方保持透明5,NAT网关为了实现双向翻译,需要维持一张关联表,将会话信息保存 NAT的副作用 NAT表的淘汰 当NAT表对应的记录在一段时间内没有通讯时,网络运营商就会将其淘汰掉,若此时外网还通过原来记录的外网IP地址和内网设备进行通讯则会不通. NAT墙 当外界对内网的请求到达NAT设备时,若不符合NAT设备和NAT表的要求,则会被丢弃,这样若想实现ip地址不固定客户端间通讯则需要额外的打洞操作(需要心跳包刷新NAT表重置时间) 端对端通信模型的破坏 NAT实现了将多个内部主机发出的链接被复用到一个ip上,这样无法基于ip对主机进行追踪,这样服务器不能简单的将同一ip与主机挂钩.这样再统计信息和防止DDOS攻击时都会变得复杂, 有时,若-个NAT设备拥有多个IP地址时,一组关联的会话可能会被分配到不同公网ip里,总之NAT隐蔽了通讯的另一端. NAT类型1, Full Cone NAT(完全雏形NAT) 设备比较少,一旦内部主机端口在NAT网关完成端口映射,则后续外网任一主机都可以通过这映射好的端口进行访问 2, Restricted Cone NAT (限制雏形NAT) 相较与全雏形NAT,在完成端口映射后,对IP地址有限制,只有内网对外访问过的ip地址才可以对该端口进行连接 3, Port Restricted Cone NAT(端口限制雏形NAT) 相较于限制雏形NAT,在端口上也加以限制,只有内网向该ip与端口发送过信息才能对其访问 4, Symmetric NAT (对称NAT) 也就是说,虽然是同一个内网主机,对不同的外网ip+端口访问时,在NAT表上会映射成不同的端口号 注意: 事实上，这些术语的引入是很多混淆的起源。现实中的很多NAT设备是将这些转换方式混合在一起工作的，而不单单使用一种，所以这些术语只适合描述一种工作方式，而不是一个设备。比如，很多NAT设备对内部发出的连接使用对称型NAT方式，而同时支持静态的端口映射，后者可以被看作是全锥型NAT方式。而有些情况下，NAT设备的一个公网地址和端口可以同时映射到内部几个服务器上以实现负载分担，比如一个对外提供WEB服务器的站点可能是有成百上千个服务器在提供HTTP服务，但是对外却表现为一个或少数几个IP地址。 内网穿透应用层网管(ALG)普通NAT实现了对UDP或TCP报文头中的的IP地址及端口转换功能，但对应用层数据载荷中的字段无能为力，在许多应用层协议中，比如多媒体协议（H.323、SIP等）、FTP、SQLNET等，TCP/UDP载荷中带有地址或者端口信息，这些内容不能被NAT进行有效的转换，就可能导致问题。而NAT ALG（Application Level Gateway，应用层网关）技术能对多通道协议进行应用层报文信息的解析和地址转换，将载荷中需要进行地址转换的IP地址和端口或者需特殊处理的字段进行相应的转换和处理，从而保证应用层通信的正确性。 例如，FTP应用就由数据连接和控制连接共同完成，而且数据连接的建立动态地由控制连接中的载荷字段信息决定，这就需要ALG来完成载荷字段信息的转换，以保证后续数据连接的正确建立。 图中私网侧的主机要访问公网的FTP服务器。NAT设备上配置了私网地址192.168.1.2到公网地址8.8.8.11的映射，实现地址的NAT转换，以支持私网主机对公网的访问。组网中，若没有ALG对报文载荷的处理，私网主机发送的PORT报文到达服务器端后，服务器无法根据私网地址进行寻址，也就无法建立正确的数据连接。整个通信过程包括如下四个阶段： (1) 私网主机和公网FTP服务器之间通过TCP三次握手成功建立控制连接。 (2) 控制连接建立后，私网主机向FTP服务器发送PORT报文，报文中携带私网主机指定的数据连接的目的地址和端口，用于通知服务器使用该地址和端口和自己进行数据连接。 (3) PORT报文在经过支持ALG特性的NAT设备时，报文载荷中的私网地址和端口会被转换成对应的公网地址和端口。即设备将收到的PORT报文载荷中的私网地址192.168.1.2转换成公网地址8.8.8.11，端口1084转换成12487。 (4) 公网的FTP服务器收到PORT报文后，解析其内容，并向私网主机发起数据连接，该数据连接的目的地址为8.8.8.11，目的端口为12487（注意：一般情况下，该报文源端口为20，但由于FTP协议没有严格规定，有的服务器发出的数据连接源端口为大于1024的随机端口，如本例采用的是wftpd服务器，采用的源端口为3004）。由于该目的地址是一个公网地址，因此后续的数据连接就能够成功建立，从而实现私网主机对公网服务器的访问。 总而言之,在ALG中配置的支持的协议,可以实现逆向访问 中间件技术这也是一种通过开发通用方法解决NAT穿越问题的努力。与前者不同之处是，NAT网关是这一解决方案的参与者。与ALG的不同在于，客户端会参与网关公网映射信息的维护，此时NAT网关只要理解客户端的请求并按照要求去分配转换表，不需要自己去分析客户端的应用层数据。其中UPnP就是这样一种方法。UPnP中文全称为通用即插即用，是一个通用的网络终端与网关的通信协议，具备信息发布和管理控制的能力。其中，网关映射请求可以为客户动态添加映射表项。此时，NAT不再需要理解应用层携带的信息，只转换IP地址和端口信息。而客户端通过控制消息或信令发到公网侧的信息中，直接携带公网映射的IP地址和端口，接收端可以按照此信息建立数据连接。NAT网关在收到数据或连接请求时，按照UPnP建立的表项只转换地址和端口信息，不关心内容，再将数据转发到内网。这种方案需要网关、内部主机和应用程序都支持UPnP技术，且组网允许内部主机和NAT网关之间可以直接交换UPnP信令才能实施。 中继代理技术准确说它不是NAT穿越技术，而是NAT旁路技术。简单说，就是在NAT网关所在的位置旁边放置一个应用服务器，这个服务器在内部网络和外部公网分别有自己的网络连接。客户端特定的应用产生网络请求时，将定向发送到应用代理服务器。应用代理服务器根据代理协议解析客户端的请求，再从服务器的公网侧发起一个新的请求，把客户端请求的内容中继到外部网络上，返回的相应反方向中继。这项技术和ALG有很大的相似性，它要求为每个应用类型部署中继代理业务，中间服务器要理解这些请求。 特定协议的自穿越技术在所有方法中最复杂也最可靠的就是自己解决自己的问题。比如IKE和IPsec技术，在设计时就考虑了到如何穿越NAT的问题。因为这个协议是一个自加密的协议并且具有报文防修改的鉴别能力，其他通用方法爱莫能助。因为实际应用的NAT网关基本都是NAPT方式，所有通过传输层协议承载的报文可以顺利通过NAT。IKE和IPsec采用的方案就是用UDP在报文外面再加一层封装，而内部的报文就不再受到影响。IKE中还专门增加了NAT网关是否存在的检查能力以及绕开NAT网关检测IKE协议的方法。 探针技术STUN和TURN所谓探针技术，是通过在所有参与通信的实体上安装探测插件，以检测网络中是否存在NAT网关，并对不同NAT模型实施不同穿越方法的一种技术。STUN服务器被部署在公网上，用于接收来自通信实体的探测请求，服务器会记录收到请求的报文地址和端口，并填写到回送的响应报文中。客户端根据接收到的响应消息中记录的地址和端口与本地选择的地址和端口进行比较，就能识别出是否存在NAT网关。如果存在NAT网关，客户端会使用之前的地址和端口向服务器的另外一个IP发起请求，重复前面的探测。然后再比较两次响应返回的结果判断出NAT工作的模式。由前述的一对多转换模型得知，除对称型NAT以外的模型，NAT网关对内部主机地址端口的映射都是相对固定的，所以比较容易实现NAT穿越。而对称型NAT为每个连接提供一个映射，使得转换后的公网地址和端口对不可预测。此时TURN可以与STUN绑定提供穿越NAT的服务，即在公网服务器上提供一个“地址端口对”，所有此“地址端口对”接收到的数据会经由探测建立的连接转发到内网主机上。TURN分配的这个映射“地址端口对”会通过STUN响应发给内部主机，后者将此信息放入建立连接的信令中通知通信的对端。这种探针技术是一种通用方法，不用在NAT设备上为每种应用协议开发功能，相对于ALG方式有一定普遍性。但是TURN中继服务会成为通信瓶颈。而且在客户端中增加探针功能要求每个应用都要增加代码才能支持。]]></content>
      <tags>
        <tag>nat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2021%2F04%2F27%2Fgitpod%2F</url>
    <content type="text"><![CDATA[测试]]></content>
  </entry>
  <entry>
    <title><![CDATA[windows包管理工具 Chocolatey]]></title>
    <url>%2F2020%2F05%2F12%2Fwindows1-md%2F</url>
    <content type="text"><![CDATA[安装右键开始菜单，选择以管理员身份运行PowerShell，然后粘贴以下指令： 1Set-ExecutionPolicy Bypass -Scope Process -Force; iex ((New-Object System.Net.WebClient).DownloadString(&apos;https://chocolatey.org/install.ps1&apos;)) 用法choco install 软件名]]></content>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[google-flash]]></title>
    <url>%2F2019%2F12%2F09%2Fgoogle-flash%2F</url>
    <content type="text"><![CDATA[https://jingyan.baidu.com/article/60ccbceb8730c764cab1973c.html]]></content>
      <tags>
        <tag>google</tag>
        <tag>flash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[v2ray]]></title>
    <url>%2F2019%2F12%2F03%2Fv2ray%2F</url>
    <content type="text"><![CDATA[简介V2Ray 是 Project V 下的一个工具。Project V 是一个包含一系列构建特定网络环境工具的项目，而 V2Ray 属于最核心的一个。 官方中介绍Project V 提供了单一的内核和多种界面操作方式。内核（V2Ray）用于实际的网络交互、路由等针对网络数据的处理，而外围的用户界面程序提供了方便直接的操作流程。不过从时间上来说，先有 V2Ray 才有 Project V。 如果还是不理解，那么简单地说，V2Ray 是一个与 Shadowsocks 类似的代理软件，可以用来科学上网（翻墙）学习国外先进科学技术。 V2Ray 用户手册：https://www.v2ray.com（已被墙） https://v2ray.cool（已被墙） https://v2ray.com/ V2Ray 项目地址：https://github.com/v2ray/v2ray-core V2Ray Telegram 使用群链接：https://t.me/projectv2ray 下载预编译的压缩包可以在如下几个站点找到： Github Release: github.com/v2ray/v2ray-core Github 分流: github.com/v2ray/dist Homebrew: github.com/v2ray/homebrew-v2ray Arch Linux: packages/community/x86_64/v2ray/ Snapcraft: snapcraft.io/v2ray-core 压缩包均为 zip 格式，找到对应平台的压缩包，下载解压即可使用。]]></content>
      <tags>
        <tag>v2ray</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node中使用redis]]></title>
    <url>%2F2019%2F11%2F29%2Fnode-redis%2F</url>
    <content type="text"><![CDATA[Redis简介Redis是一个高性能的key-value数据库，Redis把数据存在内存中，并在磁盘中记录数据的变化。因为将数据存在内存中，所以数据操作非常快。 安装以windows环境为例，先下载windows版本的redis，地址如下：3.2.100下载完成后，解压，我这里解压到D:redis目录下 开启服务打开一个 cmd 窗口，进入目录到 D:redis，运行 redis-server.exe redis.windows.conf。 出现上面界面，则redis已经在本机端口6379启动了服务，那么接下来，便可以用客户端连接到redis服务端了。 在node中使用redis首先，安装驱动：npm install redis redis支持多种数据类型，常用的有键/值对，哈希表，链表，集合等。 普通数据我们先来看看如何存储和获取键/值对。 1234567891011121314var redis = require(&apos;redis&apos;)var client = redis.createClient(6379, &apos;127.0.0.1&apos;)client.on(&apos;error&apos;, function (err) &#123; console.log(&apos;Error &apos; + err);&#125;);// 1 键值对client.set(&apos;color&apos;, &apos;red&apos;, redis.print);client.get(&apos;color&apos;, function(err, value) &#123; if (err) throw err; console.log(&apos;Got: &apos; + value) client.quit();&#125;) 哈希表哈希表有点类似ES6中的Map。 12345678910111213141516client.hmset(&apos;kitty&apos;, &#123; &apos;age&apos;: &apos;2-year-old&apos;, &apos;sex&apos;: &apos;male&apos;&#125;, redis.print);client.hget(&apos;kitty&apos;, &apos;age&apos;, function(err, value) &#123; if (err) throw err; console.log(&apos;kitty is &apos; + value);&#125;);client.hkeys(&apos;kitty&apos;, function(err, keys) &#123; if (err) throw err; keys.forEach(function(key, i) &#123; console.log(key, i); &#125;); client.quit();&#125;); 链表Redis链表类似JS数组，lpush向链表中添加值，lrange获取参数start和end范围内的链表元素, 参数end为-1，表明到链表中最后一个元素。注意：随着链表长度的增长，数据获取也会逐渐变慢（大O表示法中的O(n)） 123456789client.lpush(&apos;tasks&apos;, &apos;Paint the house red.&apos;, redis.print);client.lpush(&apos;tasks&apos;, &apos;Paint the house green.&apos;, redis.print);client.lrange(&apos;tasks&apos;, 0, -1, function(err, items) &#123; if (err) throw err; items.forEach(function(item, i) &#123; console.log(&apos; &apos; + item); &#125;); client.quit();&#125;); 集合类似JS中的Set，集合中的元素必须是唯一的，其性能: 大O表示法中的O(1) 12345678client.sadd(&apos;ip&apos;, &apos;192.168.3.7&apos;, redis.print);client.sadd(&apos;ip&apos;, &apos;192.168.3.7&apos;, redis.print);client.sadd(&apos;ip&apos;, &apos;192.168.3.9&apos;, redis.print);client.smembers(&apos;ip&apos;, function(err, members) &#123; if (err) throw err; console.log(members); client.quit();&#125;); 信道Redis超越了数据存储的传统职责，它还提供了信道，信道是数据传递机制，提供了发布/预定功能。 1234567891011var redis = require(&apos;redis&apos;)var clientA = redis.createClient(6379, &apos;127.0.0.1&apos;)var clientB = redis.createClient(6379, &apos;127.0.0.1&apos;)clientA.on(&apos;message&apos;, function(channel, message) &#123; console.log(&apos;Client A got message from channel %s: %s&apos;, channel, message);&#125;);clientA.on(&apos;subscribe&apos;, function(channel, count) &#123; clientB.publish(&apos;main_chat_room&apos;, &apos;Hello world!&apos;);&#125;);clientA.subscribe(&apos;main_chat_room&apos;); 上面代码中，clientA订阅了main_chat_room，这时clientA捕获到订阅事件，执行回调函数，clientB向main_chat_room发送了一条信息Hello world!clientA接受到信息后，在控制台打印出了相关信息。]]></content>
      <tags>
        <tag>node</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node.js express 配置模块config-lite的用法]]></title>
    <url>%2F2019%2F11%2F15%2Fnode-config%2F</url>
    <content type="text"><![CDATA[安装1npm i config-lite --save 使用方法配置文件的示例路径：项目文件夹/config/default.js: 1234567891011121314151617&apos;use strict&apos;; module.exports = &#123; name: &apos;zz&apos;, port: 2000, /** mysql settings */ mysql: &#123; host: &apos;127.0.0.1&apos;, port: 3306, user: &apos;root&apos;, db: &apos;auto_mon&apos;, pass: &apos;000000&apos;, char: &apos;utf8mb4&apos; &#125;, debug: true&#125; 调用 index.js: 12345import config=require(&apos;config-lite&apos;) //先引入配置模块 //config便是配置对象，通过config.port config.mysql调用其配置属性console.log(config.name); console.log(config.port); 为什么要使用配置模块？不管是小项目还是大项目，将配置与代码分离是一个非常好的做法。我们通常将配置写到一个配置文件里，如 config.js 或 config.json，并放到项目的根目录下。但通常我们都会有许多环境，如本地开发环境、测试环境和线上环境等，不同的环境的配置不同，我们不可能每次部署时都要去修改引用config.test.js 或者 config.production.js。config-lite 模块正是你需要的。 config-lite是一个轻量的读取配置文件的模块。config-lite 会根据环境变量（NODE_ENV）的不同从当前执行进程目录下的 config 目录加载不同的配置文件。如果不设置NODE_ENV，则读取默认的 default 配置文件，如果设置了NODE_ENV，则会合并指定的配置文件和 default 配置文件作为配置，config-lite 支持 .js、.json、.node、.yml、.yaml 后缀的文件。 如果程序以NODE_ENV=test node app启动，则通过require(‘config-lite’)会依次降级查找config/test.js、config/test.json、config/test.node、config/test.yml、config/test.yaml并合并 default 配置; 如果程序以NODE_ENV=production node app启动，则通过require(‘config-lite’)会依次降级查找config/production.js、config/production.json、config/production.node、config/production.yml、config/production.yaml并合并 default 配置。]]></content>
      <tags>
        <tag>node</tag>
        <tag>Express</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gRPC 官方文档中文版]]></title>
    <url>%2F2019%2F11%2F14%2Fgrpc-md%2F</url>
    <content type="text"><![CDATA[http://doc.oschina.net/grpc?t=58010]]></content>
      <tags>
        <tag>gRPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[node打包exe]]></title>
    <url>%2F2019%2F11%2F14%2Fnode-pkg%2F</url>
    <content type="text"><![CDATA[项目地址1https://github.com/zeit/pkg 安装1npm install -g pkg 打包1pkg entrance.js 即可打包linux,macos,win3个平台的可执行文件。entrance.js为你node项目的入口文件。 如果只想打包windows下的exe，则加上-t参数。win即为打包成windows平台下的exe文件 1pkg -t win entrance.js 稍等片刻后项目目录下就会生成打包好的entrance.exe文件。 pkg会自动从入口文件开始查找依赖的文件并全数打包进去，无须修改项目里的任何代码。 其他pkg可以根据package.json下的配置进行打包，默认入口文件为bin指向的文件。执行1pkg . 或是 1pkg package.json 即可自动按照package.json的配置打包。 12345678910111213//package.json&#123; //其他配置项 &quot;bin&quot;: &quot;service.js&quot;,//入口文件 &quot;pkg&quot;: &#123; &quot;scripts&quot;: [ &quot;build/**/*.js&quot;//需要打包进来的其他js文件，可添加多个 ], &quot;assets&quot;: [ &quot;dist/**/*&quot;//静态文件的目录，可添加多个 ] &#125;&#125; 注意：静态文件需要在项目中将文件的引用换成 1path.join(__dirname, &apos;dist&apos;) 的形式，才可以正常打包，否则可能会读取不到。]]></content>
      <tags>
        <tag>node</tag>
        <tag>pkg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[NodeJs - Express - apidoc 自动生成API文档]]></title>
    <url>%2F2019%2F11%2F13%2Fnode-Swagger%2F</url>
    <content type="text"><![CDATA[安装1npm i apidoc -g #全局安装 配置方式一：根目录配置apidoc.json 1234567&#123; &quot;name&quot;: &quot;example&quot;, &quot;version&quot;: &quot;0.1.0&quot;, &quot;description&quot;: &quot;apiDoc basic example&quot;, &quot;title&quot;: &quot;Custom apiDoc browser title&quot;, &quot;url&quot; : &quot;https://api.github.com/v1&quot;&#125; 方式二：项目package.json配置api-doc 123456789101112131415161718192021222324&#123; &quot;name&quot;: &quot;helo&quot;, &quot;version&quot;: &quot;0.0.0&quot;, &quot;private&quot;: true, &quot;scripts&quot;: &#123; &quot;start&quot;: &quot;node ./bin/www&quot; &#125;, &quot;dependencies&quot;: &#123; &quot;cookie-parser&quot;: &quot;~1.4.3&quot;, &quot;debug&quot;: &quot;~2.6.9&quot;, &quot;ejs&quot;: &quot;~2.5.7&quot;, &quot;express&quot;: &quot;~4.16.0&quot;, &quot;http-errors&quot;: &quot;~1.6.2&quot;, &quot;morgan&quot;: &quot;~1.9.0&quot; &#125;, &quot;devDependencies&quot;: &#123; &quot;express-session&quot;: &quot;^1.15.6&quot;, &quot;mysql&quot;: &quot;^2.15.0&quot; &#125;, &quot;apidoc&quot;: &#123; //配置api-doc &quot;title&quot;: &quot;接口文档&quot;, //Api-Doc的网页Title &quot;url&quot;: &quot;http://localhost:3000&quot; //Api测试需要这个地址，地址必须正确 &#125;&#125; 然后通过在项目的public文件夹下面新建一个apidoc目录。接着，我们需要编写router里的代码，创建一个api目录，里面编写一个User.js接口的东西。 范例： 1234567891011121314151617181920212223242526272829303132333435let express = require(&apos;express&apos;);let router = express.Router();/** * @api &#123;post&#125; /api/user/submit-login 用户登录 * @apiDescription 用户登录 * @apiName submit-login * @apiGroup User * @apiParam &#123;string&#125; loginName 用户名 * @apiParam &#123;string&#125; loginPass 密码 * @apiSuccess &#123;json&#125; result * @apiSuccessExample &#123;json&#125; Success-Response: * &#123; * &quot;success&quot; : &quot;true&quot;, * &quot;result&quot; : &#123; * &quot;name&quot; : &quot;loginName&quot;, * &quot;password&quot; : &quot;loginPass&quot; * &#125; * &#125; * @apiSampleRequest http://localhost:3000/api/user/submit-login * @apiVersion 1.0.0 */router.post(&apos;/submit-login&apos;, function (req, res, next) &#123; let loginName = req.body.loginName; let loginPass = req.body.loginPass; res.json(&#123; success: true, result: &#123; name: loginName, password: loginPass &#125; &#125;);&#125;);module.exports = router; 命令1apidoc -i routes/ -o public/apidoc/]]></content>
      <tags>
        <tag>node</tag>
        <tag>apidoc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Supervisor-守护进程工具]]></title>
    <url>%2F2019%2F11%2F12%2FSupervisor%2F</url>
    <content type="text"><![CDATA[简介Supervisor是用Python开发的一个client/server服务，是Linux/Unix系统下的一个进程管理工具，不支持Windows系统。它可以很方便的监听、启动、停止、重启一个或多个进程。用Supervisor管理的进程，当一个进程意外被杀死，supervisort监听到进程死后，会自动将它重新拉起，很方便的做到进程自动恢复的功能，不再需要自己写shell脚本来控制。 不使用守护进程会出现的三个问题： 1、ASP.NET Core应用程序运行在shell之中，如果关闭shell则会发现 ASP.NET Core程序被关闭，从而导致应用无法访问，这种情况当然是我们不想遇到的，而且生产环境对这种情况是零容忍的。2、如果 ASP.NET Core进程意外终止那么需要人为连进shell进行再次启动，往往这种操作都不够及时。3、如果服务器宕机或需要重启，我们则还是需要连入shell进行启动。为了解决这些问题，我们需要有一个程序来监听 ASP.NET Core 应用程序的状况。并在应用程序停止运行的时候立即重新启动。 安装与配置1、安装Python包管理工具(easy_install) 1yum install python-setuptools 2、安装Supervisor 1easy_install supervisor 3、配置Supervisor应用守护a) 通过运行echo_supervisord_conf程序生成supervisor的初始化配置文件，如下所示：12mkdir /etc/supervisorecho_supervisord_conf &gt; /etc/supervisor/supervisord.conf 然后查看路径下的supervisord.conf。在文件尾部添加如下配置。 … ;[include];files = relative/directory/*.ini ;conf.d 为配置表目录的文件夹，需要手动创建[include]files = conf.d/*.conf b) 为你的程序创建一个.conf文件，放在目录”/etc/supervisor/conf.d/“下。 [program:MGToastServer] ;程序名称，终端控制时需要的标识command=dotnet MGToastServer.dll ; 运行程序的命令directory=/root/文档/toastServer/ ; 命令执行的目录autorestart=true ; 程序意外退出是否自动重启stderr_logfile=/var/log/MGToastServer.err.log ; 错误日志文件stdout_logfile=/var/log/MGToastServer.out.log ; 输出日志文件environment=ASPNETCORE_ENVIRONMENT=Production ; 进程环境变量user=root ; 进程执行的用户身份stopsignal=INTc) 运行supervisord，查看是否生效 supervisord -c /etc/supervisor/supervisord.confps -ef | grep MGToastServer成功后的效果： ps 如果服务已启动，修改配置文件可用“supervisorctl reload”命令来使其生效 4、配置Supervisor开机启动a) 新建一个“supervisord.service”文件 dservice for systemd (CentOS 7.0+)by ET-CS (https://github.com/ET-CS)[Unit]Description=Supervisor daemon [Service]Type=forkingExecStart=/usr/bin/supervisord -c /etc/supervisor/supervisord.confExecStop=/usr/bin/supervisorctl shutdownExecReload=/usr/bin/supervisorctl reloadKillMode=processRestart=on-failureRestartSec=42s [Install]WantedBy=multi-user.targetb) 将文件拷贝至”/usr/lib/systemd/system/supervisord.service” c) 执行命令 systemctl enable supervisordd) 执行命令来验证是否为开机启动 systemctl is-enabled supervisord 配置完成啦. 常用的相关管理命令123456supervisorctl restart &lt;application name&gt; ;重启指定应用supervisorctl stop &lt;application name&gt; ;停止指定应用supervisorctl start &lt;application name&gt; ;启动指定应用supervisorctl restart all ;重启所有应用supervisorctl stop all ;停止所有应用supervisorctl start all ;启动所有应用]]></content>
      <tags>
        <tag>ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[winsw说明]]></title>
    <url>%2F2019%2F11%2F12%2Fwinsm%2F</url>
    <content type="text"><![CDATA[一、WinSW介绍官方介绍如下： WinSW is an executable binary, which can be used to wrap and manage a custom process as a Windows service. 现实生活中，我们使用windows系统的电脑的时候，可能会遇到这么一种情况：想把一些应用程序添加为开机启动项。对于有图形界面的应用程序，一般不存在问题。但是如果想运行命令行应用程序，就不是那么方便了。一种笨办法就是写个bat，放到启动文件夹里，就可以开机启动了。开机之后，你就会发现，这样会一直显示着一个CMD窗口，而且这个窗口不能关，关了程序就停了。 其实Windows系统自带后台程序管理的功能，也就是我们经常用到的服务。但是Windows的服务只有程序的开发者在写程序的时候引用到这个功能，我们才能利用服务来控制程序的启动和关闭。对于一般的命令行程序来说，没办法利用服务。 今天要介绍的WinSW，它就是一个可以将Windows上的任何一个程序注册为服务的工具。同样也可以进行卸载该服务。 二、WinSW使用1、工具下载这个工具可以在GitHub上【https://github.com/kohsuke/winsw/releases】进行下载。当然，在GitHub上也可以获取到工具的源码【https://github.com/kohsuke/winsw】。 下载完之后最好把文件改成一个比较短小的名字，例如：WinSW.exe 方便后面输入命令时使用。 2、修改配置文件我们需要编写一个和程序同名的XML文件作为WinSW的配置文件。大体的格式如下： 这里只是简单介绍使用WinSW的流程，配置项实际也不止那么几个，在第三部分有关于配置文件的详细解释。 3、注册服务配置文件编写完之后，将配置文件与WinSW.exe放在同一目录中。注意对应WinSW.exe的配置文件名称应该是WinSW.xml。此时，WinSW.exe、WinSW.xml以及你的应用程序应该都是在同一目录中。然后用管理员权限打开一个命令提示符窗口，cd进入到应用程序所在目录，可以通过输入下面的命令来进行控制应用程序对应的服务： winsw install 安装服务 winsw uninstall 卸载服务 winsw start 开启服务 winsw stop 停止服务 winsw restart 重新启动服务 winsw status 检查服务的当前状态 安装服务命令执行后，如果返回值为0，就表示服务已经安装成功。此时在windows服务的窗口，就能看到你刚才安装的服务了。 三、WinSW配置说明（翻译xmlConfigFile.md）1、配置文件的文件结构配置文件是一个XML格式文件，其根元素必须是“service”节点。 2、配置文件中的环境变量表达式XML配置文件中，可以包含形如“%Name%”的环境变量表达式。如果发现这种情况，将会自动被变量的实际值替换掉。如果引用未定义的环境变量，则不会进行替换。 此外，服务包装器本身定义了一个名为“BASE”的环境变量，它指向一个包含重命名为“winsw.exe”的文件的目录。这在引用同一目录中的其他文件的时候是很有用的。由于这本身就是一个环境变量，所以这个值也可以从服务包装器启动的子进程中访问。 3、配置项说明（1）id 指定在Windows系统内部使用的识别服务的ID。在系统中安装的所有服务中，这必须是唯一的，它应该完全由字母数字字符组成。 （2）name 服务的简短名称，它可以包含空格和其他字符。尽量简短，就像“id”一样，在系统的所有服务名称中，也要保持唯一。 （3）description 该服务可读描述。当选中该服务时，它将显示在Windows服务管理器中。 （4）executable 该元素指定要启动的可执行文件。它可以是绝对路径，也可以指定可执行文件的名称，然后从环境变量“PATH”中搜索（需要注意的是，服务经常在不同的用户账户中运行，因此它可能需要有不同于你设置在环境变量Path中的路径）。 （5）startmode 该元素指定Windows服务的启动模式。它可以是下列值之一：开机、系统、自动或手动。有关详细信息，请参阅MSDN【https://msdn.microsoft.com/en-us/library/aa384896%28v=vs.85%29.aspx】。默认值是“Automatic”。 （6）delayedAutoStart 这个布尔选项允许在定义“自动”启动模式时延时启动。关于延时启动模式，可参阅【https://blogs.technet.microsoft.com/askperf/2008/02/02/ws2008-startup-processes-and-delayed-automatic-start】。 请注意，延时启动模式在早于Windows 7和Windows Server 2008的操作系统中可能失效。在这种情况下，Windows服务安装可能会失败。 （7）depend 指定该服务所依赖的其他服务的id。当服务“X”依赖于服务“Y”时，“X”只能在“Y”运行后运行。可以使用多个元素来指定多个依赖项。 （8）logging 关于服务进程的日志以及错误信息，有单独的一个配置说明文档【WinSW Logging and Error Reporting】，咱们下次再详细说。 （9）argument 该元素指定要传递给可执行文件的参数。 如果有必要，Winsw会给每一个参数外加引号（“”），所以为了避免双重引号，尽量不要在参数中使用引号。 为了向后兼容，可以使用“arguments”来指定单个元素中的整个命令行。 （10）stopargument/stopexecutable 请求停止服务时，winsw通过调用终止进程的API函数来立即终结服务。然而，如果存在“stopargument”元素，winsw将通过使用”stopargument“作为参数，来启动“executable“元素（或者是”stopexecutable“元素）中配置的进程，来代替调用终止进程的API函数。期望通过这种方式来优雅的关闭服务进程。 然后，Winsw将等待两个进程自行退出，然后向Windows报告该服务已经终止。 当你使用“stopargument”元素时，你必须使用“startargument”元素代替“argument”元素。参见下面的完整示例： catalina.sh jpda run catalina.sh stop 注意，元素的名称是“startargument”，而不是“startarguments”。因此，要指定多个参数，你必须指定多个元素。 （11）stoptimeout 当服务被要求停止时，winsw首先尝试调用GenerateConsoleCtrlEvent 方法（类似于Ctrl+C），然后等待长达15秒的时间，让进程自行退出。 如果这样做了，进程关闭还是失败了（或者如果进程没有控制台）， 然后winsw会调用终止进程的API函数来立即终止服务。 这个可选元素允许您改变这个“15秒”的值，这样您就可以控制winsw等待服务进程自行关闭的时间。 如何指定时间期限，可参考下面的“onfailure”元素的设置： 10sec （12）env 如果有必要，可以使用这个可多次指定的可选元素，为子进程设置环境变量。其语法是: （13）interactive 如果指定了这个可选的元素，那么该服务将被允许与桌面交互，比如显示一个新的窗口和对话框。 如果你的程序需要GUI，那么设置如下： 请注意，自从引入UAC（Windows Vista及之后的版本）以来，服务不再被允许与桌面交互。 在这些操作系统中，所有这一切都是为了允许用户切换到一个单独的窗口来与服务交互。 （14）beeponshutdown 这个可选元素是为了在服务关闭时发出简单的音调。 这个特性应该只用于调试，因为一些操作系统和硬件不支持这种功能。 （15）download 这个可选元素可以多次指定，让服务包装器从URL检索资源，并将其作为文件放置在本地。这个操作是在服务启动时运行的，在“executable”指定的应用程序启动之前。 对于需要身份验证的服务器，必须根据认证的类型指定一些参数。只有基本身份验证需要额外的子参数。支持的身份验证类型是: none：默认类型，不能指定 sspi：微软认证，包括Kerberos、NTLM等。 basic：基本身份认证，子参数包括： 1）user=“UserName” 2）password=“Password” 3）unsecureAuth=“true”：default=“false” 当传输协议是未加密的HTTP数据传输时，参数“unsecureAuth”才生效。这是一个安全漏洞，因为凭证是用明文发送的！对于SSPI认证，这是不相关的，因为身份验证令牌是加密的。 对于使用HTTPS传输协议的目标服务器这是必须的，因为服务器发出的CA证书是客户端信任的。这通常是服务器在Internet上的情况。当一个组织在内网中使用自发布的CA时，情况可能不是这样。在这种情况下，有必要将CA导入到Windows客户端的证书MMC。可以看一下微软的说明（https://technet.microsoft.com/en-us/librar/cc754841.aspx）。自发布CA必须被导入到计算机的受信任的根证书颁发机构。 默认情况下，如果操作失败（例如，无效的下载地址），“download”命令也不会在服务启动时失败。为了在这种情况下强制下载失败，可以指定“failOnError”布尔属性。示例如下： 这是开发自动更新服务的另一个有用的构建块。 （16）onfailure 这个可选的可重复元素控制了winsw启动的进程失败后的行为（例如，执行带有非零退出码的退出操作）。 例如，上面的配置使服务在第一次故障后10秒内重新启动，在第二次失败后20秒重新启动，如果服务再次失败，Windows将重新启动。 每个元素都包含一个强制的“action”属性，它控制着Windows SCM将要做什么，以及可选的“延迟”属性，它控制着延迟，直到采取行动为止。“action”属性的值包含以下几种： restart：重启服务 reboot：重启系统 none：什么也不做，就让服务那么停着 延迟属性的可能后缀是sec/secs/min/mins/hours/day/days。如果未设置，延迟属性默认为0。 如果服务持续失败的次数超出了配置的“onfailure”的数量，那么最后的操作将会被重复。因此，如果只是想要自动重启服务，只需指定一个“onfailure”元素即可： （17）resetfailure 这个可选元素控制了Windows SCM重新设置故障计数的时间。 例如，如果指定，并且您的服务持续运行超过一个小时，那么故障计数将重置为零。 这会影响故障操作的行为（见上面的“onfailure”）。 换句话说，这是你认为服务已经成功运行的持续时间。 默认值为1天。 （18）Service account 有可能需要指定服务运行所需要的的useraccount（和密码）。要做到这一点，可以按照下面的方法指定一个“serviceaccount”元素： YOURDOMAIN useraccount Pa55w0rd true “”是可选的。如果设置为“true”，则会自动给上面列出的用户设置“Allow Log On As A Service”的权限。 可以使用（组）管理服务帐户 附加’$’到帐户名称，并删除’password’元素： YOURDOMAIN gmsa_account$ true （19）Working directory 有些服务需要使用指定的工作目录运行。 要做到这一点，要指定一个像这样的“workingdirectory”元素： C:\application （20）priority 可选地指定服务流程的调度优先级（类似于Unix）。可能的值有“idle”、“belownormal”、“normal”、“abovenormal”、“high”、“realtime”（大小写不敏感）。 idle 指定高于正常值的优先级会产生意想不到的后果。请参阅MSDN文章ProcessPriorityClass Enumeration来了解详细信息。 这个特性主要是为了在较低的优先级上启动一个进程，以避免干扰计算机的交互使用。 （21）stopparentprocessfirst 可选地指定服务关闭的顺序。 如果“true”，父进程首先关闭。 当主进程是一个控制台时，这是很有用的，它可以响应Ctrl+C命令，并优雅地关闭子进程。 true]]></content>
      <tags>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python 实战 grpc]]></title>
    <url>%2F2019%2F11%2F08%2Fgrpc%2F</url>
    <content type="text"><![CDATA[grpc 的基础: protobufgrpc 使用 protobuf 进行数据传输. protobuf 是一种数据交换格式, 由三部分组成: proto 文件: 使用的 proto 语法的文本文件, 用来定义数据格式proto语法现在有 proto2 和 proto3 两个版本, 推荐使用 proto3, 更加简洁明了 123456789101112131415161718// [python quickstart](https://grpc.io/docs/quickstart/python.html#run-a-grpc-application)// python -m grpc_tools.protoc --python_out=. --grpc_python_out=. -I. helloworld.proto// helloworld.protosyntax = &quot;proto3&quot;;service Greeter &#123; rpc SayHello(HelloRequest) returns (HelloReply) &#123;&#125; rpc SayHelloAgain(HelloRequest) returns (HelloReply) &#123;&#125;&#125;message HelloRequest &#123; string name = 1;&#125;message HelloReply &#123; string message = 1;&#125; protoc: protobuf 编译器(compile), 将 proto 文件编译成不同语言的实现, 这样不同语言中的数据就可以和 protobuf 格式的数据进行交互 protobuf 运行时(runtime): protobuf 运行时所需要的库, 和 protoc 编译生成的代码进行交互 使用 protobuf 的过程: 编写 proto 文件 -&gt; 使用 protoc 编译 -&gt; 添加 protobuf 运行时 -&gt; 项目中集成 更新 protobuf 的过程: 修改 proto 文件 -&gt; 使用 protoc 重新编译 -&gt; 项目中修改集成的地方 grpc helloworld: python 实战 grpc 环境配置上面已经定义好了 grpc helloworld demo 所需的 proto 文件, 现在来具体看看 python 怎么一步步把 grpc helloworld 的环境搭建起来: protobuf 运行时(runtime)这一步很简单, 安装 grpc 相关的 python 模块(module) 即可 1pip install grpcio 使用 protoc 编译 proto 文件, 生成 python 语言的实现 12345678910# 安装 python 下的 protoc 编译器pip install grpcio-tools# 编译 proto 文件python -m grpc_tools.protoc --python_out=. --grpc_python_out=. -I. helloworld.protopython -m grpc_tools.protoc: python 下的 protoc 编译器通过 python 模块(module) 实现, 所以说这一步非常省心--python_out=. : 编译生成处理 protobuf 相关的代码的路径, 这里生成到当前目录--grpc_python_out=. : 编译生成处理 grpc 相关的代码的路径, 这里生成到当前目录-I. helloworld.proto : proto 文件的路径, 这里的 proto 文件在当前目录 编译后生成的代码: helloworld_pb2.py: 用来和 protobuf 数据进行交互 helloworld_pb2_grpc.py: 用来和 grpc 进行交互 最后一步, 编写 helloworld 的 grpc 实现: 服务器端: helloworld_grpc_server.py 1234567891011121314151617181920212223242526272829from concurrent import futuresimport timeimport grpcimport helloworld_pb2import helloworld_pb2_grpc# 实现 proto 文件中定义的 GreeterServicerclass Greeter(helloworld_pb2_grpc.GreeterServicer): # 实现 proto 文件中定义的 rpc 调用 def SayHello(self, request, context): return helloworld_pb2.HelloReply(message = &apos;hello &#123;msg&#125;&apos;.format(msg = request.name)) def SayHelloAgain(self, request, context): return helloworld_pb2.HelloReply(message=&apos;hello &#123;msg&#125;&apos;.format(msg = request.name))def serve(): # 启动 rpc 服务 server = grpc.server(futures.ThreadPoolExecutor(max_workers=10)) helloworld_pb2_grpc.add_GreeterServicer_to_server(Greeter(), server) server.add_insecure_port(&apos;[::]:50051&apos;) server.start() try: while True: time.sleep(60*60*24) # one day in seconds except KeyboardInterrupt: server.stop(0)if __name__ == &apos;__main__&apos;: serve() 客户端: helloworld_grpc_client.py 12345678910111213141516import grpcimport helloworld_pb2import helloworld_pb2_grpcdef run(): # 连接 rpc 服务器 channel = grpc.insecure_channel(&apos;localhost:50051&apos;) # 调用 rpc 服务 stub = helloworld_pb2_grpc.GreeterStub(channel) response = stub.SayHello(helloworld_pb2.HelloRequest(name=&apos;czl&apos;)) print(&quot;Greeter client received: &quot; + response.message) response = stub.SayHelloAgain(helloworld_pb2.HelloRequest(name=&apos;daydaygo&apos;)) print(&quot;Greeter client received: &quot; + response.message)if __name__ == &apos;__main__&apos;: run() 运行 python helloworld_grpc_server.py 和 python helloworld_grpc_client.py, 就可以看到效果了 grpc basic: 4 种通信方式helloworld 使用了最简单的 grpc 通信方式: 类似 http 协议的一次 request+response. 根据不同的业务场景, grpc 支持 4 种通信方式: 客服端一次请求, 服务器一次应答 客服端一次请求, 服务器多次应答(流式) 客服端多次请求(流式), 服务器一次应答 客服端多次请求(流式), 服务器多次应答(流式) 官方提供了一个 route guide service 的 demo, 应用到了这 4 种通信方式, 具体的业务如下: 数据源: json 格式的数据源, 存储了很多地点, 每个地点由经纬度(point)和地名(location)组成 通信方式 1: 客户端请求一个地点是否在数据源中 通信方式 2: 客户端指定一个矩形范围(矩形的对角点坐标), 服务器返回这个范围内的地点信息 通信方式 3: 客户端给服务器发送多个地点信息, 服务器返回汇总信息(summary) 通信方式 4: 客户端和服务器使用地点信息 聊天(chat) 对应的 proto 文件: routeguide.proto: 123456789101112131415161718192021222324252627282930313233343536373839404142// [python quickstart](https://grpc.io/docs/quickstart/python.html#run-a-grpc-application)// python -m grpc_tools.protoc --python_out=. --grpc_python_out=. -I. routeguide.protosyntax = &quot;proto3&quot;;service RouteGuide &#123; // simple rpc rpc GetFeature(Point) returns (Feature) &#123;&#125; // server2client stream rpc rpc ListFeature(Rectangle) returns (stream Feature) &#123;&#125; // client2server stream rpc rpc RecordRoute(stream Point) returns (RouteSummary) &#123;&#125; // stream rpc rpc RouteChat(stream RouteNote) returns (stream RouteNote) &#123;&#125;&#125;message Point &#123; int32 latitude = 1; int32 longitude = 2;&#125;message Rectangle &#123; Point lo = 1; Point hi = 2;&#125;message Feature &#123; string name = 1; Point location = 2;&#125;message RouteNote &#123; Point location = 1; string message = 2;&#125;message RouteSummary &#123; int32 point_count = 1; int32 feature_count = 2; int32 distance = 3; int32 elapsed_time = 4;&#125; 完整的服务器端代码: routeguide_grpc_server.py: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102from concurrent import futuresimport mathimport timeimport grpcimport routeguide_pb2import routeguide_pb2_grpcimport routeguide_dbdef get_feature(db, point): for feature in db: if feature.location == point: return feature return Nonedef get_distance(start, end): &quot;&quot;&quot;Distance between two points.&quot;&quot;&quot; coord_factor = 10000000.0 lat_1 = start.latitude / coord_factor lat_2 = end.latitude / coord_factor lon_1 = start.longitude / coord_factor lon_2 = end.longitude / coord_factor lat_rad_1 = math.radians(lat_1) lat_rad_2 = math.radians(lat_2) delta_lat_rad = math.radians(lat_2 - lat_1) delta_lon_rad = math.radians(lon_2 - lon_1) # Formula is based on http://mathforum.org/library/drmath/view/51879.html a = (pow(math.sin(delta_lat_rad / 2), 2) + (math.cos(lat_rad_1) * math.cos(lat_rad_2) * pow( math.sin(delta_lon_rad / 2), 2))) c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a)) R = 6371000 # metres return R * cclass RouteGuide(routeguide_pb2_grpc.RouteGuideServicer): def __init__(self): self.db = routeguide_db.read_routeguide_db() def GetFeature(self, request, context): feature = get_feature(self.db, request) if feature is None: return routeguide_pb2.Feature(name = &apos;&apos;, location = request) else: return feature def ListFeature(self, request, context): left = min(request.lo.longitude, request.hi.longitude) right = max(request.lo.longitude, request.hi.longitude) top = max(request.lo.latitude, request.hi.latitude) bottom = min(request.lo.latitude, request.hi.latitude) for feature in self.db: if (feature.location.longitude &gt;= left and feature.location.longitude &lt;= right and feature.location.latitude &gt;= bottom and feature.location.latitude &lt;= top): yield feature def RecordRoute(self, request_iterator, context): point_count = 0 feature_count = 1 distance = 0.0 prev_point = None start_time = time.time() for point in request_iterator: point_count += 1 if get_feature(self.db, point): feature_count += 1 if prev_point: distance += get_distance(prev_point, point) prev_point = point elapsed_time = time.time() - start_time return routeguide_pb2.RouteSummary( point_count = point_count, feature_count = feature_count, distance = int(distance), elapsed_time = int(elapsed_time) ) def RouteChat(self, request_iterator, context): prev_notes = [] for new_note in request_iterator: for prev_note in prev_notes: if prev_note.location == new_note.location: yield prev_note prev_notes.append(new_note)def serve(): server = grpc.server(futures.ThreadPoolExecutor(max_workers=10)) routeguide_pb2_grpc.add_RouteGuideServicer_to_server(RouteGuide(), server) server.add_insecure_port(&apos;[::]:50051&apos;) server.start() try: while True: time.sleep(60*60*24) # one day in seconds except KeyboardInterrupt: server.stop(0)if __name__ == &apos;__main__&apos;: serve() 完整的客户端代码: routeguide_grpc_client.py: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475import grpcimport routeguide_pb2import routeguide_pb2_grpcimport routeguide_dbimport randomdef get_feature(feature): if not feature.location: print(&quot;Server returned incomplete feature&quot;) return if feature.name: print(&quot;Feature called &#123;name&#125; at &#123;location&#125;&quot;.format(name = feature.name, location = feature.location)) else: print(&quot;Found no feature at &#123;location&#125;&quot;.format(location = feature.location))def generate_route(feature_list): for _ in range(0, 20): random_feature = feature_list[random.randint(0, len(feature_list) - 1)] print(&quot;random feature &#123;name&#125; at &#123;location&#125;&quot;.format( name=random_feature.name, location=random_feature.location)) yield random_feature.locationdef make_route_note(message, latitude, longitude): return routeguide_pb2.RouteNote( message=message, location=routeguide_pb2.Point(latitude=latitude, longitude=longitude))def generate_route_note(): msgs = [ make_route_note(&apos;msg 1&apos;, 0, 0), make_route_note(&apos;msg 2&apos;, 1, 0), make_route_note(&apos;msg 3&apos;, 0, 1), make_route_note(&apos;msg 4&apos;, 0, 0), make_route_note(&apos;msg 5&apos;, 1, 1), ] for msg in msgs: print(&quot;send message &#123;message&#125; location &#123;location&#125;&quot;.format(message = msg.message, location = msg.location)) yield msgdef run(): channel = grpc.insecure_channel(&apos;localhost:50051&apos;) stub = routeguide_pb2_grpc.RouteGuideStub(channel) print(&quot;-------------- GetFeature --------------&quot;) response = stub.GetFeature(routeguide_pb2.Point(latitude=409146138, longitude=-746188906)) get_feature(response) response = stub.GetFeature(routeguide_pb2.Point(latitude=0, longitude=-0)) get_feature(response) print(&quot;-------------- ListFeatures --------------&quot;) response = stub.ListFeature(routeguide_pb2.Rectangle( lo = routeguide_pb2.Point(latitude=400000000, longitude=-750000000), hi=routeguide_pb2.Point(latitude=420000000, longitude=-730000000) )) for feature in response: print(&quot;Feature called &#123;name&#125; at &#123;location&#125;&quot;.format(name=feature.name, location=feature.location)) print(&quot;-------------- RecordRoute --------------&quot;) feature_list = routeguide_db.read_routeguide_db() route_iterator = generate_route(feature_list) response = stub.RecordRoute(route_iterator) print(&quot;point count: &#123;point_count&#125; feature count: &#123;feature_count&#125; distance: &#123;distance&#125; elapsed time:&#123;elapsed_time&#125;&quot;.format( point_count = response.point_count, feature_count = response.feature_count, distance = response.distance, elapsed_time = response.elapsed_time )) print(&quot;-------------- RouteChat --------------&quot;) response = stub.RouteChat(generate_route_note()) for msg in response: print(&quot;recived message &#123;message&#125; location &#123;location&#125;&quot;.format( message=msg.message, location=msg.location))if __name__ == &apos;__main__&apos;: run()]]></content>
      <tags>
        <tag>Python</tag>
        <tag>grpc</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[rtp.md]]></title>
    <url>%2F2019%2F11%2F06%2Frtp-md%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[frp 源码阅读与分析(二)：TCP内网穿透的实现]]></title>
    <url>%2F2019%2F10%2F10%2Ffrp-2%2F</url>
    <content type="text"><![CDATA[frpscmd/frps/main.go 是frps的入口处，我们从这里开始，main 函数的主体： 12345func main() &#123; crypto.DefaultSalt = "frp" Execute()&#125; 因此我们需要看到 Execute() 函数的内容，其实它是使用了 cobra这个库，所以实际的入口在 123456789101112131415161718192021222324252627282930313233var rootCmd = &amp;cobra.Command&#123; Use: "frps", Short: "frps is the server of frp (https://github.com/fatedier/frp)", RunE: func(cmd *cobra.Command, args []string) error &#123; if showVersion &#123; fmt.Println(version.Full()) return nil &#125; var err error if cfgFile != "" &#123; var content string content, err = config.GetRenderedConfFromFile(cfgFile) if err != nil &#123; return err &#125; g.GlbServerCfg.CfgFile = cfgFile err = parseServerCommonCfg(CfgFileTypeIni, content) &#125; else &#123; err = parseServerCommonCfg(CfgFileTypeCmd, "") &#125; if err != nil &#123; return err &#125; err = runServer() if err != nil &#123; fmt.Println(err) os.Exit(1) &#125; return nil &#125;,&#125; 最终，也就是 runServer() 这个函数： 123456789101112func runServer() (err error) &#123; log.InitLog(g.GlbServerCfg.LogWay, g.GlbServerCfg.LogFile, g.GlbServerCfg.LogLevel, g.GlbServerCfg.LogMaxDays) svr, err := server.NewService() if err != nil &#123; return err &#125; log.Info("Start frps success") server.ServerService = svr svr.Run() return&#125; svr.Run()，其中的 svr 是来自 server.NewService()，仔细看一下，server.NewService() 其实就是初始化了一大堆东西。我们直接看 svr.Run() 做了什么： 12345678910111213func (svr *Service) Run() &#123; if svr.rc.NatHoleController != nil &#123; go svr.rc.NatHoleController.Run() &#125; if g.GlbServerCfg.KcpBindPort &gt; 0 &#123; go svr.HandleListener(svr.kcpListener) &#125; go svr.HandleListener(svr.websocketListener) go svr.HandleListener(svr.tlsListener) svr.HandleListener(svr.listener)&#125; 可以看到，最后frps会执行到 svr.HandleListener(svr.listener)，前面的都是什么 nat hole punching, kcp, websocket,tls等等，我们不看。直接看tcp。 12345678910111213141516func (svr *Service) HandleListener(l frpNet.Listener) &#123; // Listen for incoming connections from client. for &#123; c, err := l.Accept() if err != nil &#123; log.Warn("Listener for incoming connections from client closed") return &#125; c = frpNet.CheckAndEnableTLSServerConn(c, svr.tlsConfig) // Start a new goroutine for dealing connections. go func(frpConn frpNet.Conn) &#123; ... &#125; &#125;&#125; 这里就是监听之后，每来一个新的连接，就起一个goroutine去处理，也就是 go func()... 这一段，然后我们看看内容： 123456789101112131415161718192021222324252627282930313233switch m := rawMsg.(type) &#123;case *msg.Login: err = svr.RegisterControl(conn, m) // If login failed, send error message there. // Otherwise send success message in control's work goroutine. if err != nil &#123; conn.Warn("%v", err) msg.WriteMsg(conn, &amp;msg.LoginResp&#123; Version: version.Full(), Error: err.Error(), &#125;) conn.Close() &#125;case *msg.NewWorkConn: svr.RegisterWorkConn(conn, m)case *msg.NewVisitorConn: if err = svr.RegisterVisitorConn(conn, m); err != nil &#123; conn.Warn("%v", err) msg.WriteMsg(conn, &amp;msg.NewVisitorConnResp&#123; ProxyName: m.ProxyName, Error: err.Error(), &#125;) conn.Close() &#125; else &#123; msg.WriteMsg(conn, &amp;msg.NewVisitorConnResp&#123; ProxyName: m.ProxyName, Error: "", &#125;) &#125;default: log.Warn("Error message type for the new connection [%s]", conn.RemoteAddr().String()) conn.Close()&#125; 这就是服务端启动之后，卡住的地方了。客户端建立连接之后，会发送一个消息，它的类型可能是 msg.Login, msg.NewWorkConn, msg.NewVisitorConn。上一篇我们说了，visitor是用于stcp也就是端对端加密通信的，我们不看。workConn就是用于转发流量的，Login就是新的客户端连上去之后进行启动。 frpc同样，我们从 cmd/frpc/main.go 看起： 12345func main() &#123; crypto.DefaultSalt = "frp" sub.Execute()&#125; 跳转到sub.Execute()： 123456789101112131415161718192021222324var rootCmd = &amp;cobra.Command&#123; Use: "frpc", Short: "frpc is the client of frp (https://github.com/fatedier/frp)", RunE: func(cmd *cobra.Command, args []string) error &#123; if showVersion &#123; fmt.Println(version.Full()) return nil &#125; // Do not show command usage here. err := runClient(cfgFile) if err != nil &#123; fmt.Println(err) os.Exit(1) &#125; return nil &#125;,&#125;func Execute() &#123; if err := rootCmd.Execute(); err != nil &#123; os.Exit(1) &#125;&#125; 然后我们看 runClient 函数： 123456789101112131415161718192021func runClient(cfgFilePath string) (err error) &#123; var content string content, err = config.GetRenderedConfFromFile(cfgFilePath) if err != nil &#123; return &#125; g.GlbClientCfg.CfgFile = cfgFilePath err = parseClientCommonCfg(CfgFileTypeIni, content) if err != nil &#123; return &#125; pxyCfgs, visitorCfgs, err := config.LoadAllConfFromIni(g.GlbClientCfg.User, content, g.GlbClientCfg.Start) if err != nil &#123; return err &#125; err = startService(pxyCfgs, visitorCfgs) return&#125; 基本上就是解析配置文件（因为frpc启动的时候要一个配置文件），然后执行 startService： 1234567891011121314151617181920212223242526272829303132func startService(pxyCfgs map[string]config.ProxyConf, visitorCfgs map[string]config.VisitorConf) (err error) &#123; log.InitLog(g.GlbClientCfg.LogWay, g.GlbClientCfg.LogFile, g.GlbClientCfg.LogLevel, g.GlbClientCfg.LogMaxDays) if g.GlbClientCfg.DnsServer != "" &#123; s := g.GlbClientCfg.DnsServer if !strings.Contains(s, ":") &#123; s += ":53" &#125; // Change default dns server for frpc net.DefaultResolver = &amp;net.Resolver&#123; PreferGo: true, Dial: func(ctx context.Context, network, address string) (net.Conn, error) &#123; return net.Dial("udp", s) &#125;, &#125; &#125; svr, errRet := client.NewService(pxyCfgs, visitorCfgs) if errRet != nil &#123; err = errRet return &#125; // Capture the exit signal if we use kcp. if g.GlbClientCfg.Protocol == "kcp" &#123; go handleSignal(svr) &#125; err = svr.Run() if g.GlbClientCfg.Protocol == "kcp" &#123; &lt;-kcpDoneCh &#125; return&#125; 同样的，执行 client.NewService 之后执行 svr.Run()，我们看看 svr.Run() 是什么： 1234567891011121314151617181920212223242526272829303132333435363738func (svr *Service) Run() error &#123; // first login for &#123; conn, session, err := svr.login() if err != nil &#123; log.Warn("login to server failed: %v", err) // if login_fail_exit is true, just exit this program // otherwise sleep a while and try again to connect to server if g.GlbClientCfg.LoginFailExit &#123; return err &#125; else &#123; time.Sleep(10 * time.Second) &#125; &#125; else &#123; // login success ctl := NewControl(svr.runId, conn, session, svr.pxyCfgs, svr.visitorCfgs) ctl.Run() svr.ctlMu.Lock() svr.ctl = ctl svr.ctlMu.Unlock() break &#125; &#125; go svr.keepControllerWorking() if g.GlbClientCfg.AdminPort != 0 &#123; err := svr.RunAdminServer(g.GlbClientCfg.AdminAddr, g.GlbClientCfg.AdminPort) if err != nil &#123; log.Warn("run admin server error: %v", err) &#125; log.Info("admin server listen on %s:%d", g.GlbClientCfg.AdminAddr, g.GlbClientCfg.AdminPort) &#125; &lt;-svr.closedCh return nil&#125; 可以看到，客户端启动之后，就是一个 for 循环，写入 login 信息，也就是刚才 frps 里的 msg.loginMsg，然后起一个 goroutine 执行 keepControllerWorking()，之后主 goroutine 就阻塞在 &lt;-svr.closedCh。看看 keepControllerWorking() 的内容： 12345678910111213141516171819202122232425262728293031323334func (svr *Service) keepControllerWorking() &#123; maxDelayTime := 20 * time.Second delayTime := time.Second for &#123; &lt;-svr.ctl.ClosedDoneCh() if atomic.LoadUint32(&amp;svr.exit) != 0 &#123; return &#125; for &#123; log.Info("try to reconnect to server...") conn, session, err := svr.login() if err != nil &#123; log.Warn("reconnect to server error: %v", err) time.Sleep(delayTime) delayTime = delayTime * 2 if delayTime &gt; maxDelayTime &#123; delayTime = maxDelayTime &#125; continue &#125; // reconnect success, init delayTime delayTime = time.Second ctl := NewControl(svr.runId, conn, session, svr.pxyCfgs, svr.visitorCfgs) ctl.Run() svr.ctlMu.Lock() svr.ctl = ctl svr.ctlMu.Unlock() break &#125; &#125;&#125; 基本上就是一个循环，里面最终是为了成功连接然后执行 ctl.Run()： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135func (ctl *Control) Run() &#123; go ctl.worker() // start all proxies ctl.pm.Reload(ctl.pxyCfgs) // start all visitors go ctl.vm.Run() return&#125;// If controler is notified by closedCh, reader and writer and handler will exitfunc (ctl *Control) worker() &#123; go ctl.msgHandler() go ctl.reader() go ctl.writer() select &#123; case &lt;-ctl.closedCh: // close related channels and wait until other goroutines done close(ctl.readCh) ctl.readerShutdown.WaitDone() ctl.msgHandlerShutdown.WaitDone() close(ctl.sendCh) ctl.writerShutdown.WaitDone() ctl.pm.Close() ctl.vm.Close() close(ctl.closedDoneCh) if ctl.session != nil &#123; ctl.session.Close() &#125; return &#125;&#125;// msgHandler handles all channel events and do corresponding operations.func (ctl *Control) msgHandler() &#123; defer func() &#123; if err := recover(); err != nil &#123; ctl.Error("panic error: %v", err) ctl.Error(string(debug.Stack())) &#125; &#125;() defer ctl.msgHandlerShutdown.Done() hbSend := time.NewTicker(time.Duration(g.GlbClientCfg.HeartBeatInterval) * time.Second) defer hbSend.Stop() hbCheck := time.NewTicker(time.Second) defer hbCheck.Stop() ctl.lastPong = time.Now() for &#123; select &#123; case &lt;-hbSend.C: // send heartbeat to server ctl.Debug("send heartbeat to server") ctl.sendCh &lt;- &amp;msg.Ping&#123;&#125; case &lt;-hbCheck.C: if time.Since(ctl.lastPong) &gt; time.Duration(g.GlbClientCfg.HeartBeatTimeout)*time.Second &#123; ctl.Warn("heartbeat timeout") // let reader() stop ctl.conn.Close() return &#125; case rawMsg, ok := &lt;-ctl.readCh: if !ok &#123; return &#125; switch m := rawMsg.(type) &#123; case *msg.ReqWorkConn: go ctl.HandleReqWorkConn(m) case *msg.NewProxyResp: ctl.HandleNewProxyResp(m) case *msg.Pong: ctl.lastPong = time.Now() ctl.Debug("receive heartbeat from server") &#125; &#125; &#125;&#125;// reader read all messages from frps and send to readChfunc (ctl *Control) reader() &#123; defer func() &#123; if err := recover(); err != nil &#123; ctl.Error("panic error: %v", err) ctl.Error(string(debug.Stack())) &#125; &#125;() defer ctl.readerShutdown.Done() defer close(ctl.closedCh) encReader := crypto.NewReader(ctl.conn, []byte(g.GlbClientCfg.Token)) for &#123; if m, err := msg.ReadMsg(encReader); err != nil &#123; if err == io.EOF &#123; ctl.Debug("read from control connection EOF") return &#125; else &#123; ctl.Warn("read error: %v", err) ctl.conn.Close() return &#125; &#125; else &#123; ctl.readCh &lt;- m &#125; &#125;&#125;// writer writes messages got from sendCh to frpsfunc (ctl *Control) writer() &#123; defer ctl.writerShutdown.Done() encWriter, err := crypto.NewWriter(ctl.conn, []byte(g.GlbClientCfg.Token)) if err != nil &#123; ctl.conn.Error("crypto new writer error: %v", err) ctl.conn.Close() return &#125; for &#123; if m, ok := &lt;-ctl.sendCh; !ok &#123; ctl.Info("control writer is closing") return &#125; else &#123; if err := msg.WriteMsg(encWriter, m); err != nil &#123; ctl.Warn("write message to control connection error: %v", err) return &#125; &#125; &#125;&#125; reader 从frps收信息，然后写到 ctl.readCh 这个 channel 里，writer 则相反，从 ctl.sendCh 收信息，写到 frps，而 msgHandler 则从frpc里读取信息，放到 ctl.sendCh，从 ctl.readCh 读取信息，处理之。 之所以这样设计，是为了能够异步处理所有消息。看看 msgHandler 的关键部分： 123456789switch m := rawMsg.(type) &#123;case *msg.ReqWorkConn: go ctl.HandleReqWorkConn(m)case *msg.NewProxyResp: ctl.HandleNewProxyResp(m)case *msg.Pong: ctl.lastPong = time.Now() ctl.Debug("receive heartbeat from server")&#125; 我们说过了，frps 每次收到一个请求之后，然后下发一个指令给frpc，要求frpc建立连接，然后frps再把新来的连接与请求所在的连接串起来，完成代理，msg.ReqWorkConn 就是这个指令。 那么 frps 是在哪里下发指令的呢？ frps 下发指令每当公网来一个新的请求的时候，frps就会下发一个指令给frpc，要求建立一个新的连接，代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950func (pxy *BaseProxy) GetWorkConnFromPool(src, dst net.Addr) (workConn frpNet.Conn, err error) &#123; // try all connections from the pool for i := 0; i &lt; pxy.poolCount+1; i++ &#123; if workConn, err = pxy.getWorkConnFn(); err != nil &#123; pxy.Warn("failed to get work connection: %v", err) return &#125; pxy.Info("get a new work connection: [%s]", workConn.RemoteAddr().String()) workConn.AddLogPrefix(pxy.GetName()) var ( srcAddr string dstAddr string srcPortStr string dstPortStr string srcPort int dstPort int ) if src != nil &#123; srcAddr, srcPortStr, _ = net.SplitHostPort(src.String()) srcPort, _ = strconv.Atoi(srcPortStr) &#125; if dst != nil &#123; dstAddr, dstPortStr, _ = net.SplitHostPort(dst.String()) dstPort, _ = strconv.Atoi(dstPortStr) &#125; message := msg.StartWorkConn&#123; ProxyName: pxy.GetName(), SrcAddr: srcAddr, SrcPort: uint16(srcPort), DstAddr: dstAddr, DstPort: uint16(dstPort), &#125; err := msg.WriteMsg(workConn, &amp;message) workConn.Warn("===== HERE! HERE! HERE!, message is: %+v", message) if err != nil &#123; workConn.Warn("failed to send message to work connection from pool: %v, times: %d", err, i) workConn.Close() &#125; else &#123; break &#125; &#125; if err != nil &#123; pxy.Error("try to get work connection failed in the end") return &#125; return&#125; 那个===== HERE! HERE! HERE!, message is: %+v 是我加上去的，为了方便看每次服务端下发什么信息。我们看的是TCP的代理，它继承于 server/proxy/proxy.go 里的 BaseProxy，实现是在 server/proxy/tcp.go 里的type TcpProxy struct。 那么什么时候会初始化 TcpProxy 呢？我们注意到，frps 接收的消息里，就有一种是消息类型是 msg.NewProxy，这是客户端和服务端都启动，并且客户端成功login之后，客户端发送给服务端的消息。也就是 frpc 的配置文件里具体的代理，例如： 12345678910[common]server_addr = xxxxxserver_port = 12345tls_enable = true[ssh]type = tcplocal_ip = 127.0.0.1local_port = 22remote_port = 12346 中的 ssh 就是一个TCP代理。收到msg.NewProxy 之后，服务端会起一个新的监听器监听在对应的端口，然后开始处理请求。 总结这一篇中，我们在第一篇的基础之上看了frpc和frps的交互流程，了解了frp是如何进行TCP代理的。 转载：https://www.jianshu.com/p/5b884383a508]]></content>
      <tags>
        <tag>frp</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于内网穿透frp程序的分析]]></title>
    <url>%2F2019%2F09%2F30%2Ffrp-jiexi%2F</url>
    <content type="text"><![CDATA[目前市面上实现动态域名解析的服务商花生壳,半开源的ngrok都是使用内网穿透技术来实现的,内网穿透可以解决什么样的需求呢? 有台小破电脑,想用来做一台服务器,希望出了家门也能够访问,迫于服务商不提供固定IP,不能简单的配置网关端口映射达到目的,这时我们可以采用内网穿透技术,让外网可以畅游内网. 目前物联网的概念很火,买了台用于监控室内防盗的监控设备,同样希望在任何时候都可以看见家里的状态,这样我们可以使用推流的方式向外服务器推送视频流,这样的话就会一直存在视频的传送.这里我们也可以使用内网穿透,实现需要时才推流 关于Frp项目开源地址github,当然这不是我的作品,我只是伸手党.该程序使用golang实现. frp 是一个可用于内网穿透的高性能的反向代理应用，支持 tcp, udp, http, https 协议。 frp 的作用 利用处于内网或防火墙后的机器，对外网环境提供 http 或 https 服务。 对于 http, https 服务支持基于域名的虚拟主机，支持自定义域名绑定，使多个域名可以共用一个80端口。 利用处于内网或防火墙后的机器，对外网环境提供 tcp 和 udp 服务，例如在家里通过 ssh 访问处于公司内网环境内的主机。 原理分析内网端程序分析内网程序的入口在frp/cmd/frpc下,通过入口函数,可以看见第一步其实就是读取配置文件的信息,具体怎么个读法这里就不细细展开,感兴趣的读者可以自行查阅. 程序的真正的开始执行其实是在frp/client/server.go#Run()函数中,这里调用了frp/client/control.go#Run()函数,这个函数中首先执行的是和服务端程序的对接(授权),然后开启多个goroutine,分别用于控制保持与服务端长连接,控制读写消息. 登录过程登录的代码在frp/client/control.go#login()函数中,首先 12345conn, err := net.ConnectServerByHttpProxy( config.ClientCommonCfg.HttpProxy, config.ClientCommonCfg.Protocol,//协议:tcp 或 kcp fmt.Sprintf(&quot;%s:%d&quot;,config.ClientCommonCfg.ServerAddr, config.ClientCommonCfg.ServerPort)) 获取到一个conn,这里的conn可以看成是对net.Conn的一个封装,这里的实现就是建立一个tcp/kcp的连接,从而获得一个socket句柄,供后续使用.接着往下看,执行一个msg.WriteMsg(conn, ctl.loginMsg),其目的是向上文的socket句柄写一个loginMsg,loginMsg就是对配置文件中设置privilege_token = 的加密封装,既然这里授权登录的请求发了出去,接下来就是等待授权结果,如果授权结果没有返回错误那么就表示登录成功了.这里继续保持socket句柄. 这里在谈谈它对发送接收消息的结构封装 1[第一字节为消息类型][第二字节为消息长度][后续内容为消息体 json格式] 开启消息在登录成功之后会开启一些goroutine 1234go ctl.controler() //控制代理的服务的状态监听,当服务死掉后重新发起重连go ctl.manager() //心跳检查与发起重连 从chan中读取消息go ctl.writer() //从chan中读取消息并向服务端发送go ctl.reader() //从stocket中读取消息并解析,然后发送到chan 这里我们以ssh登录为例进行说明,下面是reader()的源码摘要 123456789encReader := crypto.NewReader(ctl.conn, []byte(config.ClientCommonCfg.PrivilegeToken))for &#123; if m, err := msg.ReadMsg(encReader); err != nil &#123; ... //异常处理 &#125; else &#123; fmt.Println(&quot;新消息&quot;) ctl.readCh &lt;- m &#125;&#125; 我们可以看到其实reader()函数就是纯读取消息,然后通过chan把消息转发出去,如果不这样的话,处理就有需要单独开启线程来处理,比较麻烦.那么我们就看看到底在哪里读取消息,在manager()中,存在一下代码 1234567891011121314case rawMsg, ok := &lt;-ctl.readCh: if !ok &#123; return &#125; switch m := rawMsg.(type) &#123; case *msg.ReqWorkConn: go ctl.NewWorkConn() case *msg.NewProxyResp: ... // http等代理部分 case *msg.Pong: ctl.lastPong = time.Now() ctl.Debug(&quot;receive heartbeat from server&quot;) &#125; &#125; 果不其然, 没有在reader()中开启的线程,在manager()中开启了.因为ssh是tcp协议实现,所以在NewWorkConn会执行 123456if pxy, ok := ctl.proxies[startMsg.ProxyName]; ok &#123; workConn.Debug(&quot;start a new work connection, localAddr: %s remoteAddr: %s&quot;, workConn.LocalAddr().String(), workConn.RemoteAddr().String()) go pxy.InWorkConn(workConn) //pxy是tcpProxy&#125; else &#123; workConn.Close()&#125; 也就是会执行一下的函数 1234func (pxy *TcpProxy) InWorkConn(conn frpNet.Conn) &#123; //HttpProxy &amp; HttpsProxy 都是执行这个函数 HandleTcpWorkConnection(&amp;pxy.cfg.LocalSvrConf, pxy.proxyPlugin, &amp;pxy.cfg.BaseProxyConf, conn)&#125; 在HandleTcpWorkConnection()函数的末尾,调用了frpIo.Join(localConn, remote)实现双方的通信,这个函数的实现也是非常别致, 1234567891011121314151617181920// Join two io.ReadWriteCloser and do some operations.func Join(c1 io.ReadWriteCloser, c2 io.ReadWriteCloser) (inCount int64, outCount int64) &#123; var wait sync.WaitGroup pipe := func(to io.ReadWriteCloser, from io.ReadWriteCloser, count *int64) &#123; defer to.Close() defer from.Close() defer wait.Done() buf := pool.GetBuf(16 * 1024) defer pool.PutBuf(buf) *count, _ = io.CopyBuffer(to, from, buf) &#125; wait.Add(2) go pipe(c1, c2, &amp;inCount) go pipe(c2, c1, &amp;outCount) wait.Wait() return&#125; 这个函数的功能就是实现两个数据流的数据交换功能.比如ssh连接时,服务器会将客户的请求转发到内网的客户端机子上,客户端机子得到一个来自于服务端的conn,同时客户端根据服务端发来的数据,同本地的ssh服务建立一个conn,之后的过程就是这两个conn之间的一个通信(通过上文的Join方法),也就是frp不在参与他们之间的一个通信。 服务端程序分析相对于客户端程序，服务端程序的功能就比较的单一,就是实现一个连接的转发。程序的入口位于/cmd/frps/main.go,开始的步骤和客户端一样，都是解析配置文件，最后调用了/frp/server/server.go#Run(),这里面就调用一个HandleListener(…)函数，里面是实现也比较的简单，一个标准的tcp阻塞函数，当有新的连接来的时候开启一个goroutine,在这个goroutine中获取消息的内容,再根据不同的消息类型进行不同的处理,这里只有两种类型，分别为Login和NewWorkConn,很明显Login就是对客户端的授权处理,而NewWorkConn就是客户端发起的服务。下面分别分析。 Login Auth过程登录授权的入口在/frp/server/server.go#RegisterControl(…),验证的参数包括版本号,时间戳,private key,验证成功之后向客户端发送一个LoginResp的消息，并且生成一个id给这个连接。接下进行的操作和客户端的操作差不多。 12345678go ctl.writer() //发送消息到客户端for i := 0; i &lt; ctl.poolCount; i++ &#123; ctl.sendCh &lt;- &amp;msg.ReqWorkConn&#123;&#125; //与客户端开启多个连接&#125;go ctl.manager() //从ctl.readCh中读取并处理消息go ctl.reader() //从conn中读取消息扔到ctl.rendCh中go ctl.stoper() //当客户端断开了连接之后，关闭这个客户端的所有连接 这里就不细讲了，逻辑基本和客户端的实现一致。 NewWorkConn 消息的处理当收到新的连接的时候,也就是收到NewWorkConn这个消息时,会执行RegisterWorkConn(…)方法，这个方法的作用就是把这个conn加入到服务端的一个pool中,供后续使用。 总结frp的大体流程就是上文描述的,当然还有许多的细节点,这里只是大体描述程序的流程,如果要深入的理解还需要自己去详细的阅读源码。]]></content>
      <tags>
        <tag>frp</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搬瓦工IP被墙]]></title>
    <url>%2F2019%2F09%2F16%2Fbanwagong%2F</url>
    <content type="text"><![CDATA[https://www.banwago.com/1265.html]]></content>
      <tags>
        <tag>搬瓦工</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware虚拟机 软路由]]></title>
    <url>%2F2019%2F09%2F16%2Fopenwrt%2F</url>
    <content type="text"><![CDATA[https://zhuanlan.zhihu.com/p/60232628]]></content>
      <tags>
        <tag>openwrt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VMware虚拟机安装黑群晖DSM6.2]]></title>
    <url>%2F2019%2F09%2F16%2Fqunhui%2F</url>
    <content type="text"><![CDATA[https://www.tenlonstudio.com/3101.html]]></content>
      <tags>
        <tag>nas</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派—raspbian软件源]]></title>
    <url>%2F2019%2F09%2F07%2Fpi-disk%2F</url>
    <content type="text"><![CDATA[1sudo apt-get update 一键换源直接执行以下两行命令，即可替换将官方默认软件源替换为中科大或清华镜像源。2018.05.18更新：新的默认源为raspbian.raspberrypi.org因此一键换源相应改为 12sudo sed -i &apos;s#://raspbian.raspberrypi.org#s://mirrors.ustc.edu.cn/raspbian#g&apos; /etc/apt/sources.list sudo sed -i &apos;s#://archive.raspberrypi.org/debian#s://mirrors.ustc.edu.cn/archive.raspberrypi.org/debian#g&apos; /etc/apt/sources.list.d/raspi.list 或 12sudo sed -i &apos;s#://raspbian.raspberrypi.org#s://mirrors.tuna.tsinghua.edu.cn/raspbian#g&apos; /etc/apt/sources.listsudo sed -i &apos;s#://archive.raspberrypi.org/debian#s://mirrors.tuna.tsinghua.edu.cn/raspberrypi#g&apos; /etc/apt/sources.list.d/raspi.list]]></content>
      <tags>
        <tag>pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSH 免密登录]]></title>
    <url>%2F2019%2F09%2F05%2Fssh%2F</url>
    <content type="text"><![CDATA[基本概念SSH协议SSH 是一种计算机之间加密登录的协议，它相对于telnet和rsh的明文传输，提供了加密、校验和压缩，使得我们可以很安全的远程操作，而不用担心信息泄露(当然不是绝对的，加密总有可能被破解，只是比起明文来说那是强了不少)。 加密加密的意思是将一段数据经过处理之后，输出为一段外人无法或者很难破译的数据，除了指定的人可以解密之外。一般来说，加密的输入还会有一个key，这个key作为加密的参数，而在解密的时候也会用一个相关联(有可能是相同)的key作为输入。粗略来说是下面的流程： 1234# 加密方encrypted_data = encrypt(raw_data, key)# 解密方raw_data = decrypt(encrypted_data, key1) 目前主流的加密算法一般分为下面两类： 私钥(secret key)加密，也称为对称加密公钥(public key)加密 私钥加密所谓的私钥加密，是说加密方和解密方用的都是同一个key，这个key对于加密方和解密方来说是保密的，第三方是不能知道的。在第三方不知道私钥的情况下，是很难将加密的数据解密的。一般来说是加密方先产生私钥，然后通过一个安全的途径来告知解密方这个私钥。 公钥加密公钥加密，是说解密的一方首先生成一对密钥，一个私钥一个公钥，私钥不会泄漏出去，而公钥则是可以任意的对外发布的。用公钥进行加密的数据，只能用私钥才能解密。加密方首先从解密方获取公钥，然后利用这个公钥进行加密，把数据发送给解密方。解密方利用私钥进行解密。如果解密的数据在传输的过程中被第三方截获，也不用担心，因为第三方没有私钥，没有办法进行解密。 公钥加密的问题还包括获取了公钥之后，加密方如何保证公钥来自于确定的一方，而不是某个冒充的机器。假设公钥不是来自我们信任的机器，那么就算我们用公钥加密也没有用，因为加密之后的数据是发送给了冒充的机器，该机器就可以利用它产生的私钥进行解密了。所以公钥加密里面比较重要的一步是身份认证。 需要说明一下，一般的私钥加密都会比公钥加密快，所以大数据量的加密一般都会使用私钥加密，而公钥加密会作为身份验证和交换私钥的一个手段。 数据一致性/完整性数据一致性说得是如何保证一段数据在传输的过程中没有遗漏、破坏或者修改过。一般来说，目前流行的做法是对数据进行hash，得到的hash值和数据一起传输，然后在收到数据的时候也对数据进行hash，将得到的hash值和传输过来的hash值进行比对，如果是不一样的，说明数据已经被修改过；如果是一样的，则说明极有可能是完整的。 目前流行的hash算法有MD5和SHA-1算法。 身份验证身份验证说的是，判断一个人或者机器是不是就是你想要联系的。也就是说如果A想要和B通信，一般来说开始的时候会交换一些数据，A怎么可以判断发送回来的数据就真的是B发送的呢？现实中有很多方法可以假冒一个机器。 在SSH里面，这主要是通过公钥来完成的。首先客户端会有一个公钥列表，保存的是它信任的机器上面的公钥。在开始SSH连接之后，服务器会发送过来一个公钥，然后客户端就会进行查找，如果这个公钥在这个列表里面，就说明这个机器是真的服务器。 当然实际的情况会复杂一些。实际上服务器不是真的发送公钥过来，因为这很容易被第三方盗取。 免密码登录 在自己的操作系统上生成一对SSH KEY，如果已经存在可以不生成 将公钥上传到服务器上 生成SSH私钥和公钥1ssh-keygen -t rsa 这样会在当前目录生成名为id_rsa的私钥文件和名为id_rsa.pub的公钥文件，-t表示密钥类型是rsa。如果你只输入ssh-keygen生成的RSA密钥长度为2048，如果你对安全性要求比较高可以指定4096位的长度： 1ssh-keygen -b 4096 -t rsa 这里-b就是多少位，当然你对这些参数感兴趣可以使用–help参数看看具体的含义和解释。 当你在生成SSHKEY的时候在命令行下会提示你Enter file in which to save the key，让你确认密钥文件保存的路径，一般回车即可（一般默认会在当前用户家目录下的.ssh目录下）。 第二个提示是 Enter passphrase (empty for no passphrase) 让你输入一个密钥的密码，如果不输入则留空；回车生成公私钥完毕 :)此时你可以使用cat命令看下自己的公私钥。 服务器配置我们前面在自己的操作系统生成了公私钥，然后将公钥的内容告诉给服务器就可以了，让服务器知道自己公钥的操作方式还蛮多的。 上传公钥文件 将本地的公钥文件上传到服务器上，然后在服务器需要免密登录的用户家目录下查看是否有 ~/.ssh/authorized_keys 这个文件，如果没有手动创建一个: 1touch ~/.ssh/authorized_keys 然后我们将公钥内容写入到authorized_keys文件中，因为这个文件可能已经有内容了，所以你可以使用如下方式 1cat -n ~/.ssh/rsa.pub ~/.ssh/authorized_keys 这样就将公钥内容追加到authorized_keys中了，然后需要注意配置权限了，否则SSH不会工作的，我在这里踩了坑。。 将.ssh目录的权限为700将authorized_keys目录的权限为600 ssh-copy-id 复制公钥这个工具还蛮有用的，不过它会将我本地的所有公钥都传到服务器，使用方法： 1ssh-copy-id username@remote-server 因为我的服务器SSH端口不是22，所以使用 ssh-copy-id 登录用户@服务器IP -p端口 试试运用我们完成了这些步骤是不是就可以免密登录了呢？是的，你现在登录服务器： 1ssh user@host -p22 注意修改你自己的登录信息。 再简单一点我们前面生成SSHKEY的时候还有一个私钥没用到，这是干什么用的呢？公钥是公开的，任何人都可以获得，私钥则是保密的，只有本地存储了一份， 配置本地的ssh，修改 ~/.ssh/config 文件： 12345Host yourserver HostName 192.168.11.22 Port 12345 User username IdentityFile ~/.ssh/id_rsa 这里的 Host 是我们要登录的服务器的别名，为了方便快捷登录，下面是服务器的信息，最后一项是你的私钥路径。 完成这个配置后我们就可以使用 ssh yourserver，进行登录啦~]]></content>
      <tags>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python ssh 模块使用]]></title>
    <url>%2F2019%2F09%2F05%2Fpython-ssh%2F</url>
    <content type="text"><![CDATA[介绍paramiko是用python语言写的一个模块，遵循SSH2协议，支持以加密和认证的方式，进行远程服务器的连接。paramiko支持Linux, Solaris, BSD, MacOS X, Windows等平台通过SSH从一个平台连接到另外一个平台。利用该模块，可以方便的进行ssh连接和sftp协议进行sftp文件传输。 安装paramiko模块依赖PyCrypto模块，而PyCrypto需要GCC库编译，不过一般发行版的源里带有该模块。这里以ubuntu为例，直接借助以下命令可以直接完成安装： 1# pip install paramiko 连接使用paramiko模块有两种连接方式，一种是通过paramiko.SSHClient()函数，另外一种是通过paramiko.Transport()函数。 方法一：12345678910111213141516171819import paramikossh = paramiko.SSHClient()#这行代码的作用是允许连接不在know_hosts文件中的主机。ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())# 使用私钥连接# ssh.connect('10.120.48.109', port, '用户名',key_filename='私钥')# 使用密码连接：ssh.connect("192.168.2.247",22,"mbb", "243063036.mm")stdin, stdout, stderr = ssh.exec_command('ls')print(stdout.readlines())ssh.close() [&apos;conf\n&apos;, &apos;examples.desktop\n&apos;, &apos;frp\n&apos;, &apos;gateone\n&apos;, &apos;get_pip.py\n&apos;, &apos;git\n&apos;, &apos;gitlab\n&apos;, &apos;index2.py\n&apos;, &apos;index.py\n&apos;, &apos;Lite\n&apos;, &apos;logs\n&apos;, &apos;mongo\n&apos;, &apos;mynginx\n&apos;, &apos;myregistry\n&apos;, &apos;mysql\n&apos;, &apos;n2n\n&apos;, &apos;nbs\n&apos;, &apos;nginx\n&apos;, &apos;node\n&apos;, &apos;nohup.out\n&apos;, &apos;notebooks\n&apos;, &apos;opencv\n&apos;, &apos;opencv_python\n&apos;, &apos;packages-microsoft-prod.deb\n&apos;, &apos;portainer\n&apos;, &apos;privoxy-3.0.26-stable\n&apos;, &apos;shadowsocks-all.log\n&apos;, &apos;shadowsocks-all.sh\n&apos;, &apos;shadowsocks_python_qr.png\n&apos;, &apos;srs\n&apos;, &apos;srsnew\n&apos;, &apos;temp\n&apos;, &apos;tensorflow\n&apos;, &apos;test\n&apos;, &apos;txt\n&apos;, &apos;vpn-gen.env\n&apos;, &apos;vpnsetup.sh\n&apos;, &apos;web\n&apos;, &apos;webapp\n&apos;, &apos;wget-log\n&apos;, &apos;www\n&apos;] 方法二：123456789import paramikot = paramiko.Transport(("192.168.2.247",22))t.connect(username = "mbb", password = "243063036.mm")# t.connect(username = "用户名", password = "口令", hostkey="密钥")print(t) &lt;paramiko.Transport at 0xa0ec10f0 (cipher aes128-ctr, 128 bits) (active; 0 open channel(s))&gt; sftp文件传输 12345678910111213141516171819import paramikossh = paramiko.SSHClient()#这行代码的作用是允许连接不在know_hosts文件中的主机。ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())# 使用私钥连接# ssh.connect('10.120.48.109', port, '用户名',key_filename='私钥')# 使用密码连接：ssh.connect("192.168.2.247",22,"mbb", "243063036.mm")# sftp = paramiko.SFTPClient.from_transport(t)sftp = paramiko.SFTPClient.from_transport(ssh.get_transport())sftp = ssh.open_sftp() 1.文件上传 1sftp.put('index.py', 'index.py') &lt;SFTPAttributes: [ size=787 uid=1008 gid=1009 mode=0o100664 atime=1567670573 mtime=1567670585 ]&gt; 2.文件下载 1sftp.get('get_pip.py', 'get_pip.py') 3.获取文件列表 1print(sftp.listdir()) [&apos;vpn-gen.env&apos;, &apos;conf&apos;, &apos;.Xauthority&apos;, &apos;logs&apos;, &apos;n2n&apos;, &apos;temp&apos;, &apos;.ssh&apos;, &apos;.bashrc&apos;, &apos;tensorflow&apos;, &apos;www&apos;, &apos;srs&apos;, &apos;.pip&apos;, &apos;examples.desktop&apos;, &apos;index2.py&apos;, &apos;.cache&apos;, &apos;wget-log&apos;, &apos;.profile&apos;, &apos;.python_history&apos;, &apos;packages-microsoft-prod.deb&apos;, &apos;gitlab&apos;, &apos;myregistry&apos;, &apos;.keras&apos;, &apos;.bash_logout&apos;, &apos;node&apos;, &apos;shadowsocks-all.log&apos;, &apos;gateone&apos;, &apos;txt&apos;, &apos;nohup.out&apos;, &apos;frp&apos;, &apos;srsnew&apos;, &apos;nginx&apos;, &apos;opencv_python&apos;, &apos;.vim_mru_files&apos;, &apos;portainer&apos;, &apos;.bash_history&apos;, &apos;.vscode-server&apos;, &apos;opencv&apos;, &apos;privoxy-3.0.26-stable&apos;, &apos;shadowsocks_python_qr.png&apos;, &apos;nbs&apos;, &apos;mysql&apos;, &apos;test&apos;, &apos;shadowsocks-all.sh&apos;, &apos;vpnsetup.sh&apos;, &apos;.viminfo&apos;, &apos;.vim&apos;, &apos;mongo&apos;, &apos;.docker&apos;, &apos;Lite&apos;, &apos;.local&apos;, &apos;get_pip.py&apos;, &apos;webapp&apos;, &apos;mynginx&apos;, &apos;.vimrc&apos;, &apos;git&apos;, &apos;notebooks&apos;, &apos;web&apos;, &apos;index.py&apos;] 1t.close() 官方文档：https://paramiko-docs.readthedocs.io/en/2.6/]]></content>
      <tags>
        <tag>python</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux 安装 Shadowsocks 客户端 并全局代理]]></title>
    <url>%2F2019%2F09%2F02%2Fss%2F</url>
    <content type="text"><![CDATA[安装 Shadowsocksshadowsocks 客户端和服务器端是同一个安装包，两个脚本不同，客户端模式是 sslocal，服务器端模式是 ssserver CentOS 下搭建1234# 安装pipyum install python-setuptools &amp;&amp; easy_install pip# 安装shadowsockspip install shadowsocks Ubuntu 下搭建1234# 安装pipapt-get install python-pip# 安装shadowsockspip install shadowsocks sslocal 运行 shadowsocks 客户端 1nohup sslocal -s your_server_ip -p your_server_port -l 1080 -k your_server_passwd -t 600 -m rc4-md5 &gt; /dev/null 2&gt;&amp;1 &amp; 解释 1234# your_server_ip: 服务器 IP# your_server_port: 服务器端口# your_server_passwd: SS 密码# rc4-md5: 加密方式 或创建一个 shadowsocks 的配置文件 123456789101112vim /etc/shadowsocks.json&#123; &quot;server&quot;:&quot;your_server_ip&quot;, # ss 服务器 IP &quot;server_port&quot;:your_server_port, # 端口 &quot;local_address&quot;: &quot;127.0.0.1&quot;, # 本地 IP &quot;local_port&quot;:1080, # 本地端口 &quot;password&quot;:&quot;your_server_passwd&quot;,# 连接 ss 密码 &quot;timeout&quot;:300, # 等待超时 &quot;method&quot;:&quot;rc4-md5&quot;, # 加密方式 &quot;fast_open&quot;: false, # true 或 false。 &quot;workers&quot;: 1 # 工作线程数&#125; 解释（使用时删除井号及后面文字） 123fast_open: 如果你的服务器 Linux 内核在3.7+，可以开启 fast_open 以降低延迟。开启方法： echo 3 &gt; /proc/sys/net/ipv4/tcp_fastopen 开启之后，将 fast_open 的配置设置为 true 即可 以 json 文件来运行启动 sslocal 1nohup sslocal -c /etc/shadowsocks.json &gt; /dev/null 2&gt;&amp;1 &amp; 增加开启自动启动，执行： 1echo &quot; nohup sslocal -c /etc/shadowsocks.json &gt; /dev/null 2&gt;&amp;1 &amp;&quot; /etc/rc.local 执行 ps aux | grep sslocal | grep -v “grep” 可查看后台 sslocal 是否运行。 安装 Privoxy上述安好了 shadowsocks，但它是 socks5 代理，我门在 shell 里执行的命令，发起的网络请求现在还不支持 socks5 代理，只支持 http／https 代理。为了我门需要安装 privoxy 代理，它能把电脑上所有 http 请求转发给 shadowsocks。 123wget http://www.privoxy.org/sf-download-mirror/Sources/3.0.26%20%28stable%29/privoxy-3.0.26-stable-src.tar.gztar -zxvf privoxy-3.0.26-stable-src.tar.gzcd privoxy-3.0.26-stable 若上述地址无法连接可替换为本站链接 http://blog.liuguofeng.com/wp-content/uploads/2018/07/privoxy-3.0.26-stable-src.tar.gz 新建一个 privoxy 用户用来运行 1useradd privoxy 编译安装 123autoheader &amp;&amp; autoconf./configuremake &amp;&amp; make install 配置 1vim /usr/local/etc/privoxy/config 确保下面两句没有被注释 12listen-address 127.0.0.1:8118 # 8118 是默认端口，不用改，下面会用到forward-socks5t / 127.0.0.1:1080 # 这里的端口写 shadowsocks 的本地端口 使用 privoxy-gfwlist获取 privoxy-gfwlist 1234wget https://raw.github.com/zfl9/gfwlist2privoxy/master/gfwlist2privoxy bash gfwlist2privoxy &apos;127.0.0.1:1080&apos;cp gfwlist.action /usr/local/etc/privoxyecho &apos;actionsfile gfwlist.action&apos; &gt;&gt; /usr/local/etc/privoxy/config 启动 privoxy 1privoxy --user privoxy /usr/local/etc/privoxy/config 配置 /etc/profile 1vim /etc/profile 输入内容 1234export http_proxy=http://127.0.0.1:8118 #这里的端口和上面 privoxy 中的保持一致export https_proxy=http://127.0.0.1:8118export ftp_proxy=http://127.0.0.1:8118 #ftp可以不用export no_proxy=&quot;localhost, 127.0.0.1, ::1, aliyuncs.com, qiniuapi.com, qiniu.com, qiniucdn.com&quot; 刷新 1source /etc/profile 测试 1curl https://www.google.com 若不能访问，重启机器然后依次 12nohup sslocal -c /etc/shadowsocks.json /dev/null 2&gt;&amp;1 &amp;privoxy --user privoxy /usr/local/etc/privoxy/config]]></content>
      <tags>
        <tag>Shadowsocks</tag>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[face_recognition试用]]></title>
    <url>%2F2019%2F08%2F28%2Fface-recognition%2F</url>
    <content type="text"><![CDATA[安装1pip install face_recognition 识别人脸123456789101112131415161718192021222324252627282930313233# -*- coding: utf-8 -*-# # 检测人脸import face_recognitionimport cv2# 读取图片并识别人脸img = face_recognition.load_image_file("faces/1.jpg")face_locations = face_recognition.face_locations(img)print(face_locations)# 遍历每个人脸，并标注faceNum = len(face_locations)for i in range(0, faceNum): top = face_locations[i][0] right = face_locations[i][1] bottom = face_locations[i][2] left = face_locations[i][3] start = (left, top) end = (right, bottom) color = (55,255,155) thickness = 3 cv2.rectangle(img, start, end, color, thickness)# 显示识别结果cv2.namedWindow("img2")cv2.imshow("img2", img)cv2.waitKey(0)cv2.destroyAllWindows() [(67, 296, 196, 167)] 人脸比对1234567891011121314151617import face_recognitionjobs_image = face_recognition.load_image_file("faces/1.jpg");obama_image = face_recognition.load_image_file("faces/3.jpg");unknown_image = face_recognition.load_image_file("faces/2.jpg");jobs_encoding = face_recognition.face_encodings(jobs_image)[0]obama_encoding = face_recognition.face_encodings(obama_image)[0]unknown_encoding = face_recognition.face_encodings(unknown_image)[0]results = face_recognition.compare_faces([jobs_encoding, obama_encoding], unknown_encoding )labels = ['obam', 'mibb']print('results:'+str(results))for i in range(0, len(results)): if results[i] == True: print('The person is:'+labels[i]) results:[True, False] The person is:obam 识别出未知的照片是 obam 摄像头实时识别12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455# -*- coding: utf-8 -*-import face_recognitionimport cv2video_capture = cv2.VideoCapture('rtsp://admin:thrn.com@192.168.2.214:554/h264/ch33/main/av_stream')obama_img = face_recognition.load_image_file("faces/3.jpg")obama_face_encoding = face_recognition.face_encodings(obama_img)[0]face_locations = []face_encodings = []face_names = []process_this_frame = Truewhile True: ret, frame = video_capture.read() small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25) if process_this_frame: face_locations = face_recognition.face_locations(small_frame) face_encodings = face_recognition.face_encodings(small_frame, face_locations) face_names = [] for face_encoding in face_encodings: match = face_recognition.compare_faces([obama_face_encoding], face_encoding) if match[0]: name = "mibb" else: name = "unknown" face_names.append(name) process_this_frame = not process_this_frame for (top, right, bottom, left), name in zip(face_locations, face_names): top *= 4 right *= 4 bottom *= 4 left *= 4 cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2) cv2.rectangle(frame, (left, bottom - 35), (right, bottom), (0, 0, 255), 2) font = cv2.FONT_HERSHEY_DUPLEX cv2.putText(frame, name, (left+6, bottom-6), font, 1.0, (255, 255, 255), 1) cv2.imshow('Video', frame) if cv2.waitKey(1) &amp; 0xFF == ord('q'): breakvideo_capture.release()cv2.destroyAllWindows()]]></content>
      <tags>
        <tag>dlib</tag>
        <tag>opencv</tag>
        <tag>python</tag>
        <tag>face_recognition</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[dlib深度学习模型训练]]></title>
    <url>%2F2019%2F08%2F28%2Fdlib-train%2F</url>
    <content type="text"><![CDATA[下载https://github.com/davisking/dlib win10 编译imglab 进入tools\imglab目录 新建文件build，进入build 右键cmd命令，输入：cmake .. cmd命令，输入：cmake --build . --config Release 将Release目录加入到系统环境变量 1234mkdir buildcd buildcmake ..cmake --build . --config Release 编译完成 imglab图片标注 新建文件夹：images 在images下放你想标注的图像，就是训练集 输入：imglab -c mydataset.xml images，生成mydataset.xml文件 cmd输入：imglab mydataset.xml 出现imglab标注软件了，可以自己标注了，这是一个漫长的过程 打标注，打标签，保存，退出软件 xml其实就是保存标注点的坐标信息了 训练模型1234567891011121314151617181920212223242526272829303132333435363738394041# %load train_model.pyimport osimport sysimport globimport dlibimport cv2# options用于设置训练的参数和模式options = dlib.simple_object_detector_training_options()# Since faces are left/right symmetric we can tell the trainer to train a# symmetric detector. This helps it get the most value out of the training# data.options.add_left_right_image_flips = True# 支持向量机的C参数，通常默认取为5.自己适当更改参数以达到最好的效果options.C = 5# 线程数，你电脑有4核的话就填4options.num_threads = 4options.be_verbose = True# 获取路径current_path = os.getcwd()train_folder = current_path + '/train/cats_train/'test_folder = current_path + '/train/cats_test/'train_xml_path = train_folder + 'mydataset.xml'test_xml_path = test_folder + 'mydataset.xml'print("training file path:" + train_xml_path)# print(train_xml_path)print("testing file path:" + test_xml_path)# print(test_xml_path)# 开始训练print("start training:")dlib.train_simple_object_detector(train_xml_path, 'detector.svm', options)print("") # Print blank line to create gap from previous outputprint("Training accuracy: &#123;&#125;".format( dlib.test_simple_object_detector(train_xml_path, "detector.svm")))print("Testing accuracy: &#123;&#125;".format( dlib.test_simple_object_detector(test_xml_path, "detector.svm"))) training file path:G:\py\dlib/train/cats_train/mydataset.xml testing file path:G:\py\dlib/train/cats_test/mydataset.xml start training: Training accuracy: precision: 1, recall: 1, average precision: 1 Testing accuracy: precision: 1, recall: 1, average precision: 1 测试模型123456789101112131415161718192021222324252627282930313233# %load test_model.pyimport osimport sysimport dlibimport cv2import globprint('start')detector = dlib.simple_object_detector("detector.svm")current_path = os.getcwd()test_folder = current_path + '/train/cats_train/images/'print('load images')for f in glob.glob(test_folder+'*.jpg'): print("Processing file: &#123;&#125;".format(f)) img = cv2.imread(f, cv2.IMREAD_COLOR) b, g, r = cv2.split(img) img2 = cv2.merge([r, g, b]) dets = detector(img2) print("Number of faces detected: &#123;&#125;".format(len(dets))) for index, face in enumerate(dets): print('face &#123;&#125;; left &#123;&#125;; top &#123;&#125;; right &#123;&#125;; bottom &#123;&#125;'.format(index, face.left(), face.top(), face.right(), face.bottom())) left = face.left() top = face.top() right = face.right() bottom = face.bottom() cv2.rectangle(img, (left, top), (right, bottom), (0, 255, 0), 3) cv2.namedWindow(f, cv2.WINDOW_AUTOSIZE) cv2.imshow(f, img)k = cv2.waitKey(0)cv2.destroyAllWindows() start load images Processing file: G:\py\dlib/train/cats_train/images\filename1.jpg Number of faces detected: 1 face 0; left 681; top 194; right 910; bottom 480 Processing file: G:\py\dlib/train/cats_train/images\filename10.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename11.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename12.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename13.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename14.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename15.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename16.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename17.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename18.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename19.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename2.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename20.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename21.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename22.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename23.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename24.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename25.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename26.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename27.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename28.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename29.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename3.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename30.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename31.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename32.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename33.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename4.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename5.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename6.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename7.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename8.jpg Number of faces detected: 0 Processing file: G:\py\dlib/train/cats_train/images\filename9.jpg Number of faces detected: 0]]></content>
      <tags>
        <tag>dlib</tag>
        <tag>opencv</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[人脸比对]]></title>
    <url>%2F2019%2F08%2F28%2Fdlib-face%2F</url>
    <content type="text"><![CDATA[原理使用dlib标定人脸，提取68个特征点，将人脸的信息提取成一个128维的向量空间。在这个向量空间上，同一个人脸的更接近，不同人脸的距离更远。度量采用欧式距离，欧氏距离计算不算复杂。 二维情况下： $$ \sqrt{(x1−x2)^2+(y1−y2)^2} $$ 三维情况下： $$ \sqrt{(x1−x2)^2+(y1−y2)^2+(z1−z2)^2} $$ 将其扩展到128维的情况下即可。通常使用的判别阈值是0.6，即如果两个人脸的向量空间的欧式距离超过了0.6，即认定不是同一个人；如果欧氏距离小于0.6，则认为是同一个人。这个距离也可以由自己定，只要效果能更好。 计算人脸128维向量123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354# %load demo5.pyimport sysimport dlibimport cv2import osimport globimport matplotlib.pyplot as pltcurrent_path = os.getcwd() # 获取当前路径# 模型路径predictor_path = current_path + "\\cnn\\shape_predictor_68_face_landmarks.dat"face_rec_model_path = current_path + "\\cnn\\dlib_face_recognition_resnet_model_v1.dat"#测试图片路径faces_folder_path = current_path + "\\faces\\"# 读入模型detector = dlib.get_frontal_face_detector()shape_predictor = dlib.shape_predictor(predictor_path)face_rec_model = dlib.face_recognition_model_v1(face_rec_model_path)for img_path in glob.glob(os.path.join(faces_folder_path, "*.jpg")): print("Processing file: &#123;&#125;".format(img_path)) # opencv 读取图片，并显示 img = cv2.imread(img_path, cv2.IMREAD_COLOR) # opencv的bgr格式图片转换成rgb格式 b, g, r = cv2.split(img) img2 = cv2.merge([r, g, b]) dets = detector(img, 1) # 人脸标定 print("Number of faces detected: &#123;&#125;".format(len(dets))) for index, face in enumerate(dets): print('face &#123;&#125;; left &#123;&#125;; top &#123;&#125;; right &#123;&#125;; bottom &#123;&#125;'.format(index, face.left(), face.top(), face.right(), face.bottom())) shape = shape_predictor(img2, face) # 提取68个特征点 for i, pt in enumerate(shape.parts()): #print('Part &#123;&#125;: &#123;&#125;'.format(i, pt)) pt_pos = (pt.x, pt.y) cv2.circle(img, pt_pos, 2, (255, 0, 0), 1) #print(type(pt)) #print("Part 0: &#123;&#125;, Part 1: &#123;&#125; ...".format(shape.part(0), shape.part(1)))# cv2.namedWindow(img_path+str(index), cv2.WINDOW_AUTOSIZE)# cv2.imshow(img_path+str(index), img) plt.figure(img_path+str(index)) # 图像窗口名称 plt.imshow(img) plt.axis('on') # 关掉坐标轴为 off plt.title('image') # 图像题目 plt.show() face_descriptor = face_rec_model.compute_face_descriptor(img2, shape) # 计算人脸的128维的向量 print(face_descriptor)k = cv2.waitKey(0)cv2.destroyAllWindows() Processing file: G:\py\dlib\faces\1.jpg Number of faces detected: 1 face 0; left 167; top 67; right 296; bottom 196 -0.100903 0.107215 0.0127989 -0.0740284 0.0066496 0.0225189 -0.078312 -0.0923171 0.196753 -0.108072 0.236062 0.101153 -0.207568 -0.139876 0.0408826 0.114068 -0.199692 -0.0939411 -0.0996753 -0.11982 0.0413545 -0.00487671 0.0877109 0.0492948 -0.137577 -0.353298 -0.0608 -0.171296 0.00199143 -0.105018 -0.081396 0.000772364 -0.181964 -0.107023 0.0216598 -0.0236119 0.019205 0.00282077 0.201093 0.0315438 -0.125799 0.0942641 0.0268356 0.230741 0.276493 0.0833094 -0.00933838 -0.0849845 0.126553 -0.229523 0.0602546 0.163942 0.0720226 0.0233181 0.0970623 -0.198381 -0.0020905 0.0887514 -0.13795 0.0311375 0.00210361 -0.0886309 -0.0286811 0.0405957 0.191806 0.0950056 -0.124005 -0.0708959 0.129652 -0.0221997 0.022522 0.0184984 -0.194719 -0.214093 -0.233502 0.0845566 0.38484 0.193726 -0.198322 0.0328681 -0.202065 0.0332264 0.085176 0.0261305 -0.0700808 -0.122556 -0.0421356 0.0571684 0.0831238 0.0534201 -0.0515448 0.228289 -0.0252842 0.0643284 0.016167 0.0649517 -0.162603 -0.00856679 -0.17663 -0.0593192 0.0167162 -0.0178645 0.0543968 0.145731 -0.22838 0.0544676 0.00459545 -0.0257714 0.018232 0.0707982 -0.0418243 -0.0374448 0.0511305 -0.254493 0.23714 0.253834 0.0390552 0.180478 0.0882472 0.00598699 0.00265156 -0.0281207 -0.176554 -0.0485108 0.0544809 0.0590729 0.0764981 0.00331541 Processing file: G:\py\dlib\faces\2.jpg Number of faces detected: 1 face 0; left 210; top 110; right 339; bottom 239 -0.0656277 0.103886 0.0584333 -0.00946767 0.0313492 0.00599562 -0.0815832 -0.0543527 0.210806 -0.0652889 0.274125 0.0799883 -0.157585 -0.127232 0.0448985 0.153828 -0.150277 -0.0207188 -0.14031 -0.0766388 -6.17933e-06 0.000160489 0.0753391 0.0159993 -0.173483 -0.378838 -0.0494293 -0.15175 0.00172043 -0.152177 -0.0613851 0.00298419 -0.227171 -0.0889237 -0.0430099 -0.0198571 -0.00600264 -0.0256885 0.116474 0.0501233 -0.157516 0.112152 -0.0676546 0.234205 0.239259 0.0355268 0.0269477 -0.0462278 0.0857875 -0.218189 0.0237351 0.0650885 0.0457599 -0.0163889 0.0886727 -0.14048 -0.0469625 0.132312 -0.168475 0.0611648 -0.0031102 -0.0756179 -0.0682836 -0.00150348 0.179482 0.137031 -0.119424 -0.0555014 0.145337 -0.00377072 0.0697277 -0.00566657 -0.120912 -0.246407 -0.292141 0.0990863 0.331274 0.133164 -0.255346 0.0111306 -0.180369 0.0733314 0.0485543 -0.000675225 -0.0391747 -0.0659976 -0.0642663 0.0420131 0.124276 0.035692 -0.024141 0.232806 -0.0875989 -0.0289126 -0.0256559 0.0359742 -0.171378 -0.0157063 -0.144515 -0.0645077 0.0765323 -0.0545965 0.0089937 0.118871 -0.227901 0.117894 0.0338295 -0.0148607 0.0951797 0.0859544 -0.0798149 -0.0333232 0.114725 -0.241588 0.273436 0.223575 0.0414235 0.168515 0.0783172 0.0253355 -0.045372 0.0127425 -0.178775 -0.0632875 0.0440628 0.0167294 0.0563011 0.0142771 封装计算类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495# %load face_rec.pyimport sysimport dlibimport cv2import osimport globimport numpy as npdef comparePersonData(data1, data2): diff = 0 # for v1, v2 in data1, data2: # diff += (v1 - v2)**2 for i in range(len(data1)): diff += (data1[i] - data2[i])**2 diff = np.sqrt(diff) print(diff) if(diff &lt; 0.6): print("It's the same person") else: print("It's not the same person")def savePersonData(face_rec_class, face_descriptor): if face_rec_class.name == None or face_descriptor == None: return filePath = face_rec_class.dataPath + face_rec_class.name + '.npy' vectors = np.array([]) for i, num in enumerate(face_descriptor): vectors = np.append(vectors, num) # print(num) print('Saving files to :'+filePath) np.save(filePath, vectors) return vectorsdef loadPersonData(face_rec_class, personName): if personName == None: return filePath = face_rec_class.dataPath + personName + '.npy' vectors = np.load(filePath) print(vectors) return vectorsclass face_recognition(object): def __init__(self): self.current_path = os.getcwd() # 获取当前路径 self.predictor_path = self.current_path + \ "\\cnn\\shape_predictor_68_face_landmarks.dat" self.face_rec_model_path = self.current_path + \ "\\cnn\\dlib_face_recognition_resnet_model_v1.dat" self.faces_folder_path = self.current_path + "\\faces\\" self.dataPath = self.current_path + "\\data\\" self.detector = dlib.get_frontal_face_detector() self.shape_predictor = dlib.shape_predictor(self.predictor_path) self.face_rec_model = dlib.face_recognition_model_v1( self.face_rec_model_path) self.name = None self.img_bgr = None self.img_rgb = None self.detector = dlib.get_frontal_face_detector() self.shape_predictor = dlib.shape_predictor(self.predictor_path) self.face_rec_model = dlib.face_recognition_model_v1( self.face_rec_model_path) def inputPerson(self, name='people', img_path=None): if img_path == None: print('No file!\n') return # img_name += self.faces_folder_path + img_name self.name = name self.img_bgr = cv2.imread(self.current_path+img_path) # opencv的bgr格式图片转换成rgb格式 b, g, r = cv2.split(self.img_bgr) self.img_rgb = cv2.merge([r, g, b]) def create128DVectorSpace(self): dets = self.detector(self.img_rgb, 1) print("Number of faces detected: &#123;&#125;".format(len(dets))) for index, face in enumerate(dets): print('face &#123;&#125;; left &#123;&#125;; top &#123;&#125;; right &#123;&#125;; bottom &#123;&#125;'.format( index, face.left(), face.top(), face.right(), face.bottom())) shape = self.shape_predictor(self.img_rgb, face) face_descriptor = self.face_rec_model.compute_face_descriptor( self.img_rgb, shape) # print(face_descriptor) # for i, num in enumerate(face_descriptor): # print(num) # print(type(num)) return face_descriptor 测试11234567891011121314# %load demo5.2.pyimport face_rec as fcface_rec = fc.face_recognition() # 创建对象face_rec.inputPerson(name='jobs', img_path='\\faces\\1.jpg') # name中写第一个人名字，img_name为图片名字，注意要放在faces文件夹中vector = face_rec.create128DVectorSpace() # 提取128维向量，是dlib.vector类的对象person_data1 = fc.savePersonData(face_rec, vector ) # 将提取出的数据保存到data文件夹，为便于操作返回numpy数组，内容还是一样的# 导入第二张图片，并提取特征向量face_rec.inputPerson(name='jobs2', img_path='\\faces\\2.jpg')vector = face_rec.create128DVectorSpace() # 提取128维向量，是dlib.vector类的对象person_data2 = fc.savePersonData(face_rec, vector )# 计算欧式距离，判断是否是同一个人fc.comparePersonData(person_data1, person_data2) Number of faces detected: 1 face 0; left 167; top 67; right 296; bottom 196 Saving files to :G:\py\dlib\data\jobs.npy Number of faces detected: 1 face 0; left 210; top 110; right 339; bottom 239 Saving files to :G:\py\dlib\data\jobs2.npy 0.43092407321591797 It&apos;s the same person 测试2如果data文件夹中已经有了模型文件，可以直接导入 123456# %load demo5.3.pyimport face_rec as fcface_rec = fc.face_recognition() # 创建对象person_data1 = fc.loadPersonData(face_rec , 'jobs') # 创建一个类保存相关信息，后面还要跟上人名，程序会在data文件中查找对应npy文件，比如这里就是'jobs.npy'person_data2 = fc.loadPersonData(face_rec , 'jobs2') # 导入第二张图片fc.comparePersonData(person_data1, person_data2) # 计算欧式距离，判断是否是同一个人 [-0.10090288 0.1072145 0.01279887 -0.07402837 0.0066496 0.02251893 -0.07831199 -0.09231715 0.19675256 -0.10807184 0.23606203 0.10115325 -0.20756839 -0.13987558 0.04088261 0.11406779 -0.19969247 -0.0939411 -0.09967533 -0.11981992 0.0413545 -0.00487671 0.08771094 0.04929478 -0.13757712 -0.35329792 -0.06079998 -0.17129567 0.00199143 -0.10501849 -0.08139595 0.00077236 -0.18196386 -0.10702266 0.02165978 -0.02361187 0.01920501 0.00282077 0.20109291 0.03154382 -0.12579948 0.09426409 0.02683559 0.23074135 0.27649316 0.08330945 -0.00933838 -0.08498447 0.12655319 -0.22952324 0.06025456 0.16394231 0.07202258 0.02331806 0.0970623 -0.19838132 -0.0020905 0.08875141 -0.13795027 0.03113746 0.00210361 -0.08863088 -0.02868112 0.04059572 0.19180585 0.09500565 -0.12400492 -0.07089586 0.12965189 -0.02219969 0.02252199 0.0184984 -0.19471948 -0.21409343 -0.23350216 0.08455663 0.38484025 0.19372645 -0.19832234 0.03286812 -0.20206457 0.03322642 0.08517597 0.02613049 -0.07008083 -0.1225555 -0.04213565 0.05716839 0.08312382 0.05342007 -0.05154483 0.22828871 -0.02528416 0.06432839 0.01616702 0.06495167 -0.16260289 -0.00856679 -0.17663012 -0.05931918 0.01671621 -0.0178645 0.05439681 0.14573105 -0.2283798 0.05446758 0.00459545 -0.02577139 0.01823203 0.07079822 -0.0418243 -0.0374448 0.05113045 -0.25449288 0.23714027 0.25383428 0.03905518 0.18047769 0.08824719 0.00598699 0.00265156 -0.02812069 -0.17655382 -0.04851077 0.05448093 0.05907289 0.07649811 0.00331541] [-6.56276643e-02 1.03885919e-01 5.84333241e-02 -9.46767069e-03 3.13491672e-02 5.99562051e-03 -8.15831944e-02 -5.43527044e-02 2.10805923e-01 -6.52888864e-02 2.74125129e-01 7.99882561e-02 -1.57584816e-01 -1.27232060e-01 4.48985100e-02 1.53828233e-01 -1.50276557e-01 -2.07187757e-02 -1.40310183e-01 -7.66388401e-02 -6.17932528e-06 1.60488766e-04 7.53390938e-02 1.59993358e-02 -1.73482582e-01 -3.78838450e-01 -4.94292676e-02 -1.51749954e-01 1.72043126e-03 -1.52176514e-01 -6.13850914e-02 2.98418920e-03 -2.27170840e-01 -8.89236853e-02 -4.30098511e-02 -1.98571198e-02 -6.00264221e-03 -2.56885011e-02 1.16473638e-01 5.01232818e-02 -1.57516152e-01 1.12152390e-01 -6.76545724e-02 2.34205097e-01 2.39259332e-01 3.55268009e-02 2.69476771e-02 -4.62278351e-02 8.57875049e-02 -2.18188748e-01 2.37350836e-02 6.50884509e-02 4.57599387e-02 -1.63888503e-02 8.86726677e-02 -1.40480235e-01 -4.69624698e-02 1.32311836e-01 -1.68474615e-01 6.11648224e-02 -3.11019551e-03 -7.56178722e-02 -6.82836100e-02 -1.50347827e-03 1.79482132e-01 1.37031436e-01 -1.19423933e-01 -5.55013828e-02 1.45336628e-01 -3.77072487e-03 6.97276667e-02 -5.66656608e-03 -1.20911710e-01 -2.46406645e-01 -2.92141348e-01 9.90862995e-02 3.31274062e-01 1.33164003e-01 -2.55346388e-01 1.11306198e-02 -1.80368572e-01 7.33314380e-02 4.85542640e-02 -6.75224583e-04 -3.91747132e-02 -6.59976155e-02 -6.42662570e-02 4.20131311e-02 1.24276385e-01 3.56920399e-02 -2.41409671e-02 2.32805774e-01 -8.75988677e-02 -2.89126188e-02 -2.56559085e-02 3.59742008e-02 -1.71378091e-01 -1.57062970e-02 -1.44514963e-01 -6.45076707e-02 7.65323266e-02 -5.45964502e-02 8.99369642e-03 1.18871428e-01 -2.27900982e-01 1.17893651e-01 3.38294841e-02 -1.48606580e-02 9.51796919e-02 8.59544352e-02 -7.98148885e-02 -3.33232321e-02 1.14725292e-01 -2.41587505e-01 2.73435503e-01 2.23574698e-01 4.14235108e-02 1.68515399e-01 7.83172250e-02 2.53354982e-02 -4.53720056e-02 1.27424598e-02 -1.78775147e-01 -6.32874891e-02 4.40627933e-02 1.67294331e-02 5.63010573e-02 1.42770782e-02] 0.43092407321591797 It&apos;s the same person]]></content>
      <tags>
        <tag>dlib</tag>
        <tag>Python</tag>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[困倦探测]]></title>
    <url>%2F2019%2F08%2F27%2Fdlib-kun%2F</url>
    <content type="text"><![CDATA[困倦探测器算法我们的困倦检测算法的一般流程相当简单。 首先，我们将设置一个监视面部流的摄像头： 如果找到了面部，我们应用面部标志检测并提取眼部区域： 现在我们有眼睛区域，我们可以计算眼睛纵横比，以确定眼睛是否闭合： 123456789# import the necessary packagesfrom scipy.spatial import distance as distfrom imutils.video import VideoStreamfrom imutils import face_utilsimport numpy as npimport imutilsimport timeimport dlibimport cv2 eye_aspect_ratio 函数，该函数用于计算垂直眼睛地标与水平眼睛地标之间距离的比率： 123456789101112131415def eye_aspect_ratio(eye): # compute the euclidean distances between the two sets of # vertical eye landmarks (x, y)-coordinates A = dist.euclidean(eye[1], eye[5]) B = dist.euclidean(eye[2], eye[4]) # compute the euclidean distance between the horizontal # eye landmark (x, y)-coordinates C = dist.euclidean(eye[0], eye[3]) # compute the eye aspect ratio ear = (A + B) / (2.0 * C) # return the eye aspect ratio return ear 当眼睛打开时，眼睛纵横比的返回值将近似恒定。然后，该值将在眨眼期间快速减小到零。 如果眼睛闭合，眼睛纵横比将再次保持近似恒定，但将 远小于眼睛打开时的比率。 在我们的困倦探测器情况下，我们将监测眼睛纵横比，看看该值是否 下降但 不再增加，从而暗示该人已闭上眼睛。 定义参数 EYE_AR_THRESH 默认0.3 1234567891011# define two constants, one for the eye aspect ratio to indicate# blink and then a second constant for the number of consecutive# frames the eye must be below the threshold for to set off the# alarmEYE_AR_THRESH = 0.3EYE_AR_CONSEC_FRAMES = 48 # initialize the frame counter as well as a boolean used to# indicate if the alarm is going offCOUNTER = 0ALARM_ON = False dlib库附带了一个基于方向梯度的直方图面部检测器以及面部标志预测器 - 我们在以下代码块中实例化这两个： 12345# initialize dlib's face detector (HOG-based) and then create# the facial landmark predictorprint("[INFO] loading facial landmark predictor...")detector = dlib.get_frontal_face_detector()predictor = dlib.shape_predictor('cnn/shape_predictor_68_face_landmarks.dat') [INFO] loading facial landmark predictor... dlib生成的面部标志是一个可索引的列表，我在这里描述： 因此，要从一组面部标志中提取眼睛区域，我们只需要知道正确的阵列切片索引： 1234# grab the indexes of the facial landmarks for the left and# right eye, respectively(lStart, lEnd) = face_utils.FACIAL_LANDMARKS_IDXS["left_eye"](rStart, rEnd) = face_utils.FACIAL_LANDMARKS_IDXS["right_eye"] 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586# start the video stream threadprint("[INFO] starting video stream thread...")vs = VideoStream(src='rtsp://admin:thrn.com@192.168.2.214:554/h264/ch33/main/av_stream').start()time.sleep(1.0) # loop over frames from the video streamwhile True: # grab the frame from the threaded video file stream, resize # it, and convert it to grayscale # channels) frame = vs.read() frame = imutils.resize(frame, width=450) gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # detect faces in the grayscale frame rects = detector(gray, 0) # loop over the face detections for rect in rects: # determine the facial landmarks for the face region, then # convert the facial landmark (x, y)-coordinates to a NumPy # array shape = predictor(gray, rect) shape = face_utils.shape_to_np(shape) # extract the left and right eye coordinates, then use the # coordinates to compute the eye aspect ratio for both eyes leftEye = shape[lStart:lEnd] rightEye = shape[rStart:rEnd] leftEAR = eye_aspect_ratio(leftEye) rightEAR = eye_aspect_ratio(rightEye) # average the eye aspect ratio together for both eyes ear = (leftEAR + rightEAR) / 2.0 # compute the convex hull for the left and right eye, then # visualize each of the eyes leftEyeHull = cv2.convexHull(leftEye) rightEyeHull = cv2.convexHull(rightEye) cv2.drawContours(frame, [leftEyeHull], -1, (0, 255, 0), 1) cv2.drawContours(frame, [rightEyeHull], -1, (0, 255, 0), 1) # check to see if the eye aspect ratio is below the blink # threshold, and if so, increment the blink frame counter if ear &lt; EYE_AR_THRESH: COUNTER += 1 # if the eyes were closed for a sufficient number of # then sound the alarm if COUNTER &gt;= EYE_AR_CONSEC_FRAMES: # if the alarm is not on, turn it on# if not ALARM_ON:# ALARM_ON = True # # check to see if an alarm file was supplied,# # and if so, start a thread to have the alarm# # sound played in the background# if args["alarm"] != "":# t = Thread(target=sound_alarm,# args=(args["alarm"],))# t.deamon = True# t.start() # draw an alarm on the frame cv2.putText(frame, "DROWSINESS ALERT!", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2) # otherwise, the eye aspect ratio is not below the blink # threshold, so reset the counter and alarm else: COUNTER = 0 ALARM_ON = False # draw the computed eye aspect ratio on the frame to help # with debugging and setting the correct eye aspect ratio # thresholds and frame counters cv2.putText(frame, "EAR: &#123;:.2f&#125;".format(ear), (300, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2) # show the frame cv2.imshow("Frame", frame) key = cv2.waitKey(1) &amp; 0xFF # if the `q` key was pressed, break from the loop if key == ord("q"): break # do a bit of cleanupcv2.destroyAllWindows()vs.stop() [INFO] starting video stream thread...]]></content>
      <tags>
        <tag>dlib</tag>
        <tag>opencv</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面部标志探测器]]></title>
    <url>%2F2019%2F08%2F27%2Fdlib%2F</url>
    <content type="text"><![CDATA[Dlib的5点面部标志探测器当68点探测器定位沿着眼睛，眉毛，鼻子，嘴巴和下颚线的区域时，5点面部标志探测器将此信息减少为： 左眼2分 右眼2分 1分为鼻子 5点探测器比原始版本快8-10％，模型尺寸：分别为9.2MB和99.7MB（小于10倍）。 通常，在选择面部检测模型时，您会发现以下指南是一个很好的起点： Haar级联：快速，但不太准确。调整参数可能很痛苦。 HOG +线性SVM：通常（显着）比Haar级联更准确，误报率更低。通常在测试时调整的参数较少。与Haar级联相比可能会很慢。 基于深度学习的探测器：正确训练后，比Haar级联和HOG +线性SVM更加准确和稳健。根据模型的深度和复杂程度，可能会非常慢。可以通过在GPU上进行推理来加速（你可以在这篇文章中看到一个OpenCV深度学习面部探测器）。 使用dlib，OpenCV和Python实现面部标记import12345678# import the necessary packagesfrom imutils.video import VideoStreamfrom imutils import face_utilsimport argparseimport imutilsimport timeimport dlibimport cv2 1# pip install --upgrade imutils 初始化视频流123456789101112# initialize dlib's face detector (HOG-based) and then create the# facial landmark predictorprint("[INFO] loading facial landmark predictor...")detector = dlib.get_frontal_face_detector()predictor = dlib.shape_predictor('cnn/shape_predictor_68_face_landmarks.dat') # initialize the video stream and sleep for a bit, allowing the# camera sensor to warm upprint("[INFO] camera sensor warming up...")vs = VideoStream(src='rtsp://admin:thrn.com@192.168.2.214:554/h264/ch33/main/av_stream').start()# vs = VideoStream(usePiCamera=True).start() # Raspberry Pitime.sleep(2.0) [INFO] loading facial landmark predictor... [INFO] camera sensor warming up... 启动跟踪123456789101112131415161718192021222324252627282930313233343536373839404142434445464748# loop over the frames from the video streamwhile True: # grab the frame from the threaded video stream, resize it to # have a maximum width of 400 pixels, and convert it to # grayscale frame = vs.read() frame = imutils.resize(frame, width=800) gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # detect faces in the grayscale frame rects = detector(gray, 0) # check to see if a face was detected, and if so, draw the total # number of faces on the frame if len(rects) &gt; 0: text = "&#123;&#125; face(s) found".format(len(rects)) cv2.putText(frame, text, (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2) # loop over the face detections for rect in rects: # compute the bounding box of the face and draw it on the # frame (bX, bY, bW, bH) = face_utils.rect_to_bb(rect) cv2.rectangle(frame, (bX, bY), (bX + bW, bY + bH), (0, 255, 0), 1) # determine the facial landmarks for the face region, then # convert the facial landmark (x, y)-coordinates to a NumPy # array shape = predictor(gray, rect) shape = face_utils.shape_to_np(shape) # loop over the (x, y)-coordinates for the facial landmarks # and draw each of them for (i, (x, y)) in enumerate(shape): cv2.circle(frame, (x, y), 1, (0, 0, 255), -1) cv2.putText(frame, str(i + 1), (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.35, (0, 0, 255), 1) # show the frame cv2.imshow("Frame", frame) key = cv2.waitKey(1) &amp; 0xFF # if the `q` key was pressed, break from the loop if key == ord("q"): break # do a bit of cleanupcv2.destroyAllWindows()vs.stop() dlib的5点或68点面部标志检测器更快吗？在我自己的测试中，我发现dlib的5点面部标志探测器比原来的68点面部标志探测器快8-10％。 加速8-10％是显着的; 但是，更重要的是模型的大小。 最初的68点面部地标接近100MB，重达99.7MB。 5点面部标志探测器低于10MB，仅为9.2MB - 超过10倍的小型号！ 当您构建自己的应用程序使用面部标记时，您现在拥有一个小得多的模型文件，可以与您的应用程序的其余部分一起分发。 较小的型号尺寸也无需嘲笑 - 只需考虑移动应用用户的下载时间/资源减少！ 5点面部标志探测器的局限性5点面部标志检测器的主要用途是面部对齐： 对于面部对齐，可以将5点面部标志检测器视为68点检测器的直接替代品 - 相同的通用算​​法适用： 计算5点面部标志 根据每只眼睛的两个界标分别计算每只眼睛的中心 通过利用眼睛之间的中点来计算眼睛质心之间的角度 通过应用仿射变换获得面部的规范对齐 虽然68点面部标志探测器可以给我们稍微更好的近似眼睛中心，但实际上你会发现5点面部标志探测器也能正常工作。 尽管如此，虽然5点面部标志探测器肯定更小（分别为9.2MB和99.7MB），但并不能在所有情况下使用。]]></content>
      <tags>
        <tag>Python</tag>
        <tag>opencv</tag>
        <tag>Dlib</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jupyter用法]]></title>
    <url>%2F2019%2F08%2F26%2Fjupyter%2F</url>
    <content type="text"><![CDATA[将本地的.py文件load到jupyter的一个cell中12# %load test.pyprint('test') test jupyter的cell可以作为unix command使用1!python --version Python 3.7.0b2 1!python test.py test 从网络load代码到jupyter1# %load https://matplotlib.org/examples/color/color_cycle_demo.html 获取current working directory12current_path = %pwd print(current_path) G:\tensorflow\Jupyter 运行代码1print("Hello, World!") Hello, World! 12345678for letter in 'Python': # 第一个实例 print('当前字母 :', letter) fruits = ['banana', 'apple', 'mango']for fruit in fruits: # 第二个实例 print('当前水果 :', fruit) print("Good bye!") 当前字母 : P 当前字母 : y 当前字母 : t 当前字母 : h 当前字母 : o 当前字母 : n 当前水果 : banana 当前水果 : apple 当前水果 : mango Good bye! 使用Matplotlib绘图1%matplotlib inline 1234567import matplotlib.pyplot as pltimport numpy as npx = np.arange(20)y = x**2plt.plot(x, y) [&lt;matplotlib.lines.Line2D at 0x1d3e0edc3c8&gt;] 12]]></content>
      <tags>
        <tag>jupyter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用OpenCV 3.4.1 DNN模块的MobileNet SSD对象检测]]></title>
    <url>%2F2019%2F08%2F23%2Fopencv-dnn-1%2F</url>
    <content type="text"></content>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[opencv-dnn]]></title>
    <url>%2F2019%2F08%2F22%2Fopencv-dnn%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title><![CDATA[opencv 人脸识别]]></title>
    <url>%2F2019%2F08%2F20%2Fopencv-face%2F</url>
    <content type="text"><![CDATA[步骤 训练数据收集:收集您想要识别的人的面部数据(本例中为面部图像) 识别器的训练:将人脸数据(以及每个人脸的相应名称)输入人脸识别器，使其能够学习。 识别:输入这些人的新面孔，看看你刚训练过的人脸识别器是否识别他们 OpenCV带有内置的人脸识别器1、EigenFaces人脸识别器识别器 - cv2.face.createEigenFaceRecognizer() 2、FisherFaces人脸识别器识别器 - cv2.face.createFisherFaceRecognizer() 3、局部二值模式直方图（LBPH）人脸识别器 - cv2.face.createLBPHFaceRecognizer() EigenFaces面部识别器这个算法考虑的事实是，并不是脸的所有部分都同样重要，或同样有用。当你看一个人的时候，你会通过他独特的特征认出他/她，比如眼睛、鼻子、脸颊、前额以及他们之间的差异。所以你实际上关注的是最大变化的区域(数学上说，这个变化是方差)。例如，从眼睛到鼻子有一个显著的变化，从鼻子到嘴也是如此。当你看多张脸的时候你可以通过看脸的这些部分来比较它们因为这些部分是脸最有用和最重要的组成部分。重要的是，它们捕捉到人脸之间的最大变化，这种变化可以帮助你区分不同的人脸，这就是特征人脸识别系统的工作原理。 EignFaces人脸识别器将所有人的训练图像作为一个整体，并试图提取重要和有用的成分(捕捉最大方差/变化的成分)，并丢弃其余的成分。这样，它不仅从训练数据中提取重要的组件，而且通过丢弃不重要的组件来节省内存。它提取的这些重要成分被称为主成分。 我所用主成分，方差，高变化区域，可互换的有用特征等术语，它们的性质基本上是一样的东西。 以下是显示从面部列表中提取的主要组件的图像。 FisherFaces人脸识别器算法是改进后的FisherFaces人脸识别算法。FisherFaces人脸识别器同时查看所有人的训练面，并从所有人的训练面中找到主要的组成部分。通过从所有的人脸中捕获主要的组成部分，你并没有把注意力集中在区分一个人和另一个人的特征上，而是集中在代表整个训练数据中所有人的所有面孔的特征上。 局部二值模式直方图(LBPH)人脸识别器我们知道Eigenfaces和Fisherfaces都受光线影响，在现实生活中，我们无法保证完美的光照条件。 LBPH人脸识别器是克服这个缺点的一种改进。 这种想法是不看整个图像，而是查找图像的局部特征。 LBPH算法试图找出图像的局部结构，并通过比较每个像素与其相邻像素来实现。 取一个3x3的窗口，每移动一个图像(图像的每个局部)，将中心的像素与相邻像素进行比较。强度值小于或等于中心像素的邻域用1表示，其它邻域用0表示。然后你以顺时针的顺序读取3x3窗口下的0/1值，你会得到一个像11100011这样的二进制模式，这个模式在图像的特定区域是局部的。在整个图像上这样做，就会得到一个局部二进制模式的列表。 转载：https://www.cnblogs.com/zhuifeng-mayi/p/9171383.html]]></content>
      <tags>
        <tag>opencv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos 搭建ss服务器]]></title>
    <url>%2F2019%2F08%2F19%2Fshadowsocks%2F</url>
    <content type="text"><![CDATA[安装pipyum install python-setuptools &amp;&amp; easy_install pip 安装 shadowsockspip install shadowsocks 配置vi /etc/shadowsocks.json 1234567891011121314151617&#123;&quot;server&quot;:&quot;你的ip地址&quot;,&quot;server_port&quot;:443,&quot;local_address&quot;:&quot;127.0.0.1&quot;,&quot;local_port&quot;:1080,&quot;password&quot;:&quot;MyPass&quot;,&quot;timeout&quot;:600,&quot;method&quot;:&quot;rc4-md5&quot;&#125; 启动服务ssserver -c /etc/shadowsocks.json -d start 停止服务ssserver -c /etc/shadowsocks.json -d stop]]></content>
      <tags>
        <tag>Centos</tag>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vs code 通过ssh 远程连接 linux]]></title>
    <url>%2F2019%2F08%2F08%2Fssh-vs%2F</url>
    <content type="text"><![CDATA[vscode 安装 Remote Development 插件配置 Remote-ssh 配置文件一般放在用户目录下的 .ssh 1234Host AliServer HostName 192.168.2.247 User mbb IdentityFile C:\Users\Tmac\.ssh\id_rsa 配置windows下的sshcd 到 .ssh 执行 ssh-keygen 生成秘钥 linux下配置ssh将windows生成的公钥文件 id_rsa.pub 复制到 用户目录下 .ssh 执行 cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys]]></content>
      <tags>
        <tag>ssh</tag>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vscode源码剖析]]></title>
    <url>%2F2019%2F06%2F25%2Fvs-code%2F</url>
    <content type="text"><![CDATA[vscode作为微软推出的现代编辑器已经在GitHub上开源了。用过vscode的人都纷纷表示速度极快，秒杀同为使用Electron架构的Atom。这次我们从源码级别来剖析为何vscode快速，高效。 ElectronElectron 是基于 Node.js 和 Chromium 的跨平台桌面应用开发框架。使用 JavaScipt，HTML，CSS 真正将 Node.js 带到了前端。Electron 通过 BrowserWindow 可以创建一个本地窗口，并加载一个HTML文档，BrowserWindow中的内容就是一个浏览器窗口，不仅能创建DOM元素，同时能使用任意的Node模块，并且还可以通过IPC与主进程通讯。 多进程每一个 Electron 应用都对应一个主进程(main process)， 主进程通过BrowserWindow创建的每个本地窗口对应一个渲染进程(renderer process)。 主进程vscode的主进程主要负责创建窗口和菜单，生命周期管理，自动更新等与系统相关的功能。 渲染进程绝大多数代码都是运行在渲染进程中的，渲染进程负责界面的显示，响应用户操作。前面说到在浏览器中也可以使用Node模块，渲染进程还通过Node创建了一个插件子进程，负责插件的初始化。另外渲染进程还可以创建Worker执行一些复杂的计算，比如markdown的解析。 插件进程每一个渲染进程同时也对应一个插件进程，插件运行在单独的进程不会对渲染进程造成影响，这也是vscode比atom要快的原因。Atom中插件是直接运行在渲染进程中的，所以当插件很多的时候会卡。同时又由于vscode的插件运行在一个普通的Node进程中，所以对UI的操作能力是比较弱的，这点不及Atom。 VSCode LoaderVSCode Loader是类似于 RequireJS 的一个异步加载模块(AMD)。所有的TypeScript源码都被编译成了使用AMD规范的js文件，使用时通过这个loader加载。 虽然主进程(Node进程)是使用CommonJS规范的，但是在浏览器中的代码加载是异步的，所以使用AMD是没有争议的。在vscode中的一些核心代码，基本库都是用TypeScript编写的，也会被编译成AMD规范的js，这些基本代码也会被主进程用到，所以主进程里面也用到了这个loader。同理，插件进程和Worker都会使用这个loader加载代码。 VSCode Loader不仅实现了类似RequireJS的模块加载功能，还附带几个插件可以加载css(css.js)和文档，以及实现多语言。 项目结构vscode的主要目录结构如下: 12345678910111213141516├── build // gulp打包编译相关脚本├── node_modules // 依赖模块├── src // 源代码和素材(ts,js,css,svg,html等)│ ├── typings // 常用模块定义│ ├── vs│ │ ├── base // 核心模块，常用库和基本组件│ │ ├── editor // 编辑器模块│ │ ├── languages // 默认编辑器语言支持│ │ ├── platform // 核心功能接口定义和基本实现│ │ ├── workbench // 业务逻辑功能实现│ │ ├── loader.js // vscode loader│ │ └── vscode.d.ts // 插件API定义│ └── main.js // 主进程入口├── gulpfile.js // gulp打包编译入口├── product.json // 产品描述文件└── package.json basebase包封装了大量API，实现常用功能。在vscode中目录结构都是都是按照browser，common，node，electron的方式划分的。 browser 实现浏览器相关的功能。common 实现不依赖node模块的基本功能。node 实现需要node模块支持的功能，比如文件操作。electron 实现需要electron api的功能，比如ipc通讯。 browserbrowser中实现了一个简单的UI库，包括 Button，CheckBox，List，Scrollbar等常用组件。并且封装了一套类似JQuery的DOM操作API(参见 dom.ts 和 builder.ts)。 commoncommon包中封装了大量实用工具类。如 arrays.ts，strings.ts，objects.ts 封装了一套类似underscore的api。uri.ts 和 paths.ts 实现了路径解析功能。winjs.base.js 实现了一个功能强大的Promise。另外还有很多其他的工具类，每一个模块的耦合度都很低，基本都可以单独拿出来用，学习起来也和容易。这里就不一一介绍了。 nodenode包中封装了一些node实现的功能。如 extfs.ts 和 pfs.ts 封装了文件操作相关的api。request.ts 封装了网络请求的api，能方便的发送网络请求，加载json，下载文件。service.cp.ts 和 service.net.ts 封装了socket和进程通讯的api。zip.ts 封装了解压缩文件的操作 ##parts 这个包额外定义了一些复杂的UI组件，tree 和 quickopen。 editor and language本篇主要了解vscode基本框架的结构，这两包作为编辑器功能的主要实现，这里面的逻辑太复杂就不细说了。 platform and workbenchvscode中基本所有的具体功能实现代码都在这两包中。platform主要定义了一些服务的接口和简单实现，workbench则实现了这些接口，并且创建了一个工作台，构建了一个完整界面结构。 下面从程序入口开始，从源码一步一步来看vscode是怎样运行起来的。 启动主进程Eletron通过package.json中的main字段来定义应用入口。main.js 是vscode的入口。 初始化loader这个模块是一个壳，主要解析多语言配置，然后初始化loader，通过loader加载 main.ts。 123456// Load our code once readyapp.once('ready', function () &#123; var nlsConfig = getNLSConfiguration(); process.env['VSCODE_NLS_CONFIG'] = JSON.stringify(nlsConfig); require('./bootstrap-amd').bootstrap('vs/workbench/electron-main/main');&#125;); 这里的 bootstrap-amd.js 负责创建一个loader，实现异步加载。 12345678910111213141516loader.config(&#123; baseUrl: uriFromPath(path.join(__dirname)), catchError: true, nodeRequire: require, nodeMain: __filename, 'vs/nls': nlsConfig&#125;);......exports.bootstrap = function (entrypoint) &#123; if (!entrypoint) &#123; return; &#125; loader([entrypoint], function () &#123; &#125;, function (err) &#123; console.error(err); &#125;);&#125;; 解析命令行参数在 main.ts 中依赖一个 env 的模块 1import env = require('vs/workbench/electron-main/env'); 该模块负责命令行参数的解析，以及读取 package.json 和 product.json 保存软件的一些基本信息，主要变量如下： 123456789101112131415161718// 是否是发行版export const isBuilt = !process.env.VSCODE_DEV;// 应用程序根目录export const appRoot = path.dirname(uri.parse(require.toUrl('')).fsPath);// 产品配置export const product: IProductConfiguration = productContents;// 程序版本export const version = app.getVersion();// 命令行参数export const cliArgs = parseCli();// 数据文件目录export const appHome = app.getPath('userData');// setting文件路径export const appSettingsPath = path.join(appSettingsHome, 'settings.json');// keybindings文件路径export const appKeybindingsPath = path.join(appSettingsHome, 'keybindings.json');// 用户插件目录export const userExtensionsHome = cliArgs.extensionsHomePath || path.join(userHome, 'extensions'); 初始化管理器在main.ts的main方法中，初始化了主进程中的各个管理器 12345678910111213141516// Lifecyclelifecycle.manager.ready();// Load settingssettings.manager.loadSync();// Propagate to clientswindows.manager.ready(userEnv);// Install Menumenu.manager.ready();.....// Setup auto updateUpdateManager.initialize(); lifecycle 负责管理软件的生命周期，派发onBeforeQuit等事件。 setting 负责管理用户设置和快捷键绑定的读取和存储。 windows 负责窗口的创建和管理，非常核心的一个模块。 menus 负责菜单栏的创建。 update-manager 自动更新功能。以上管理器中大量使用了Eletron的 ipc 模块发送接收渲染进程的消息，来实现主进程和渲染进程的交互。 打开第一个窗口在main.ts的main方法的最后 12345678// Open our first windowif (env.cliArgs.openNewWindow &amp;&amp; env.cliArgs.pathArguments.length === 0) &#123; windows.manager.open(&#123; cli: env.cliArgs, forceNewWindow: true, forceEmpty: true &#125;); // new window if "-n" was used without paths&#125; else if (global.macOpenFiles &amp;&amp; global.macOpenFiles.length &amp;&amp; (!env.cliArgs.pathArguments || !env.cliArgs.pathArguments.length)) &#123; windows.manager.open(&#123; cli: env.cliArgs, pathsToOpen: global.macOpenFiles &#125;); // mac: open-file event received on startup&#125; else &#123; windows.manager.open(&#123; cli: env.cliArgs, forceNewWindow: env.cliArgs.openNewWindow, diffMode: env.cliArgs.diffMode &#125;); // default: read paths from cli&#125; 调用了 windows 模块的 open 方法打开了第一个窗口。这里调用了 env.cliArgs 获取命令行参数传递给 open 方法来实现不同的打开方式。 在 open 方法中创建一个了 VSCodeWindow 实例，并且通过 toConfiguration 方法创建了一个 IWindowConfiguration 的对象。 IWindowConfiguration 中定义了大量的 env 中的信息，包括环境变量，命令行参数，软件信息等。在之后 IWindowConfiguration 会作为参数传递给 VSCodeWindow 的 load 方法。 VSCodeWindow 包装了一个 BrowserWindow 对象。load 方法调用 getUrl 加载了一个的 html文件。 12345678private getUrl(config: IWindowConfiguration): string &#123; let url = require.toUrl('vs/workbench/electron-browser/index.html'); // Config url += '?config=' + encodeURIComponent(JSON.stringify(config)); return url;&#125; 可以看到 IWindowConfiguration 被序列化成字符串作为参数传递给了 index.html。由于在浏览器进程要获取主进程中 env 模块的数据比较复杂(需要使用 ipc 通讯)。所以这里直接将一些基本信息打包成config传递给了浏览器进程。这时浏览器窗口才正式打开并初始化。 启动浏览器初始化loader浏览器的入口在 index.html 中。与主进程类似这里也对loader进行了初始化并加载浏览器主模块 main 。主要代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 解析config参数var args = parseURLQueryArgs();var configuration = JSON.parse(args['config']);......// loader的加载根目录var rootUrl = uriFromPath(configuration.appRoot) + '/out';// 加载loadercreateScript(rootUrl + '/vs/loader.js', function() &#123; // 多语言配置 var nlsConfig; try &#123; var config = process.env['VSCODE_NLS_CONFIG']; if (config) &#123; nlsConfig = JSON.parse(config); &#125; &#125; catch (e) &#123; &#125; if (!nlsConfig) &#123; nlsConfig = &#123; availableLanguages: &#123;&#125; &#125;; &#125; // 配置loader require.config(&#123; baseUrl: rootUrl, 'vs/nls': nlsConfig, recordStats: configuration.enablePerformance &#125;); ...... require([ // 项目正式发布后大多数的js都被合并进了workbench.main.js中 'vs/workbench/workbench.main', 'vs/nls!vs/workbench/workbench.main', 'vs/css!vs/workbench/workbench.main' ], function() &#123; timers.afterLoad = new Date(); // 浏览器主模块 var main = require('vs/workbench/electron-browser/main'); // config作为参数，调用startup启动主模块 main.startup(configuration, globalSettings).then(function() &#123; mainStarted = true; &#125;, function(error) &#123; onError(error, enableDeveloperTools) &#125;); &#125;);&#125;); 初始化工作台在 main 模块的 startup 方法中进一步加工 config，并创建了一个 workspace。 123456789101112131415161718192021222324252627282930313233export function startup(environment: IMainEnvironment, globalSettings: IGlobalSettings): winjs.TPromise&lt;void&gt; &#123; // 将主进程中的环境变量合并到浏览器进程 assign(process.env, environment.userEnv); // Shell Configuration let shellConfiguration: IConfiguration = &#123; env: environment &#125;; ...... let shellOptions: IOptions = &#123; ...... &#125;; ...... // Open workbench return openWorkbench(getWorkspace(environment), shellConfiguration, shellOptions);&#125;function getWorkspace(environment: IMainEnvironment): IWorkspace &#123; if (!environment.workspacePath) &#123; return null; &#125; ...... let workspace: IWorkspace = &#123; 'resource': workspaceResource, 'id': platform.isLinux ? realWorkspacePath : realWorkspacePath.toLowerCase(), 'name': folderName, 'uid': platform.isLinux ? folderStat.ino : folderStat.birthtime.getTime(), 'mtime': folderStat.mtime.getTime() &#125;; return workspace;&#125; 这里的 environment 就是上文的 config。 IWorkspace 记录了当前打开的文件夹路径等信息(当打开单文件时 IWorkspace 不存在)。 12345678910111213141516function openWorkbench(workspace: IWorkspace, configuration: IConfiguration, options: IOptions): winjs.TPromise&lt;void&gt; &#123; let eventService = new EventService(); let contextService = new WorkspaceContextService(eventService, workspace, configuration, options); let configurationService = new ConfigurationService(contextService, eventService); return configurationService.initialize().then(() =&gt; &#123; ...... let shell = new WorkbenchShell(document.body, workspace, &#123; configurationService, eventService, contextService &#125;, configuration, options); shell.open(); ...... &#125;);&#125; 在 openWorkbench 创建了三个基本服务(Service)，并将 config，workspace 等参数传给 WorkbenchShell 。WorkbenchShell 获取html文档的 body 节点准备创建界面。 初始化服务WorkbenchShell 主要负责初始化各服务(Service)，并创建了一个 Workbench 完成界面的初始化工作。 常用的Service比如 IStorageService 浏览器进程数据的持久化存储与读取。 IWorkspaceContextService 获取工作空间数据和config等基本配置信息。 IKeybindingService 管理快捷键相关的注册。 IFileService 封装了文件操作的相关API，并实现 FileWatcher 功能。 IExtensionService 管理插件的初始化，加载和交互。 IInstantiationService 负责创建实例对象，这个Service比较重要，下面单独说明。 initInstantiationService 方法中创建了各个服务，并返回 IInstantiationService。 IInstantiationService 在vscode中随处可见 IInstantiationService 的应用。以 CloseWindowAction 为例 123456789101112131415export class CloseWindowAction extends Action &#123; public static ID = 'workbench.action.closeWindow'; public static LABEL = nls.localize('closeWindow', "Close Window"); constructor(id: string, label: string, @IWindowService private windowService: IWindowService) &#123; super(CloseWindowAction.ID, label); &#125; public run(): TPromise&lt;boolean&gt; &#123; this.windowService.getWindow().close(); return TPromise.as(true); &#125;&#125; 在构造函数(constructor)中，后面的参数写法比较特殊 @IWindowService private windowService: IWindowService使用了 @IWindowService 这种decorate语法。当要创建 CloseWindowAction 这个实例时，可以使用 IInstantiationService 只需要传入前两个参数，在IInstantiationService 中能获取所有的其他服务对象， windowService 这个参数由 IInstantiationService 传入。 1this.instantiationService.createInstance(CloseWindowAction, CloseWindowAction.ID， CloseWindowAction.LABEL); 创建WorkbenchWorkbenchShell 的 createContents 方法还创建了一个 Workbench 负责整个界面的创建。 1234567891011121314151617private createContents(parent: Builder): Builder &#123; ...... // Instantiation service with services let instantiationService = this.initInstantiationService(); ...... // Workbench this.workbench = new Workbench(workbenchContainer.getHTMLElement(), this.workspace, this.configuration, this.options, instantiationService); this.workbench.startup(&#123; onServicesCreated: () =&gt; &#123; this.initExtensionSystem(); &#125;, onWorkbenchStarted: () =&gt; &#123; this.onWorkbenchStarted(); &#125; &#125;); ......&#125; Workbench 是 IPartService 的具体实现。vscode由多个Part组成。 activitybar 是最左边(也可以设置到右边)的选项卡。目前有 Explore，Search，Git，Debug 这4个选项卡。 sidebar 是activitybar选中的内容。 editor 是最主要的编辑器部分。 statusbar 是下方的状态栏。 panel 是状态栏上方的面板选项卡，目前主要有 output，debug，errorlist 等几个面板。 quickopen 是悬浮在中上方的弹出界面，常用的命令面板(F1)就是一个quickopen widget。 下面的代码展示了各个part的创建，并添加到显示列表。 123456789101112131415private renderWorkbench(): void &#123; ...... // Create Parts this.createActivityBarPart(); this.createSidebarPart(); this.createEditorPart(); this.createPanelPart(); this.createStatusbarPart(); // Create QuickOpen this.createQuickOpen(); // Add Workbench to DOM this.workbenchContainer.build(this.container);&#125; 扩展点的注册和实现vscode中几乎每个部分都是可扩展的。例如最常见的有快捷键命令的注册，编辑器类型的扩展，扩展输出面板Channel。下面以 ViewletRegistry 为例，分析 activitybar 和 sidebar 上面的 Explore 文件浏览器是如何显示的。 contribution通常情况下以 .contribution 结尾的模块，都用作扩展点的注册。由于一般情况下这些模块不会被其他模块依赖，所以要提供一个入口来加载这些模块，这个入口就是 workbench.main。 其中 Explore 文件浏览器的注册是在 files.contribution 中定义的。 123456789101112// Register Viewlet(&lt;ViewletRegistry&gt;Registry.as(ViewletExtensions.Viewlets)).registerViewlet(new ViewletDescriptor( 'vs/workbench/parts/files/browser/explorerViewlet', 'ExplorerViewlet', VIEWLET_ID, nls.localize('explore', "Explorer"), 'explore', 0));(&lt;ViewletRegistry&gt;Registry.as(ViewletExtensions.Viewlets)).setDefaultViewletId(VIEWLET_ID);explorerViewlet 模块是 Explore 的界面显示入口。 registryplatform 中定义了 IRegistry 接口及实现。 1234567891011121314151617181920212223export interface IRegistry &#123; /** * Adds the extension functions and properties defined by data to the * platform. The provided id must be unique. * @param id a unique identifier * @param data a contribution */ add(id: string, data: any): void; /** * Returns true iff there is an extension with the provided id. * @param id an extension idenifier */ knows(id: string): boolean; /** * Returns the extension functions and properties defined by the specified key or null. * @param id an extension idenifier */ as(id: string): any; as&lt;T&gt;(id: string): T;&#125; add 添加一个注册点， as 方法获取一个注册点对象。 viewlet 模块添加了 ViewletRegistry。 1Registry.add(Extensions.Viewlets, new ViewletRegistry()); 之后可以通过 Registry.as(Extensions.Viewlets) 获取 ViewletRegistry 注册不同的 Viewlet。 实现注册功能所有的注册信息储存在 ViewletRegistry 中，使用时通过 getViewlet 或者 getViewlets 方法获取。 activitybarPart 实现了注册点的读取，并填充 ActionBar，显示出来。 12345678910111213141516171819202122private createViewletSwitcher(div: Builder): void &#123; // Viewlet switcher is on top this.viewletSwitcherBar = new ActionBar(div, &#123; ....... &#125;); this.viewletSwitcherBar.getContainer().addClass('position-top'); // Build Viewlet Actions in correct order let activeViewlet = this.viewletService.getActiveViewlet(); let registry = (&lt;ViewletRegistry&gt;Registry.as(ViewletExtensions.Viewlets)); let viewletActions: Action[] = registry.getViewlets() // 获取注册的viewlets .sort((v1: ViewletDescriptor, v2: ViewletDescriptor) =&gt; v1.order - v2.order) .map((viewlet: ViewletDescriptor) =&gt; &#123; let action = this.instantiationService.createInstance(ViewletActivityAction, viewlet.id + '.activity-bar-action', viewlet); ...... return action; &#125;); // Add to viewlet switcher this.viewletSwitcherBar.push(viewletActions, &#123; label: true, icon: true &#125;);&#125; 类似的这种扩展点还有很多，如: IWorkbenchActionRegistry 注册一个action和快捷键，并出现在命令面板中。 IEditorRegistry 注册一种编辑器。 IConfigurationRegistry 注册设置项。 IActionBarRegistry 注册右键菜单。这种通过注册扩展点的架构方式，使得vscode整体变得很容易扩展。 VSCode PK Atomvscode整体架构给人一种很清晰明了的感觉。多进程从主进程到浏览器，从浏览器到插件系统，服务驱动，可扩展的结构。 另外无论是UI组件还是工具和加载器都是自身实现的，没有借助第三方模块，使得耦合性和性能都得到了很好的保障。这也是vscode速度比Atom快的原因。 尽管扩展vscode自身是很容易的，但是目前vscode开放的插件接口还是极其有限。由于为了保证渲染进程的安全和速度，插件是一个单独的Node进程，插件进程无法创建UI，这一点使得vscode的插件开放没有Atom灵活，很多需要借助UI的插件功能也无法实现。 转载：http://xzper.com/2016/04/17/vscode%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90/]]></content>
      <tags>
        <tag>vscode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS Grid 网格布局]]></title>
    <url>%2F2019%2F06%2F24%2Fcss-grid%2F</url>
    <content type="text"><![CDATA[http://www.ruanyifeng.com/blog/2019/03/grid-layout-tutorial.html]]></content>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[弹性盒子模型 flex]]></title>
    <url>%2F2019%2F06%2F24%2Fcss-flex%2F</url>
    <content type="text"><![CDATA[Flex 布局是什么？Flex 是 Flexible Box 的缩写，意为”弹性布局”，用来为盒状模型提供最大的灵活性。任何一个容器都可以指定为 Flex 布局。 123.box&#123; display: flex;&#125; 行内元素也可以使用 Flex 布局。 123.box&#123; display: inline-flex;&#125; Webkit 内核的浏览器，必须加上-webkit前缀。 1234.box&#123; display: -webkit-flex; /* Safari */ display: flex;&#125; 注意，设为 Flex 布局以后，子元素的float、clear和vertical-align属性将失效。 基本概念采用 Flex 布局的元素，称为 Flex 容器（flex container），简称”容器”。它的所有子元素自动成为容器成员，称为 Fl`ex 项目（flex item），简称”项目”。 容器默认存在两根轴：水平的主轴（main axis）和垂直的交叉轴（cross axis）。主轴的开始位置（与边框的交叉点）叫做main start，结束位置叫做main end；交叉轴的开始位置叫做cross start，结束位置叫做cross end。项目默认沿主轴排列。单个项目占据的主轴空间叫做main size，占据的交叉轴空间叫做cross size。 容器的属性以下6个属性设置在容器上。 123456flex-directionflex-wrapflex-flowjustify-contentalign-itemsalign-content flex-direction属性flex-direction属性决定主轴的方向（即项目的排列方向）。 123.box &#123; flex-direction: row | row-reverse | column | column-reverse;&#125; 它可能有4个值。 1234row（默认值）：主轴为水平方向，起点在左端。row-reverse：主轴为水平方向，起点在右端。column：主轴为垂直方向，起点在上沿。column-reverse：主轴为垂直方向，起点在下沿。 flex-wrap属性默认情况下，项目都排在一条线（又称”轴线”）上。flex-wrap属性定义，如果一条轴线排不下，如何换行。 123.box&#123; flex-wrap: nowrap | wrap | wrap-reverse;&#125; 它可能取三个值。 （1）nowrap（默认）：不换行。 （2）wrap：换行，第一行在上方。 （3）wrap-reverse：换行，第一行在下方。 flex-flowflex-flow属性是flex-direction属性和flex-wrap属性的简写形式，默认值为row nowrap。 123.box &#123; flex-flow: &lt;flex-direction&gt; || &lt;flex-wrap&gt;;&#125; justify-content属性justify-content属性定义了项目在主轴上的对齐方式。 123.box &#123; justify-content: flex-start | flex-end | center | space-between | space-around;&#125; 它可能取5个值，具体对齐方式与轴的方向有关。下面假设主轴为从左到右。 12345flex-start（默认值）：左对齐flex-end：右对齐center： 居中space-between：两端对齐，项目之间的间隔都相等。space-around：每个项目两侧的间隔相等。所以，项目之间的间隔比项目与边框的间隔大一倍。 align-items属性align-items属性定义项目在交叉轴上如何对齐。 123.box &#123; align-items: flex-start | flex-end | center | baseline | stretch;&#125; 它可能取5个值。具体的对齐方式与交叉轴的方向有关，下面假设交叉轴从上到下。 12345flex-start：交叉轴的起点对齐。flex-end：交叉轴的终点对齐。center：交叉轴的中点对齐。baseline: 项目的第一行文字的基线对齐。stretch（默认值）：如果项目未设置高度或设为auto，将占满整个容器的高度。 align-content属性align-content属性定义了多根轴线的对齐方式。如果项目只有一根轴线，该属性不起作用。 123.box &#123; align-content: flex-start | flex-end | center | space-between | space-around | stretch;&#125; 该属性可能取6个值。 123456flex-start：与交叉轴的起点对齐。flex-end：与交叉轴的终点对齐。center：与交叉轴的中点对齐。space-between：与交叉轴两端对齐，轴线之间的间隔平均分布。space-around：每根轴线两侧的间隔都相等。所以，轴线之间的间隔比轴线与边框的间隔大一倍。stretch（默认值）：轴线占满整个交叉轴。 项目的属性以下6个属性设置在项目上。 123456orderflex-growflex-shrinkflex-basisflexalign-self order属性order属性定义项目的排列顺序。数值越小，排列越靠前，默认为0。 123.item &#123; order: &lt;integer&gt;;&#125; flex-grow属性flex-grow属性定义项目的放大比例，默认为0，即如果存在剩余空间，也不放大。 123.item &#123; flex-grow: &lt;number&gt;; /* default 0 */&#125; 如果所有项目的flex-grow属性都为1，则它们将等分剩余空间（如果有的话）。如果一个项目的flex-grow属性为2，其他项目都为1，则前者占据的剩余空间将比其他项多一倍。 flex-shrink属性flex-shrink属性定义了项目的缩小比例，默认为1，即如果空间不足，该项目将缩小。 123.item &#123; flex-shrink: &lt;number&gt;; /* default 1 */&#125; 如果所有项目的flex-shrink属性都为1，当空间不足时，都将等比例缩小。如果一个项目的flex-shrink属性为0，其他项目都为1，则空间不足时，前者不缩小。负值对该属性无效。 flex-basis属性flex-basis属性定义了在分配多余空间之前，项目占据的主轴空间（main size）。浏览器根据这个属性，计算主轴是否有多余空间。它的默认值为auto，即项目的本来大小。 123.item &#123; flex-basis: &lt;length&gt; | auto; /* default auto */&#125; 它可以设为跟width或height属性一样的值（比如350px），则项目将占据固定空间。 flex属性flex属性是flex-grow, flex-shrink 和 flex-basis的简写，默认值为0 1 auto。后两个属性可选。 123.item &#123; flex: none | [ &lt;'flex-grow'&gt; &lt;'flex-shrink'&gt;? || &lt;'flex-basis'&gt; ]&#125; 该属性有两个快捷值：auto (1 1 auto) 和 none (0 0 auto)。建议优先使用这个属性，而不是单独写三个分离的属性，因为浏览器会推算相关值。 align-self属性align-self属性允许单个项目有与其他项目不一样的对齐方式，可覆盖align-items属性。默认值为auto，表示继承父元素的align-items属性，如果没有父元素，则等同于stretch。 123.item &#123; align-self: auto | flex-start | flex-end | center | baseline | stretch;&#125; 该属性可能取6个值，除了auto，其他都与align-items属性完全一致。]]></content>
      <tags>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gateone docker安装配置]]></title>
    <url>%2F2019%2F06%2F13%2Fgateone%2F</url>
    <content type="text"><![CDATA[GateOne是一个能在阅读器上运转的Terminal SSH客户端，不管你在那里，只需有网，你便可以用阅读器操控你的VPS云主机，还支援右键复制/粘贴等客户端经常使用效能，包罗多窗口等，应用起来异常便宜，同时别的人也能够应用，之前也说过一品种似的东西WebSSH2，检察：WebSSH2装置教程，都挺好用的，这边就说下应用Docker快速装置GateOne，并增加SSL证明。 拉取镜像1docker pull liftoff/gateone 启动容器123456789docker run -d -p 443:8000 -h Rats --name gateone -v $PWD/gateone:/etc/gateone/conf.d liftoff/gateone gateone参数说明：-d/-t：决定镜像是使用Deamon（后台）模式启动，或者显示启动过程 -p 443:8000：绑定端口，注意：GateOne强制使用SSL，8000端口为Docker容器内的固定映射端口，请只改动冒号前面的端口，不要动后面的端口号！ -h hostname：设置Docker容器的主机名（这个将会显示在你的浏览器标题中） --name gateone：设置Docker容器的名称（不是主机名），用来docker ps时识别用 liftoff/gateone：镜像名称 gateone：启动命令行，勿动（默认命令行会发生Python io_loop报错，故使用此命令行来避免错误）]]></content>
      <tags>
        <tag>docker</tag>
        <tag>gateone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shadowsocks原理]]></title>
    <url>%2F2019%2F06%2F12%2FShadow%2F</url>
    <content type="text"><![CDATA[本文将教你从0写一个Shadowsocks，无需任何基础，读完本文你就能完成一个轻量级、高性能的 Shadowsocks 代替品。我们暂且把最终完成的项目叫做 Lightsocks，如果你很急切地想看到结果，可以先体验本文最终完成的项目 Lightsocks ，也可以下载阅读源码。 认识 Shadowsockshadowsocks 是一个能骗过防火墙的网络代理工具。它把要传输的原数据经过加密后再传输，网络中的防火墙由于得不出要传输的原内容是什么而只好放行，于是就完成了防火墙穿透，也即是所谓的“翻墙”。 在自由的网络环境下，在本机上访问服务时是直接和远程服务建立连接传输数据，流程如图： 自由网络环境下的传输流程 但在受限的网络环境下会有防火墙，本机电脑和远程服务之间传输的数据都必须通过防火墙的检查，流程如图： 受限网络环境下的传输流程如果防火墙发现你在传输受限的内容，就把拦截本次传输，就会导致在本机无法访问远程服务。 而 Shadowsocks 所做的就是把传输的数据加密，防火墙得到的数据是加密后的数据，防火墙不知道传输的原内容是什么，于是防火墙就放行本次请求，于是在本机就访问到了远程服务，流程如图： shadowsocks下的传输流程 也就是说使用 Shadowsocks 的前提是： 一台在防火墙之外的服务器； 在本机需要安装 Shadowsocks 本地端，用于加密传输数据； 服务器需要安装 Shadowsocks 服务端，用于解密加密后的传输数据，解密出原数据后发送到目标服务器。]]></content>
      <tags>
        <tag>代理</tag>
        <tag>Shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginxhls流媒体m3u8跨域问题]]></title>
    <url>%2F2019%2F05%2F23%2Fnginx-hls-m3u8%2F</url>
    <content type="text"><![CDATA[问题Nginx以HLS+m3u8方式搭建的流媒体报https://www.***.com/crossdomain.xml找不到 解决方案在跨域的网站根目录放crossdomain.xml文件，下面是允许所有的网站（一般不采取这样的方式，我只是方便调试）均可以跨越访问资源配置如下： 123456&lt;?xml version=&quot;1.0&quot;?&gt;&lt;!DOCTYPE cross-domain-policy SYSTEM &quot;http://www.macromedia.com/xml/dtds/cross-domain-policy.dtd&quot;&gt;&lt;cross-domain-policy&gt;&lt;allow-access-from domain=&quot;*&quot; /&gt;&lt;allow-http-request-headers-from domain=&quot;*&quot; headers=&quot;*&quot;/&gt;&lt;/cross-domain-policy&gt;]]></content>
      <tags>
        <tag>m3u8</tag>
        <tag>hls</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo中添加本地图片]]></title>
    <url>%2F2019%2F05%2F23%2Fhexo-img%2F</url>
    <content type="text"><![CDATA[把主页配置文件_config.yml 里的post_asset_folder:这个选项设置为true 在你的hexo目录下执行这样一句话npm install hexo-asset-image –save 运行hexo n “xxxx”来生成md博文时，/source/_posts文件夹内除了xxxx.md文件还有一个同名的文件夹 最后在xxxx.md中想引入图片时，先把图片复制到xxxx这个文件夹中，然后只需要在xxxx.md中按照markdown的格式引入图片： 1![你想输入的替代文字](图片名.jpg)]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HLS协议介绍]]></title>
    <url>%2F2019%2F05%2F23%2Fhls%2F</url>
    <content type="text"><![CDATA[今天来介绍一下HLS协议，这个协议是由苹果公司提出并推广开来的。来一段维基百科的定义。 HTTP Live Streaming（缩写是HLS）是一个由苹果公司提出的基于HTTP的流媒体网络传输协议。是苹果公司QuickTime X和iPhone软件系统的一部分。它的工作原理是把整个流分成一个个小的基于HTTP的文件来下载，每次只下载一些。当媒体流正在播放时，客户端可以选择从许多不同的备用源中以不同的速率下载同样的资源，允许流媒体会话适应不同的数据速率。在开始一个流媒体会话时，客户端会下载一个包含元数据的extended M3U (m3u8)playlist文件，用于寻找可用的媒体流。HLS只请求基本的HTTP报文，与实时传输协议（RTP)不同，HLS可以穿过任何允许HTTP数据通过的防火墙或者代理服务器。它也很容易使用内容分发网络来传输媒体流。苹果公司把HLS协议作为一个互联网草案（逐步提交），在第一阶段中已作为一个非正式的标准提交到IETF。但是，即使苹果偶尔地提交一些小的更新，IETF却没有关于制定此标准的有关进一步的动作。 协议简介HLS协议规定： 视频的封装格式是TS。 视频的编码格式为H264,音频编码格式为MP3、AAC或者AC-3。 除了TS视频文件本身，还定义了用来控制播放的m3u8文件（文本文件）。 为什么苹果要提出HLS这个协议，其实他的主要是为了解决RTMP协议存在的一些问题。比如RTMP协议不使用标准的HTTP接口传输数据，所以在一些特殊的网络环境下可能被防火墙屏蔽掉。但是HLS由于使用的HTTP协议传输数据，不会遇到被防火墙屏蔽的情况（该不会有防火墙连80接口都不放过吧）。另外于负载，RTMP是一种有状态协议，很难对视频服务器进行平滑扩展，因为需要为每一个播放视频流的客户端维护状态。而HLS基于无状态协议（HTTP），客户端只是按照顺序使用下载存储在服务器的普通TS文件，做负责均衡如同普通的HTTP文件服务器的负载均衡一样简单。另外HLS协议本身实现了码率自适应，不同带宽的设备可以自动切换到最适合自己码率的视频播放。其实HLS最大的优势就是他的亲爹是苹果。苹果在自家的IOS设备上只提供对HLS的原生支持，并且放弃了flash。Android也迫于平果的“淫威”原生支持了HLS。这样一来flv，rtmp这些Adobe的视频方案要想在移动设备上播放需要额外下点功夫。当然flash对移动设备造成很大的性能压力确实也是自身的问题。但HLS也有一些无法跨越的坑，比如采用HLS协议直播的视频延迟时间无法下到10秒以下，而RTMP协议的延迟最低可以到3、4秒左右。所以说对直播延迟比较敏感的服务请慎用HLS。 来解释一下这张图，从左到右讲，左下方的inputs的视频源是什么格式都无所谓，他与server之间的通信协议也可以任意（比如RTMP），总之只要把视频数据传输到服务器上即可。这个视频在server服务器上被转换成HLS格式的视频（既TS和m3u8文件）文件。细拆分来看server里面的Media encoder的是一个转码模块负责将视频源中的视频数据转码到目标编码格式（H264）的视频数据，视频源的编码格式可以是任何的视频编码格式（参考《视频技术基础》）。转码成H264视频数据之后，在stream segmenter模块将视频切片，切片的结果就是index file（m3u8）和ts文件了。图中的Distribution其实只是一个普通的HTTP文件服务器，然后客户端只需要访问一级index文件的路径就会自动播放HLS视频流了。 HLS的index文件所谓index文件就是之前说的m3u8文本文件。 如上图所示，客户端播放HLS视频流的逻辑其实非常简单，先下载一级Index file，它里面记录了二级索引文件（Alternate-A、Alternate-B、Alternate-C）的地址，然后客户端再去下载二级索引文件，二级索引文件中又记录了TS文件的下载地址，这样客户端就可以按顺序下载TS视频文件并连续播放。 一级index文件视频源：https://dco4urblvsasc.cloudfront.net/811/81095_ywfZjAuP/game/index.m3u8 123456789#EXTM3U#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=10640001000kbps.m3u8#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=564000500kbps.m3u8#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=282000250kbps.m3u8#EXT-X-STREAM-INF:PROGRAM-ID=1,BANDWIDTH=21280002000kbps.m3u8 bandwidth指定视频流的比特率，PROGRAM-ID无用无需关注，每一个#EXT-X-STREAM-INF的下一行是二级index文件的路径，可以用相对路径也可以用绝对路径。例子中用的是相对路径。这个文件中记录了不同比特率视频流的二级index文件路径，客户端可以自己判断自己的现行网络带宽，来决定播放哪一个视频流。也可以在网络带宽变化的时候平滑切换到和带宽匹配的视频流。 1234567891011121314151617181920212223242526272829#EXTM3U#EXT-X-PLAYLIST-TYPE:VOD#EXT-X-TARGETDURATION:10#EXTINF:10,2000kbps-00001.ts#EXTINF:10,2000kbps-00002.ts#EXTINF:10,2000kbps-00003.ts#EXTINF:10,2000kbps-00004.ts#EXTINF:10,... ...#EXTINF:10,2000kbps-00096.ts#EXTINF:10,2000kbps-00097.ts#EXTINF:10,2000kbps-00098.ts#EXTINF:10,2000kbps-00099.ts#EXTINF:10,2000kbps-00100.ts#ZEN-TOTAL-DURATION:999.66667#ZEN-AVERAGE-BANDWIDTH:2190954#ZEN-MAXIMUM-BANDWIDTH:3536205#EXT-X-ENDLIST 二级文件实际负责给出ts文件的下载地址，这里同样使用了相对路径。#EXTINF表示每个ts切片视频文件的时长。#EXT-X-TARGETDURATION指定当前视频流中的切片文件的最大时长，也就是说这些ts切片的时长不能大于#EXT-X-TARGETDURATION的值。#EXT-X-PLAYLIST-TYPE:VOD的意思是当前的视频流并不是一个直播流，而是点播流，换句话说就是该视频的全部的ts文件已经被生成好了，#EXT-X-ENDLIST这个表示视频结束，有这个标志同时也说明当前的流是一个非直播流。 播放模式 点播VOD的特点就是当前时间点可以获取到所有index文件和ts文件，二级index文件中记录了所有ts文件的地址。这种模式允许客户端访问全部内容。上面的例子中就是一个点播模式下的m3u8的结构。 Live 模式就是实时生成M3u8和ts文件。它的索引文件一直处于动态变化的，播放的时候需要不断下载二级index文件，以获得最新生成的ts文件播放视频。如果一个二级index文件的末尾没有#EXT-X-ENDLIST标志，说明它是一个Live视频流。 客户端在播放VOD模式的视频时其实只需要下载一次一级index文件和二级index文件就可以得到所有ts文件的下载地址，除非客户端进行比特率切换，否则无需再下载任何index文件，只需顺序下载ts文件并播放就可以了。但是Live模式下略有不同，因为播放的同时，新ts文件也在被生成中，所以客户端实际上是下载一次二级index文件，然后下载ts文件，再下载二级index文件（这个时候这个二级index文件已经被重写，记录了新生成的ts文件的下载地址）,再下载新ts文件，如此反复进行播放。 转载： https://www.jianshu.com/p/426425cad08a]]></content>
      <tags>
        <tag>m3u8</tag>
        <tag>hls</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[m3u8说明]]></title>
    <url>%2F2019%2F05%2F23%2Fm3u8%2F</url>
    <content type="text"><![CDATA[m3u8简介原理：将视频或音频流分片，并建立m3u8格式的索引，m3u8可以嵌套（最多支持一层嵌套）。可用于直播或者点播。 格式：m3u8是由独立行组成的文本文件，行分成三类： 以#EXT开头的表示是tag 仅有#表示是注释 uri行表示嵌套的m3u8文件，或者真正的分片流。 m3u8参数一级索引和二级索引中，给出的地址可能是相对地址/绝对地址。相对地址根据一级索引的地址更改。通常一级索引会给出不同带宽的下载链接，可以根据网速适配不同的下载链接，从而避免卡顿。流格式可能是.ts .aac或者RFC支持的其他格式。 m3u8参数 EXTINF：播放时间长度，单位s BANDWIDTH：带宽 EXT-X-ENDLIST：有这个参数，说明是点播，是完整的一段音频或者视频；没有这个参数，说明是直播，需要不断从二级索引中去获取下一片段的链接 EXT-X-MEDIA-SEQUENCE（可选）： 播放列表的第一个音频的序号，如64.m3u8中，有3个音频，序号分别是12591742，12591743,12591744。如果不设置，默认为第一个音频链接序号为0。可以没有这个参数 EXT-X-KEY：可能是加密的，具体见RFC EXT-X-TARGETDURATION：每片最大时长，单位s, #EXTINF应该小于这个值 更多参数参考中文链接：http://www.dnsdizhi.com/m/?post=242 例子一级索引 (可以这一层索引，直接是下面的二级索引）http://devimages.apple.com/iphone/samples/bipbop/bipbopall.m3u8二级索引（在一级索引中根据当前网速找合适的带宽的链接下载）http://devimages.apple.com/iphone/samples/bipbop/gear1/prog_index.m3u8可以直接播放的文件，mpeg2格式http://devimages.apple.com/iphone/samples/bipbop/gear1/fileSequence0.ts bipbopall.m3u8123456789#EXTM3U#EXT-X-STREAM-INF:PROGRAM-ID=1, BANDWIDTH=200000gear1/prog_index.m3u8#EXT-X-STREAM-INF:PROGRAM-ID=1, BANDWIDTH=311111gear2/prog_index.m3u8#EXT-X-STREAM-INF:PROGRAM-ID=1, BANDWIDTH=484444gear3/prog_index.m3u8#EXT-X-STREAM-INF:PROGRAM-ID=1, BANDWIDTH=737777gear4/prog_index.m3u8 prog_index.m3u8 1234567891011121314151617#EXTM3U#EXT-X-TARGETDURATION:10#EXT-X-MEDIA-SEQUENCE:0#EXTINF:10, no descfileSequence0.ts#EXTINF:10, no descfileSequence1.ts#EXTINF:10, no desc.........fileSequence178.ts#EXTINF:10, no descfileSequence179.ts#EXTINF:1, no descfileSequence180.ts#EXT-X-ENDLIST 转载 https://www.cnblogs.com/pukaifei/p/8312936.html]]></content>
      <tags>
        <tag>m3u8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows下配置nginx的m3u8点播服务]]></title>
    <url>%2F2019%2F05%2F23%2Fnginx-hls%2F</url>
    <content type="text"><![CDATA[下载ffmpeg 新建子目录：nginx-1.5.10\html\hls，把生成的m3u8和切片好的ts文件或目录拷贝到hls目录下 打开任务管理其，杀掉ngnix.exe,重启ngnix.exe 打开vlc播放器, 【打开网络串流】菜单，输入url：http://127.0.0.1/hls/playlist.m3u8 即可测试播放了]]></content>
      <tags>
        <tag>m3u8</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ffmpeg视频m3u8切片]]></title>
    <url>%2F2019%2F05%2F23%2Fffmpeg-m3u8%2F</url>
    <content type="text"><![CDATA[首先将视频文件转为视频编码h.264，音频编码aac格式的mp4文件 使用ffprobe查看文件编码方式 1ffprobe xxx.mp4 如果不是mp4的，可以用如下命令进行转 1ffmpeg -i input.mkv -acodec copy -vcodec copy out.mp4 将mp4转为完整的ts1ffmpeg -i out.mp4 -c copy -bsf h264_mp4toannexb output.ts 说明 为什么要用-bsf h264_mp4toannexb,主要是因为使用了mp4中的h264编码，而h264有两种封装：一种是annexb模式，传统模式，有startcode，SPS和PPS是在ES中；另一种是mp4模式，一般mp4、mkv、avi会没有startcode，SPS和PPS以及其它信息被封装在container中，每一个frame前面是这个frame的长度，很多解码器只支持annexb这种模式，因此需要将mp4做转换；在ffmpeg中用h264_mp4toannexb_filter可以做转换；所以需要使用-bsf h264_mp4toannexb来进行转换； 将ts切片，并生成m3u8文件12ffmpeg -i output.ts -c copy -map 0 -f segment -segment_list playlist.m3u8 -segment_time 5 output%03d.ts #其中segment 就是切片，-segment_time表示隔几秒进行切一个文件 m3u8视频文件下载1ffmpeg -i https://dbx3.tyswmp.com/ppvod/0B1CBC90EC065FB92F2ECB5D9E03B4A5.m3u8 Vid.mp4]]></content>
      <tags>
        <tag>ffmpeg</tag>
        <tag>m3u8</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派使用ffmpeg说明]]></title>
    <url>%2F2019%2F05%2F22%2Fpi-ffmpeg%2F</url>
    <content type="text"><![CDATA[编译ffmpeg1https://www.jianshu.com/p/dec9bf9cffc9 用法1234567891011su - lyj#切换用户lyjcd /ffmpeg_build/rpilib#切换目录LD_LIBRARY_PATH=./mylib#添加临时环境变量./ffmpeg -v#执行当前目录下的ffmpeg]]></content>
      <tags>
        <tag>pi</tag>
        <tag>ffmpeg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Chrome.console输出]]></title>
    <url>%2F2019%2F05%2F22%2FChrome-console%2F</url>
    <content type="text"><![CDATA[控制台输出格式1console.log(&quot;%c需要输出的信息 &quot;, &quot;css 代码&quot;); 示例 3D Text: 1console.log(&quot;%c3D Text&quot;,&quot; text-shadow: 0 1px 0 #ccc,0 2px 0 #c9c9c9,0 3px 0 #bbb,0 4px 0 #b9b9b9,0 5px 0 #aaa,0 6px 1px rgba(0,0,0,.1),0 0 5px rgba(0,0,0,.1),0 1px 3px rgba(0,0,0,.3),0 3px 5px rgba(0,0,0,.2),0 5px 10px rgba(0,0,0,.25),0 10px 10px rgba(0,0,0,.2),0 20px 20px rgba(0,0,0,.15);font-size:5em&quot;) Colorful CSS 1console.log(&quot;%cColorful CSS&quot;,&quot;background: rgba(252,234,187,1);background: -moz-linear-gradient(left, rgba(252,234,187,1) 0%, rgba(175,250,77,1) 12%, rgba(0,247,49,1) 28%, rgba(0,210,247,1) 39%,rgba(0,189,247,1) 51%, rgba(133,108,217,1) 64%, rgba(177,0,247,1) 78%, rgba(247,0,189,1) 87%, rgba(245,22,52,1) 100%);background: -webkit-gradient(left top, right top, color-stop(0%, rgba(252,234,187,1)), color-stop(12%, rgba(175,250,77,1)), color-stop(28%, rgba(0,247,49,1)), color-stop(39%, rgba(0,210,247,1)), color-stop(51%, rgba(0,189,247,1)), color-stop(64%, rgba(133,108,217,1)), color-stop(78%, rgba(177,0,247,1)), color-stop(87%, rgba(247,0,189,1)), color-stop(100%, rgba(245,22,52,1)));background: -webkit-linear-gradient(left, rgba(252,234,187,1) 0%, rgba(175,250,77,1) 12%, rgba(0,247,49,1) 28%, rgba(0,210,247,1) 39%, rgba(0,189,247,1) 51%, rgba(133,108,217,1) 64%, rgba(177,0,247,1) 78%, rgba(247,0,189,1) 87%, rgba(245,22,52,1) 100%);background: -o-linear-gradient(left, rgba(252,234,187,1) 0%, rgba(175,250,77,1) 12%, rgba(0,247,49,1) 28%, rgba(0,210,247,1) 39%, rgba(0,189,247,1) 51%, rgba(133,108,217,1) 64%, rgba(177,0,247,1) 78%, rgba(247,0,189,1) 87%, rgba(245,22,52,1) 100%);background: -ms-linear-gradient(left, rgba(252,234,187,1) 0%, rgba(175,250,77,1) 12%, rgba(0,247,49,1) 28%, rgba(0,210,247,1) 39%, rgba(0,189,247,1) 51%, rgba(133,108,217,1) 64%, rgba(177,0,247,1) 78%, rgba(247,0,189,1) 87%, rgba(245,22,52,1) 100%);background: linear-gradient(to right, rgba(252,234,187,1) 0%, rgba(175,250,77,1) 12%, rgba(0,247,49,1) 28%, rgba(0,210,247,1) 39%, rgba(0,189,247,1) 51%, rgba(133,108,217,1) 64%, rgba(177,0,247,1) 78%, rgba(247,0,189,1) 87%, rgba(245,22,52,1) 100%);filter: progid:DXImageTransform.Microsoft.gradient( startColorstr=&apos;#fceabb&apos;, endColorstr=&apos;#f51634&apos;, GradientType=1 );font-size:5em&quot;) Rainbow Text 1console.log(&apos;%cRainbow Text &apos;, &apos;background-image:-webkit-gradient( linear, left top, right top, color-stop(0, #f22), color-stop(0.15, #f2f), color-stop(0.3, #22f), color-stop(0.45, #2ff), color-stop(0.6, #2f2),color-stop(0.75, #2f2), color-stop(0.9, #ff2), color-stop(1, #f22) );color:transparent;-webkit-background-clip: text;font-size:5em;&apos;);]]></content>
      <tags>
        <tag>Chrome</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux如何查看端口状态]]></title>
    <url>%2F2019%2F05%2F22%2Flunx%2F</url>
    <content type="text"><![CDATA[netstat命令各个参数说明如下： 12345678910 -t : 指明显示TCP端口 -u : 指明显示UDP端口 -l : 仅显示监听套接字(所谓套接字就是使应用程序能够读写与收发通讯协议(protocol)与资料的程序) -p : 显示进程标识符和程序名称，每一个套接字/端口都属于一个程序。 -n : 不进行DNS轮询，显示IP(可以加速操作) 即可显示当前服务器上所有端口及进程服务，于grep结合可查看某个具体端口及服务情况·· netstat -ntlp //查看当前所有tcp端口· netstat -ntulp |grep 80 //查看所有80端口使用情况· netstat -an | grep 3306 //查看所有3306端口使用情况· 查看一台服务器上面哪些服务及端口 1netstat -lanp 查看一个服务有几个端口。比如要查看mysqld 1ps -ef |grep mysqld 查看某一端口的连接数量,比如3306端口 1netstat -pnt |grep :3306 |wc 查看某一端口的连接客户端IP 比如3306端口 12345netstat -anp |grep 3306netstat -an 查看网络端口 lsof -i :port，使用lsof -i :port就能看见所指定端口运行的程序，同时还有当前连接。 nmap 端口扫描 123netstat -nupl (UDP类型的端口)netstat -ntpl (TCP类型的端口)netstat -anp 显示系统端口使用情况]]></content>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ss无法上网的排查]]></title>
    <url>%2F2019%2F05%2F22%2Fss-1%2F</url>
    <content type="text"><![CDATA[从日志开始排查。 登录服务器端 1$ ssh root@[IP] 关闭 ss，再次启动并其指定日志输出文件 12$ ssserver -c /etc/shadowsocks.json -d stop$ ssserver -c /etc/shadowsocks.json --log-file /var/log/shadowsocks.log -d start 启动后查看日志 1$ tail -f /var/log/shadowsocks.log 由日志可见启动正常。 本地电脑开启ss客户端，打开Google网址。返回终端查看服务器日志，发现日志没有任何变化。于是可以断定，是客户端向服务器端发请求的这个过程失败了。本地电脑检查客户端配置，都没有错。感觉是端口被墙了。 于是在服务器端修改 ss 端口。 12345678910$ vim /etc/shadowsocks.json&#123;&quot;server&quot;:&quot;0.0.0.0&quot;,&quot;server_port&quot;:8388,&quot;local_address&quot;: &quot;127.0.0.1&quot;,&quot;local_port&quot;:1080,&quot;password&quot;:&quot;helloworld&quot;,&quot;timeout&quot;:300,&quot;method&quot;:&quot;rc4-md5&quot;&#125; 找到 server_port 字段，修改它的值。注意不要和现有端口冲突。 重启 ss 服务,并再次查看日志输出： 123$ ssserver -c /etc/shadowsocks.json -d stop$ ssserver -c /etc/shadowsocks.json --log-file /var/log/shadowsocks.log -d start$ tail -f /var/log/shadowsocks.log 本地电脑再次访问Google网址，发现日志变化了。同时本地电脑网址也打开了🎉。]]></content>
      <tags>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建飞机场教程]]></title>
    <url>%2F2019%2F05%2F22%2Fss-jichang%2F</url>
    <content type="text"><![CDATA[第一步：安装宝塔Web管理面板SSH登陆服务器，sodu su获得系统管理权限，输入下面代码进行宝塔面板安装： 1wget -O install.sh http://download.bt.cn/install/install-ubuntu.sh &amp;&amp; bash install.sh 安装完毕后登陆管理后台安装LNMP环境，数据库推荐MYSQL5.6+，如果因内存小可以选5.5版本，PHP环境必须选7.1，ftp看个人需要，phpMyAdmin为了便于管理数据库也是必装的，选了4.7版本但实际安装会变成4.4版本，估计是宝塔的Bug，强迫症的可以删除这项安装任务，待后面手动安装4.7版本的，安装过程时间较长需要耐心等待，时间有点长，可以去喝杯茶，吃个饭，泡个澡，回来后可能还没装好，哈哈哈。 下一步新建一个站点，这里需要你去申请一个域名，可以去申请一个免费域名freenom.com这里可以去申请，但是建议还是去买一个域名吧。数据库暂时先不创建，网站目录自己设定，这里简单设置为ssrpanel。 点击软件管理，找到php7.1设置，在禁用函数里面找一下proc开头的函数，找到后都删除。Debian环境下装了几次这两个函数都不在列表里面，Centos6系统安装宝塔后应该会有，如果实际操作删除成功就在php服务里面重启一下php。 然后需要在php7.1设置里面安装扩展fileinfo，如下图: 第二步：ssrpanel前端安装返回到shell命令行模式，进入刚才建立的站点根目录 cd /www/wwwroot/ssrpanel 说明下这里的ssrpanel是你的站名，这个不是唯一的哦，牢记，你前面写的是什么就填什么！！！下载ssrpanel源代码（如果没有系统默认没有安装git的话，先用apt-get install git命令安装一下）： 1git clone https://github.com/ssrpanel/ssrpanel.git tmp &amp;&amp; mv tmp/.git . &amp;&amp; rm -rf tmp &amp;&amp; git reset --hard 下一步先回到宝塔面板添加ssrpanel所需的数据库，数据库名和密码自行设定，需要注意的是访问权限改为所有人，这样后端才能有权限远程访问前端数据库 在宝塔面板的文件管理中找到www/wwwroot/ssrpanel sql目录下的db.sql，下载到本地 点数据库，找到前面创建的数据库，点管理进入phpMyAdmin，选Import，点浏览找到本地的db.sql文件，最后点Go导入数据库 点文件找到/www/wwwroot/ssrpanel/config目录下的database.php文件点编辑，打开编辑窗口找到mysql设置的地方修改成刚才创建的数据库名称、用户名和密码，修改完毕点保存后关闭 需要配置邮件发送的在同目录下找到mail.php文件，编辑设置SMTP信息，邮箱我觉得不用去设置了所以这里就不设置了。 OK，数据库配置好了回到Shell继续安装前端，依次输入以下命令： 123456789101112php composer.phar installcp .env.example .envphp artisan key:generatechown -R www:www storage/chmod -R 777 storage/chmod -R 777 public/upload/ 回到宝塔面板中，点击所建网站——设置，找到伪静态这里，填写如下规则后保存： 1234location / &#123; try_files $uri $uri/ /index.php$is_args$args;&#125; 找到网站目录，把运行目录改为/public，保存 至此前端安装结束，打开浏览器访问域名。由于作者的更新，需要执行 php artisan upgradeUserPassword (默认用户名密码是admin/admin)： 登陆进去之后记得修改管理员密码和默认的SSR连接密码，然后在设置里面根据需要做相应的调整。 第三步:ssrpanel后端安装SSH登陆服务器安装libsodium，让后端支持更多的加密方式（以下命令一个个输入）： 123456789101112cd /rootapt-get install build-essentialwget https://github.com/jedisct1/libsodium/releases/download/1.0.15/libsodium-1.0.15.tar.gztar xf libsodium-1.0.15.tar.gz &amp;&amp; cd libsodium-1.0.15./configure &amp;&amp; make -j2 &amp;&amp; make installecho /usr/local/lib &gt; /etc/ld.so.conf.d/usr_local_lib.conf ldconfig安装shadowsocksr后端程序： 12345678910111213141516171819202122cd /rootgit clone -b manyuser https://github.com/shadowsocksrr/shadowsocksr.gitcd shadowsocksr./setup_cymysql.sh./initcfg.sh修改userapiconfig.py的接口为glzjinmod，修改完毕按Ctrl+X，输入Y回车退出并保存nano userapiconfig.py修改user-config.json，将connect_verbose_info的值改为1nano user-config.json修改usermysql.json，将数据库信息改为前面自己创建的数据库信息，记得修改node_id的值为1，这个值是要和前端面板的节点ID相对应的nano usermysql.json 回到宝塔面板，在安全里面放行3306数据库端口和10000后面ssrpanel需要用到的端口，这里设置放行10000至10500的端口 返回shell运行下面命令测试后端看是否正常，出现如下信息说明数据库连接正常 python server.py 运行正常后可以按Ctrl+C退出，运行下面的命令放入后台运行，如果前后端在同一台服务器上的可以运行./logrun.sh，这样管理后台能看到日志分析： ./run.sh运行说明, 有几种方式python server.py 用于调错的./run.sh 无日志后台运行./logrun.sh 有日志后台运行./stop.sh 停止运行./tail.sh 在有日志后台运行的情况下显示运行信息 现在进入ssrpanel前端面板，在节点管理——节点分组列表——新增一个“所有可见”的分组名称，可见级别选“倔强青铜”，这里只是为了演示，分组名称和对应的级别都是可以根据自己需要设定的 然后在节点管理——节点列表——新增节点，根据自己需要和实际设置一下，所属分组选“所有可见” 至此正常情况下前后端都能正常运行了，可以新建一个账号或是注册一个账号进行测试。 为了运行更可靠，可以用Supervisor守护进程启动ssr，先安装supervisor apt-get install supervisor -y写入配置 nano /etc/supervisor/conf.d/ssr.conf写入以下内容 [program:ssr]command=python /root/shadowsocksr/server.pyautorestart=trueautostart=trueuser=root重启Supervisor服务。 /etc/init.d/supervisor restart 重启ssr supervisorctl restart ssr查看Supervisor服务运行状态 supervisorctl status如果遇到问题，可以检查日志 supervisorctl tail -f ssr stderr如果使用supervisor进程守护，需要修改文件/etc/default/supervisor： nano /etc/default/supervisor添加一行 ulimit -n 1024000『代码升级』如果代码有更新可以进入网站根目录运行以下命令，更新前最好利用宝塔面板做好网站和数据库备份： cd /www/wwwroot/ssrpanelgit pull数据库升级可以用https://github.com/ssrpanel/ssrpanel/tree/master/sql/update里面的升级指令，打开phpMyAdmin，在ssrpanel数据库里面用SQL命令执行进行升级。以/sql/update/20171020.sql为例，在浏览器输入网址https://github.com/ssrpanel/ssrpanel/blob/master/sql/update/20171020.sql打开这个文件，将指令复制。随后打开宝塔面板数据库ssrpanel的phpMyAdmin管理，在SQL区域黏贴指令，点Go运行导入即可，如图： 以此类推，只要是在初始安装过后的数据库升级按文件日期先后用这个方式对数据库进行升级。 这篇教程其实也谈不上什么教程，只是整理一下便于自己今后使用而已。本篇教程全部基于bebian系统。centos以及乌班图系统的勿扰。如果你还有不会的，可以留言提出！ 转载：https://qukashing.com/?p=9]]></content>
      <tags>
        <tag>shadowsocks</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[vip解析]]></title>
    <url>%2F2019%2F05%2F22%2Fvip%2F</url>
    <content type="text"><![CDATA[最稳定万能vip视频解析接口 支持HTTPS https://cdn.yangju.vip/k/?url=后面加上播放的地址即可 https://cdn.yangju.vip/k/?url=https://jx.lache.me/cc/?url=https://api.653520.top/vip/?url=https://jx.ab33.top/vip/?url=https://vip.mpos.ren/v/?url=https://jx.000180.top/jx/?url=https://jx.km58.top/jx/?url= 永久性，重要的是够稳定！而且CDN加速！！解析接口支持:URL模式]]></content>
      <tags>
        <tag>vip解析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker安装mysql]]></title>
    <url>%2F2019%2F05%2F22%2Fdocker-mysql%2F</url>
    <content type="text"><![CDATA[docker pull mysql运行1docker run -p 3306:3306 --name mymysql -v $PWD/conf:/etc/mysql/conf.d -v $PWD/logs:/logs -v $PWD/data:/var/lib/mysql -e MYSQL_ROOT_PASSWORD=123456 -d mysql 命令说明： -p 3306:3306：将容器的 3306 端口映射到主机的 3306 端口。 -v -v $PWD/conf:/etc/mysql/conf.d：将主机当前目录下的 conf/my.cnf 挂载到容器的 /etc/mysql/my.cnf。 -v $PWD/logs:/logs：将主机当前目录下的 logs 目录挂载到容器的 /logs。 -v $PWD/data:/var/lib/mysql ：将主机当前目录下的data目录挂载到容器的 /var/lib/mysql 。 -e MYSQL_ROOT_PASSWORD=123456：初始化 root 用户的密码。 解决node 连接mysql错误ER_NOT_SUPPORTED_AUTH_MODE: Client does not support authentication protocol requested by server; consider upgrading MySQL client 1234567docker exec -it mysql(这里的mysql是指你启动时的容器名称) bashmysql -uroot -pALTER USER &apos;root&apos;@&apos;%&apos; IDENTIFIED WITH mysql_native_password BY &apos;123456&apos;;ALTER USER &apos;root&apos;@&apos;localhost&apos; IDENTIFIED WITH mysql_native_password BY &apos;123456&apos;;SELECT plugin FROM mysql.user WHERE User = &apos;root&apos;;]]></content>
  </entry>
  <entry>
    <title><![CDATA[frp安装配置]]></title>
    <url>%2F2019%2F05%2F21%2Ffrp%2F</url>
    <content type="text"><![CDATA[Frp的下载地址12345https://github.com/fatedier/frp/releasesFrp的官方中文文档: https://github.com/fatedier/frp/blob/master/README_zh.md 服务端frps.ini12[common]bind_port = 7080 #客户端和服务端之间通信的端口 客户端frpc.ini12345678910[common]server_addr = X.X.X.X #服务端IPserver_port = 7080 #与服务端bind_port一致[ssh]# tcp | udp | http | https | stcp | xtcp, default is tcptype = tcplocal_ip = 127.0.0.1local_port = 8080remote_port = 6080 启动12./frps -c ./frps.ini #服务端启动(linux)frpc.exe -c frpc.ini #客户端启动(windows) 制作为服务12345678910111213141516171819202122232425262728293031# 需要先 cd 到 frp 解压目录.# 复制文件cp frps /usr/local/bin/frpsmkdir /etc/frpcp frps.ini /etc/frp/frps.ini# 编写 frp service 文件，以 centos7 为例,适用于 debianvim /usr/lib/systemd/system/frps.service# 内容如下[Unit]Description=frpsAfter=network.target[Service]TimeoutStartSec=30ExecStart=/usr/local/bin/frps -c /etc/frp/frps.iniExecStop=/bin/kill $MAINPID[Install]WantedBy=multi-user.target# 启动 frp 并设置开机启动systemctl enable frpssystemctl start frpssystemctl status frps# 部分服务器上,可能需要加 .service 后缀来操作,即:systemctl enable frps.servicesystemctl start frps.servicesystemctl status frps.service]]></content>
      <tags>
        <tag>frp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派安装docker nextcloud]]></title>
    <url>%2F2019%2F05%2F21%2Fdocker-pi-nextcloud%2F</url>
    <content type="text"><![CDATA[查找nextcloud1docker search nextcloud 拉去1docker pull nextcloud 启动1docker run -d --restart=always --name nextcloud -p 8080:80 -v $PWD/docker/nextcloud:/var/www/html nextcloud 修改文件夹访问权限1sudo chown -R www-data:pi nextcloud 修改文件读写权限1sudo chmod -R 774 nextcloud/]]></content>
      <tags>
        <tag>docker</tag>
        <tag>pi</tag>
        <tag>nextcloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[树莓派安装docker]]></title>
    <url>%2F2019%2F05%2F20%2Fpi-docker%2F</url>
    <content type="text"><![CDATA[使用快捷脚本安装123curl -fsSL https://get.docker.com -o get-docker.shsh get-docker.sh 注意： “dpkg ”是“Debian Packager ”的简写。为 “Debian” 专门开发的套件管理系统，方便软件的安装、更新及移除。所有源自“Debian”的“Linux ” 发行版都使用 “dpkg”，例如 “Ubuntu”、“Knoppix ”等。dpkg是Debian软件包管理器的基础，在刚才安装docker时，dpkg被中断，我们可以使用“sudo dpkg –configure -a”命令来重新配置和释放所有的软件包。 将docker权限添加给普通用户12sudo gpasswd -a $USER docker #将登陆用户加入到docker用户组中newgrp docker #更新用户组]]></content>
      <tags>
        <tag>docker</tag>
        <tag>pi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker.core]]></title>
    <url>%2F2019%2F05%2F14%2Fdocker-core%2F</url>
    <content type="text"><![CDATA[拉取microsoft/dotnet镜像1ocker pull microsoft/dotnet 运行镜像使用docker run &lt;image&gt;可以启动镜像，通过指定参数-it以交互模式（进入容器内部）启动。依次执行以下命令： 12345678//启动一个dotnet镜像$ docker run -it microsoft/dotnet//创建项目名为HelloDocker.Web的.NET Core MVC项目dotnet new mvc -n HelloDocker.Web//进入HelloDocker.Web文件夹cd HelloDocker.Web//启动.NET Core MVC项目dotnet run 键盘按住Ctrl+C即可关闭应用，输入exit即可退出当前容器。 挂载宿主机项目到容器中在启动Docker镜像时，Docker允许我们通过使用-v参数挂载宿主机的文件到容器的指定目录下。换句话说，就相当于宿主机共享指定文件供容器去访问 1234// 命令中的`\`结合`Enter`键构成换行符，允许我们换行输入一个长命令。$ docker run -it \-v $HOME/demo/HelloDocker.Web:/app \microsoft/dotnet:latest 上面的命令就是把$HOME/demo/HelloDocker.Web文件夹下的文件挂载到容器的\app目录下。 Dockerfile123456//确保进入我们创建的MVC项目目录中去$ cd $HOME/demo/HelloDocker.Web//使用touch命令创建Dockerfile$ touch Dockerfile//使用vi命令编辑Dockerfilevi Dockerfile 进入VI编辑界面后，复制以下代码，使用shift + Ins命令即可粘贴。然后按ESE退出编辑模式，按shift + :，输入wq即可保存并退出编辑界面。 1234567FROM microsoft/dotnet:latestWORKDIR /appCOPY . /appRUN dotnet restoreEXPOSE 5000ENV ASPNETCORE_URLS http://*:5000ENTRYPOINT [&quot;dotnet&quot;,&quot;run&quot;] 上面的命令我依次解释一下： 使用FROM指定容器使用的镜像 使用WORKDIR指定工作目录 使用COPY指令，复制当前目录（其中.即代表当前目录）到容器中的/app目录下 使用RUN命令指定容器中执行的命令 使用EXPOSE指定容器暴露的端口号 使用ENV指定环境参数，上面用来告诉.NETCore项目在所有网络接口上监听5000端口 使用ENTRYPOINT制定容器的入口点 Dockerfile就绪，我们就可以将我们当前项目打包成镜像以分发部署。使用docker build -t &lt;name&gt; &lt;path&gt;指令打包镜像： 1docker build -t hellodocker.web . 推送镜像到仓库到Docker Hub注册个账号，然后我们把本地打包的镜像放到自己账号下的仓库 注册完毕后，执行docker login： 再执行docker push： 镜像按&lt;user&gt;/&lt;repo&gt;格式来命名 1docker tag hellodocker.web shengjie/hellodocker.web:v1]]></content>
      <tags>
        <tag>docker</tag>
        <tag>core</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GitLab持续集成环境 windows版]]></title>
    <url>%2F2019%2F05%2F13%2Fgitlab-CI%2F</url>
    <content type="text"><![CDATA[搭建环境GitLab-Runner下载1https://gitlab-ci-multi-runner-downloads.s3.amazonaws.com/latest/binaries/gitlab-ci-multi-runner-windows-amd64.exe GitLab查看项目的Runners 点击一个项目-&gt;Settings-&gt;Runners, 得到Url地址①和registration token② 构建GitLab-Runner服务12345678910gitlab-ci-multi-runner-windows-amd64.exe register根据提示，填写1) GitLab-&gt;Runners的Url地址①2) GitLab-&gt;Runners的registration token②3) runner名称，这个随便写4) 分支名，master5) 协议方式，shellgitlab-ci-multi-runner-windows-amd64.exe installgitlab-ci-multi-runner-windows-amd64.exe start 修改协议config.toml文件 注册成功后，在文件夹中找到config.toml，在[[runners]]后面添加shell = “powershell”节点 构建.gitlab-ci.yml脚本1234567891011121314151617181920212223stages:- buildjob: stage: build script: - echo &quot;Restoring NuGet Packages...&quot; #- C:\test\nuget.exe restore &quot;ConsoleApplication1.sln&quot; - echo &quot;Solution Build...&quot; - C:\Windows\Microsoft.NET\Framework64\v4.0.30319\msbuild.exe /p:Configuration=Debug /p:Platform=&quot;Any CPU&quot; /consoleloggerparameters:ErrorsOnly /maxcpucount /nologo /property:Configuration=Release /verbosity:quiet /p:VisualStudioVersion=10.0 &quot;test1.sln&quot; tags: except: - tags]]></content>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker.gitlab]]></title>
    <url>%2F2019%2F05%2F10%2Fdocker-gitlab%2F</url>
    <content type="text"><![CDATA[拉取镜像并启动123456789101112docker pull gitlab/gitlab-ce# 拉取镜像mkdir -p gitlab/config gitlab/logs gitlab/data# 创建映射文件sudo docker run -d -p 8443:443 -p 8081:80 -p 8022:22 \--name gitlab --restart always \--volume $PWD/gitlab/config:/etc/gitlab \--volume $PWD/gitlab/logs:/var/log/gitlab \--volume $PWD/gitlab/data:/var/opt/gitlab \gitlab/gitlab-ce:latest# 启动8081 访问]]></content>
      <tags>
        <tag>docker</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Markdown基本语法]]></title>
    <url>%2F2019%2F05%2F10%2FMarkdown%2F</url>
    <content type="text"><![CDATA[一、标题在想要设置为标题的文字前面加#来表示一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。 注：标准语法一般在#后跟个空格再写文字，貌似简书不加空格也行。 示例：123456# 这是一级标题## 这是二级标题### 这是三级标题#### 这是四级标题##### 这是五级标题###### 这是六级标题 这是一级标题这是二级标题这是三级标题这是四级标题这是五级标题这是六级标题二、字体加粗 要加粗的文字左右分别用两个*号包起来 斜体 要倾斜的文字左右分别用一个*号包起来 斜体加粗 要倾斜和加粗的文字左右分别用三个*号包起来 删除线 要加删除线的文字左右分别用两个~~号包起来 示例：1234**这是加粗的文字***这是倾斜的文字*`***这是斜体加粗的文字***~~这是加删除线的文字~~ 这是加粗的文字这是倾斜的文字`这是斜体加粗的文字这是加删除线的文字 三、引用在引用的文字前加&gt;即可。引用也可以嵌套，如加两个&gt;&gt;三个&gt;&gt;&gt;n个…貌似可以一直加下去，但没神马卵用 示例： 123&gt;这是引用的内容&gt;&gt;这是引用的内容&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;这是引用的内容 这是引用的内容 这是引用的内容 这是引用的内容 四、分割线三个或者三个以上的 - 或者 * 都可以。 示例： 1234-------******** 五、图片语法： 1234![图片alt](图片地址 &apos;&apos;图片title&apos;&apos;)图片alt就是显示在图片下面的文字，相当于对图片内容的解释。图片title是图片的标题，当鼠标移到图片上时显示的内容。title可加可不加 示例： 12![blockchain](https://ss0.bdstatic.com/70cFvHSh_Q1YnxGkpoWK1HF6hhy/it/u=702257389,1274025419&amp;fm=27&amp;gp=0.jpg &quot;区块链&quot;) 六、超链接语法： 12[超链接名](超链接地址 &quot;超链接title&quot;)title可加可不加 12[简书](http://jianshu.com)[百度](http://baidu.com) 简书百度 七、列表无序列表 语法：无序列表用 - + * 任何一种都可以 12345- 列表内容+ 列表内容* 列表内容注意：- + * 跟内容之间都要有一个空格 列表内容 列表内容 列表内容]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker.registry]]></title>
    <url>%2F2019%2F05%2F10%2Fregistry%2F</url>
    <content type="text"><![CDATA[安装1docker pull registry 运行1docker run -d -p 5000:5000 -v $PWD/myregistry:/var/lib/registry registry 测试1234docker tag hello-world 192.168.119.148:5000/test # 复制docker push 192.168.119.148:5000/test # 提交docker rmi 192.168.119.148:5000/test # 删除原有docker pull 192.168.119.148:5000/test # 拉取 查看1curl http://192.168.2.193:5000/v2/_catalog]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker.portainer]]></title>
    <url>%2F2019%2F05%2F10%2Fdocker-portainer%2F</url>
    <content type="text"><![CDATA[安装1docker pull portainer/portainer 启动12345678$ docker run -d -p 9000:9000 -v /var/run/docker.sock:/var/run/docker.sock \ -v $PWD/portainer:/data \ --name portainer --restart=always \ portainer/portainer说明:-p 9000:9000 : portainer的端口映射为9000-v /var/run/docker.sock:/var/run/docker.sock： 映射本地docker路径，即可管理本地docker-v /home/docker/portainer:/data: 实现数据持久化，将portainer数据映射到本地。]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[docker ubuntu 安装]]></title>
    <url>%2F2019%2F05%2F10%2Fdocker-init%2F</url>
    <content type="text"><![CDATA[安装1sudo apt install docker.io 启动12sudo systemctl start dockersudo systemctl enable docker 将docker权限添加给普通用户12sudo gpasswd -a $USER docker #将登陆用户加入到docker用户组中newgrp docker #更新用户组 运行交互式的容器12345docker run -i -t microsoft/dotnet /bin/bash各个参数解析：-t:在新容器内指定一个伪终端或终端。-i:允许你对容器内的标准输入 (STDIN) 进行交互。ctrl + D 退出]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker开启远程进程服务以及VSCode、Idea等IDE连接使用远程]]></title>
    <url>%2F2019%2F05%2F09%2Fdocker%2F</url>
    <content type="text"><![CDATA[Docker远程服务开发环境大多使用的的是windows系统，服务器运行环境一般采用Linux系统，这时候生成镜像时用到远程连接Docker服务。 开启Docker远程如果只是临时使用远程docker，使用以下命令： 1sudo dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375 如果使用docker启动时开启远程docker，则修改 /lib/systemd/system/docker.service 的ExecStart(不同版本的docker可能不同，处理思路类似) 1vim /lib/systemd/system/docker.service 原docker.service配置中的ExecStart配置项 1ExecStart=/usr/bin/dockerd -H unix:// 修改为 1ExecStart=/usr/bin/dockerd -H unix:///var/run/docker.sock -H tcp://0.0.0.0:2375 重启Docker配置生效 12systemctl daemon-reloadsystemctl restart docker]]></content>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo的Next主题详细配置]]></title>
    <url>%2F2019%2F05%2F09%2Fhexo-more%2F</url>
    <content type="text"><![CDATA[在 Hexo 中有两份主要的配置文件，其名称都是 _config.yml。 其中，一份位于站点根目录下，主要包含 Hexo 本身的配置；另一份位于主题目录下，这份配置由主题作者提供，主要用于配置主题相关的选项。为了描述方便，在以下说明中，将前者称为站点配置文件， 后者称为主题配置文件。以下所有终端执行的命令都在你的Hexo根目录下 基本信息配置1基本信息包括：博客标题、作者、描述、语言等等。 打开 站点配置文件 ，找到Site模块 123456title: 标题subtitle: 副标题description: 描述author: 作者language: 语言（简体中文是zh-Hans）timezone: 网站时区（Hexo 默认使用您电脑的时区，不用写） 菜单设置菜单包括：首页、归档、分类、标签、关于等等 我们刚开始默认的菜单只有首页和归档两个，不能够满足我们的要求，所以需要添加菜单，打开 主题配置文件 找到Menu Settings 123456789menu: home: / || home //首页 archives: /archives/ || archive //归档 categories: /categories/ || th //分类 tags: /tags/ || tags //标签 about: /about/ || user //关于 #schedule: /schedule/ || calendar //日程表 #sitemap: /sitemap.xml || sitemap //站点地图 #commonweal: /404/ || heartbeat //公益404 看看你需要哪个菜单就把哪个取消注释打开就行了；关于后面的格式，以archives: /archives/ || archive为例：|| 之前的/archives/表示标题“归档”，关于标题的格式可以去themes/next/languages/zh-Hans.yml中参考或修改||之后的archive表示图标，可以去Font Awesome中查看或修改，Next主题所有的图标都来自Font Awesome。 Next主题样式设置我们百里挑一选择了Next主题，不过Next主题还有4种风格供我们选择，打开 主题配置文件 找到Scheme Settings 12345# Schemes# scheme: Muse# scheme: Mist# scheme: Piscesscheme: Gemini 4种风格大同小异，本人用的是Gemini风格，你们可以选择自己喜欢的风格。 侧栏设置侧栏设置包括：侧栏位置、侧栏显示与否、文章间距、返回顶部按钮等等 打开 主题配置文件 找到sidebar字段 12345678910111213141516sidebar:# Sidebar Position - 侧栏位置（只对Pisces | Gemini两种风格有效） position: left //靠左放置 #position: right //靠右放置# Sidebar Display - 侧栏显示时机（只对Muse | Mist两种风格有效） #display: post //默认行为，在文章页面（拥有目录列表）时显示 display: always //在所有页面中都显示 #display: hide //在所有页面中都隐藏（可以手动展开） #display: remove //完全移除 offset: 12 //文章间距（只对Pisces | Gemini两种风格有效） b2t: false //返回顶部按钮（只对Pisces | Gemini两种风格有效） scrollpercent: true //返回顶部按钮的百分比 头像设置打开 主题配置文件 找到Sidebar Avatar字段 12# Sidebar Avataravatar: /images/header.jpg 这是头像的路径，只需把你的头像命名为header.jpg（随便命名）放入themes/next/source/images中，将avatar的路径名改成你的头像名就OK啦！]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo使用next.Pisces主题]]></title>
    <url>%2F2019%2F05%2F09%2Fhexo-next%2F</url>
    <content type="text"><![CDATA[之前Hexo博客一直是使用的Jacman主题,用久的有点儿审美疲劳，最近看上比较简洁的主题Next,视觉上确实要好看很多,配色简洁看着比较舒服. 安装首先进入到你的博客的根目录 12➜ Blog git:(master) ✗ ➜ Blog git:(master) ✗ git clone https://github.com/theme-next/hexo-theme-next themes/next 配置接下来就是把主题配置成Next,修改博客根目录下的配置文件_config.yml: 1234# Extensions## Plugins: http://hexo.io/plugins/## Themes: http://hexo.io/themes/theme: next 然后启动博客就可以看到效果了. 修改next样式不过默认的博客样式不是很好,一些标签页展示的不是很好,所以还需要改下样式.进入themes/next文件夹,修改_config.yml 修改导航菜单 123456789menu: home: / || home archives: /archives/ || archive categories: /categories/ || th tags: /tags/ || tags about: /about/ || user #schedule: /schedule/ || calendar #sitemap: /sitemap.xml || sitemap #commonweal: /404/ || heartbeat 修改了这几个之后还不够,需要创建这几个的导航页面(home导航页为根目录不需要创建): 创建归档页面创建页面 1hexo new page categories 修改内容:1234title: 分类date: 2018-05-14 23:34:12type: &quot;categories&quot;--- 创建标签页创建标签页 1hexo new page tags 修改内容:1234title: 标签date: 2018-05-14 23:36:18type: &quot;tags&quot;--- 个人主页创建个人主页 1hexo new page about 修改内容:123title: 个人简介date: 2018-05-14 23:38:55--- 切换主题布局可以看到_config.yaml文件中默认是使用的Muse主题,这个主题是把标签之类的放到顶部,我更喜欢双栏布局，所以把对应部分改成下面这样: 12345# Schemes#scheme: Muse#scheme: Mistscheme: Pisces#scheme: Gemini 设置语言默认语言在~/Blog/next/languages下面: 1234➜ next git:(master) ✗ ls -l languages/zh-*-rw-rw-r-- 1 anonymous anonymous 2100 5月 15 10:47 languages/zh-CN.yml-rw-rw-r-- 1 anonymous anonymous 2094 5月 15 10:47 languages/zh-HK.yml-rw-rw-r-- 1 anonymous anonymous 2094 5月 15 10:47 languages/zh-TW.yml 默认zh-CN.yml就已经给我们映射好了，只需要把博客设置成对应的语言,修改~/Blog/_config.yml: 1234# Sitelanguage: zh-CNtimezone: Asia/ChongqingGitComment 如果你配了用GitComment来作为你的博客评论，那你还需要改下对应得配置,不然评论都不会显示了,详情可以参见:Hexo 使用Gitment评论功能]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hexo用法]]></title>
    <url>%2F2019%2F05%2F09%2FHexo%2F</url>
    <content type="text"><![CDATA[输入命令 1$ npm install -g hexo-cli 依旧用hexo -v查看一下版本 至此就全部安装完了。 接下来初始化一下hexo1hexo init myblog 这个myblog可以自己取什么名字都行，然后 cd myblog //进入这个myblog文件夹1npm install 新建完成后，指定文件夹目录下有： node_modules: 依赖包public：存放生成的页面scaffolds：生成文章的一些模板source：用来存放你的文章themes：主题 _config.yml: 博客的配置文件12hexo ghexo server 打开hexo的服务，在浏览器输入localhost:4000就可以看到你生成的博客了。 新建文档1$ hexo new &#123;title&#125;]]></content>
      <categories>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
</search>
